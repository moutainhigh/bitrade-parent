13:43:19.978 [main] INFO  o.s.c.a.AnnotationConfigApplicationContext - Refreshing org.springframework.context.annotation.AnnotationConfigApplicationContext@3300f4fd: startup date [Tue Sep 10 13:43:19 CST 2019]; root of context hierarchy
13:43:20.110 [background-preinit] INFO  org.hibernate.validator.internal.util.Version - HV000001: Hibernate Validator 5.3.6.Final
13:43:20.179 [main] INFO  o.s.b.f.a.AutowiredAnnotationBeanPostProcessor - JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
13:43:20.232 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'configurationPropertiesRebinderAutoConfiguration' of type [org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration$$EnhancerBySpringCGLIB$$6964a03e] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
13:43:20.764 [main] INFO  cn.ztuo.bitrade.MarketApplication - No active profile set, falling back to default profiles: default
13:43:20.780 [main] INFO  o.s.b.c.e.AnnotationConfigEmbeddedWebApplicationContext - Refreshing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@d56aaa6: startup date [Tue Sep 10 13:43:20 CST 2019]; parent: org.springframework.context.annotation.AnnotationConfigApplicationContext@3300f4fd
13:43:21.481 [main] INFO  o.s.b.factory.support.DefaultListableBeanFactory - Overriding bean definition for bean 'redisUtil' with a different definition: replacing [Generic bean: class [cn.ztuo.bitrade.util.RedisUtil]; scope=singleton; abstract=false; lazyInit=false; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=null; destroyMethodName=null; defined in file [F:\ztuo_v2\ztuo_framework\core\target\classes\cn\ztuo\bitrade\util\RedisUtil.class]] with [Root bean: class [null]; scope=; abstract=false; lazyInit=false; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=redisConfig; factoryMethodName=redisUtil; initMethodName=null; destroyMethodName=(inferred); defined in class path resource [cn/ztuo/bitrade/config/RedisConfig.class]]
13:43:21.666 [main] INFO  o.s.d.r.config.RepositoryConfigurationDelegate - Multiple Spring Data modules found, entering strict repository configuration mode!
13:43:21.944 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data JPA - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.OrderDetailAggregationRepository.
13:43:21.960 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data JPA - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.ExchangeOrderDetailRepository.
13:43:21.967 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data JPA - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.MemberLogDao.
13:43:21.998 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data JPA - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.TradeRepository.
13:43:22.014 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data JPA - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.ExchangeTradeRepository.
13:43:22.167 [main] INFO  o.s.d.r.config.RepositoryConfigurationDelegate - Multiple Spring Data modules found, entering strict repository configuration mode!
13:43:22.446 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.AdvertiseDao.
13:43:22.446 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.MemberPromotionDao.
13:43:22.446 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.ReleaseBalanceDao.
13:43:22.446 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.AdminDao.
13:43:22.446 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.MemberLevelDao.
13:43:22.446 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.OrderDao.
13:43:22.446 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.MemberSignRecordDao.
13:43:22.446 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.AppRevisionDao.
13:43:22.446 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.IntegrationRecordDao.
13:43:22.446 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.MemberApplicationConfigDao.
13:43:22.446 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.SysPermissionDao.
13:43:22.446 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.DataDictionaryDao.
13:43:22.446 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.HotTransferRecordDao.
13:43:22.446 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.MemberDepositDao.
13:43:22.446 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.CountryDao.
13:43:22.446 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.DividendStartRecordDao.
13:43:22.446 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.MemberBonusDao.
13:43:22.446 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.EmptionRecordDao.
13:43:22.446 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.SysHelpDao.
13:43:22.446 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.LossThresholdRepository.
13:43:22.446 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.PaymentHistoryRepository.
13:43:22.446 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.FeedbackDao.
13:43:22.446 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.RewardActivitySettingDao.
13:43:22.446 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.AnnouncementDao.
13:43:22.446 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.AdminAccessLogDao.
13:43:22.446 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.BusinessCancelApplyDao.
13:43:22.446 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.IeoEmptionDao.
13:43:22.446 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.AppealDao.
13:43:22.446 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.GiftConfigDao.
13:43:22.461 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.LockPositionRecordDao.
13:43:22.461 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.RiskRecordRepository.
13:43:22.461 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.RewardWalletDao.
13:43:22.461 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.RewardPromotionSettingDao.
13:43:22.461 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.LeverWalletTransferRecordRepository.
13:43:22.461 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.CoinDao.
13:43:22.461 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.MemberApiKeyDao.
13:43:22.461 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.MemberTransactionDao.
13:43:22.461 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.SignDao.
13:43:22.461 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.SmsDao.
13:43:22.461 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.PlatformTransactionDao.
13:43:22.461 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.LegalWalletWithdrawDao.
13:43:22.461 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.ExchangeOrderRepository.
13:43:22.461 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.LeverCoinRepository.
13:43:22.461 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.MemberDao.
13:43:22.461 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.InitPlateDao.
13:43:22.461 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.MemberAddressDao.
13:43:22.461 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.RobotTransactionDao.
13:43:22.461 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.MemberApplicationDao.
13:43:22.461 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.FavorSymbolRepository.
13:43:22.461 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.LoanRecordRepository.
13:43:22.461 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.MemberWalletDao.
13:43:22.461 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.OtcWalletDao.
13:43:22.461 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.DepositRecordDao.
13:43:22.461 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.PoundageConvertEthDao.
13:43:22.461 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.SysAdvertiseDao.
13:43:22.461 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.TransferAddressDao.
13:43:22.461 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.ExchangeCoinRepository.
13:43:22.461 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.SysRoleDao.
13:43:22.461 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.WebsiteInformationDao.
13:43:22.461 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.OtcCoinDao.
13:43:22.468 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.TransferRecordDao.
13:43:22.468 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.GiftRecordDao.
13:43:22.468 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.DepartmentDao.
13:43:22.468 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.BusinessAuthDepositDao.
13:43:22.468 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.AirdropDao.
13:43:22.468 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.LeverWalletRepository.
13:43:22.468 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.MemberGradeDao.
13:43:22.468 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.RewardRecordDao.
13:43:22.468 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.WithdrawRecordDao.
13:43:22.468 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.LegalWalletRechargeDao.
13:43:22.468 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.BusinessAuthApplyDao.
13:43:22.483 [main] INFO  o.s.d.r.config.RepositoryConfigurationDelegate - Multiple Spring Data modules found, entering strict repository configuration mode!
13:43:22.769 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.AdvertiseDao.
13:43:22.771 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.MemberPromotionDao.
13:43:22.771 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.ReleaseBalanceDao.
13:43:22.771 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.AdminDao.
13:43:22.771 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.MemberLevelDao.
13:43:22.771 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.OrderDao.
13:43:22.771 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.MemberSignRecordDao.
13:43:22.771 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.AppRevisionDao.
13:43:22.771 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.OrderDetailAggregationRepository.
13:43:22.771 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.IntegrationRecordDao.
13:43:22.771 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.MemberApplicationConfigDao.
13:43:22.771 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.SysPermissionDao.
13:43:22.771 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.ExchangeOrderDetailRepository.
13:43:22.771 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.DataDictionaryDao.
13:43:22.771 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.HotTransferRecordDao.
13:43:22.771 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.MemberDepositDao.
13:43:22.771 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.CountryDao.
13:43:22.771 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.DividendStartRecordDao.
13:43:22.771 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.MemberBonusDao.
13:43:22.771 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.MemberLogDao.
13:43:22.771 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.EmptionRecordDao.
13:43:22.771 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.SysHelpDao.
13:43:22.771 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.LossThresholdRepository.
13:43:22.771 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.PaymentHistoryRepository.
13:43:22.771 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.FeedbackDao.
13:43:22.771 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.RewardActivitySettingDao.
13:43:22.771 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.AnnouncementDao.
13:43:22.771 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.AdminAccessLogDao.
13:43:22.771 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.BusinessCancelApplyDao.
13:43:22.771 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.IeoEmptionDao.
13:43:22.771 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.AppealDao.
13:43:22.771 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.GiftConfigDao.
13:43:22.771 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.LockPositionRecordDao.
13:43:22.771 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.RiskRecordRepository.
13:43:22.771 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.RewardWalletDao.
13:43:22.771 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.RewardPromotionSettingDao.
13:43:22.771 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.LeverWalletTransferRecordRepository.
13:43:22.771 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.CoinDao.
13:43:22.771 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.MemberApiKeyDao.
13:43:22.771 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.MemberTransactionDao.
13:43:22.771 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.SignDao.
13:43:22.771 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.SmsDao.
13:43:22.771 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.PlatformTransactionDao.
13:43:22.771 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.LegalWalletWithdrawDao.
13:43:22.771 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.ExchangeOrderRepository.
13:43:22.771 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.LeverCoinRepository.
13:43:22.771 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.MemberDao.
13:43:22.771 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.InitPlateDao.
13:43:22.771 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.MemberAddressDao.
13:43:22.779 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.RobotTransactionDao.
13:43:22.779 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.MemberApplicationDao.
13:43:22.779 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.FavorSymbolRepository.
13:43:22.779 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.LoanRecordRepository.
13:43:22.779 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.MemberWalletDao.
13:43:22.779 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.OtcWalletDao.
13:43:22.779 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.DepositRecordDao.
13:43:22.779 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.PoundageConvertEthDao.
13:43:22.779 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.SysAdvertiseDao.
13:43:22.779 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.TransferAddressDao.
13:43:22.779 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.ExchangeCoinRepository.
13:43:22.779 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.SysRoleDao.
13:43:22.781 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.WebsiteInformationDao.
13:43:22.781 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.TradeRepository.
13:43:22.781 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.OtcCoinDao.
13:43:22.781 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.TransferRecordDao.
13:43:22.781 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.GiftRecordDao.
13:43:22.781 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.DepartmentDao.
13:43:22.781 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.BusinessAuthDepositDao.
13:43:22.781 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.AirdropDao.
13:43:22.781 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.LeverWalletRepository.
13:43:22.781 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.MemberGradeDao.
13:43:22.781 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.RewardRecordDao.
13:43:22.781 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.WithdrawRecordDao.
13:43:22.781 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.ExchangeTradeRepository.
13:43:22.781 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.LegalWalletRechargeDao.
13:43:22.781 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.BusinessAuthApplyDao.
13:43:22.974 [main] INFO  o.springframework.cloud.context.scope.GenericScope - BeanFactory id=30c01683-e1c5-3dbf-93ce-833db208f136
13:43:23.007 [main] INFO  o.s.b.f.a.AutowiredAnnotationBeanPostProcessor - JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
13:43:23.039 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'cn.ztuo.aqmd.HawkNettyConfiguration' of type [cn.ztuo.aqmd.HawkNettyConfiguration$$EnhancerBySpringCGLIB$$b97a6f17] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
13:43:23.054 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.kafka.annotation.KafkaBootstrapConfiguration' of type [org.springframework.kafka.annotation.KafkaBootstrapConfiguration$$EnhancerBySpringCGLIB$$20fcaec4] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
13:43:23.108 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'loginUserService' of type [cn.ztuo.aqmd.service.DefaultLoginUserService] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
13:43:23.108 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'hawkServerRealm' of type [cn.ztuo.aqmd.netty.shiro.realm.HawkServerRealm] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
13:43:23.123 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'sessionIdGenerator' of type [cn.ztuo.aqmd.netty.shiro.SequenceSessionIdGenerator] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
13:43:23.123 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'sessionDAO' of type [org.apache.shiro.session.mgt.eis.EnterpriseCacheSessionDAO] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
13:43:23.139 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'sessionManager' of type [cn.ztuo.aqmd.netty.shiro.session.DefaultHawkSessionManager] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
13:43:23.170 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'spring.cache-org.springframework.boot.autoconfigure.cache.CacheProperties' of type [org.springframework.boot.autoconfigure.cache.CacheProperties] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
13:43:23.170 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.boot.autoconfigure.cache.CacheAutoConfiguration' of type [org.springframework.boot.autoconfigure.cache.CacheAutoConfiguration$$EnhancerBySpringCGLIB$$8ad09803] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
13:43:23.186 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'cacheManagerCustomizers' of type [org.springframework.boot.autoconfigure.cache.CacheManagerCustomizers] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
13:43:23.192 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.boot.autoconfigure.cache.EhCacheCacheConfiguration' of type [org.springframework.boot.autoconfigure.cache.EhCacheCacheConfiguration$$EnhancerBySpringCGLIB$$256f6501] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
13:43:23.308 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'ehCacheCacheManager' of type [net.sf.ehcache.CacheManager] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
13:43:23.324 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'cacheManager' of type [org.springframework.cache.ehcache.EhCacheCacheManager] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
13:43:23.324 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'springCacheManagerWrapper' of type [cn.ztuo.aqmd.netty.shiro.cache.SpringCacheManagerWrapper] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
13:43:23.324 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'hawkSubjectFactory' of type [cn.ztuo.aqmd.netty.shiro.mgt.DefaultHawkSubjectFactory] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
13:43:23.339 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'securityManager' of type [cn.ztuo.aqmd.netty.shiro.mgt.DefaultHawkSecurityManager] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
13:43:23.355 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'methodInvokingFactoryBean' of type [org.springframework.beans.factory.config.MethodInvokingFactoryBean] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
13:43:23.440 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration' of type [org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration$$EnhancerBySpringCGLIB$$4d4a9d41] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
13:43:23.471 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.cache.annotation.ProxyCachingConfiguration' of type [org.springframework.cache.annotation.ProxyCachingConfiguration$$EnhancerBySpringCGLIB$$965cd35f] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
13:43:23.493 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'cacheAutoConfigurationValidator' of type [org.springframework.boot.autoconfigure.cache.CacheAutoConfiguration$CacheManagerValidator] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
13:43:23.525 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration' of type [org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration$$EnhancerBySpringCGLIB$$6964a03e] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
13:43:23.810 [main] INFO  o.s.b.c.e.tomcat.TomcatEmbeddedServletContainer - Tomcat initialized with port(s): 6004 (http)
13:43:23.810 [main] INFO  org.apache.catalina.core.StandardService - Starting service [Tomcat]
13:43:23.810 [main] INFO  org.apache.catalina.core.StandardEngine - Starting Servlet Engine: Apache Tomcat/8.5.23
13:43:23.941 [localhost-startStop-1] INFO  o.a.c.c.C.[Tomcat].[localhost].[/market] - Initializing Spring embedded WebApplicationContext
13:43:23.941 [localhost-startStop-1] INFO  org.springframework.web.context.ContextLoader - Root WebApplicationContext: initialization completed in 3161 ms
13:43:24.157 [localhost-startStop-1] INFO  o.s.boot.web.servlet.FilterRegistrationBean - Mapping filter: 'characterEncodingFilter' to: [/*]
13:43:24.157 [localhost-startStop-1] INFO  o.s.boot.web.servlet.FilterRegistrationBean - Mapping filter: 'hiddenHttpMethodFilter' to: [/*]
13:43:24.157 [localhost-startStop-1] INFO  o.s.boot.web.servlet.FilterRegistrationBean - Mapping filter: 'httpPutFormContentFilter' to: [/*]
13:43:24.157 [localhost-startStop-1] INFO  o.s.boot.web.servlet.FilterRegistrationBean - Mapping filter: 'requestContextFilter' to: [/*]
13:43:24.157 [localhost-startStop-1] INFO  o.s.boot.web.servlet.FilterRegistrationBean - Mapping filter: 'corsFilter' to: [/*]
13:43:24.157 [localhost-startStop-1] INFO  o.s.boot.web.servlet.ServletRegistrationBean - Mapping servlet: 'dispatcherServlet' to [/]
13:43:24.558 [main] INFO  com.alibaba.druid.pool.DruidDataSource - {dataSource-1} inited
13:43:26.638 [Druid-ConnectionPool-Create-445202766] ERROR com.alibaba.druid.pool.DruidDataSource - create connection SQLException, url: jdbc:mysql://127.0.0.1:3306/bitrade?characterEncoding=utf-8, errorCode 0, state 08S01
com.mysql.jdbc.exceptions.jdbc4.CommunicationsException: Communications link failure

The last packet sent successfully to the server was 0 milliseconds ago. The driver has not received any packets from the server.
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at com.mysql.jdbc.Util.handleNewInstance(Util.java:377)
	at com.mysql.jdbc.SQLError.createCommunicationsException(SQLError.java:1036)
	at com.mysql.jdbc.MysqlIO.<init>(MysqlIO.java:338)
	at com.mysql.jdbc.ConnectionImpl.coreConnect(ConnectionImpl.java:2232)
	at com.mysql.jdbc.ConnectionImpl.connectOneTryOnly(ConnectionImpl.java:2265)
	at com.mysql.jdbc.ConnectionImpl.createNewIO(ConnectionImpl.java:2064)
	at com.mysql.jdbc.ConnectionImpl.<init>(ConnectionImpl.java:790)
	at com.mysql.jdbc.JDBC4Connection.<init>(JDBC4Connection.java:44)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at com.mysql.jdbc.Util.handleNewInstance(Util.java:377)
	at com.mysql.jdbc.ConnectionImpl.getInstance(ConnectionImpl.java:395)
	at com.mysql.jdbc.NonRegisteringDriver.connect(NonRegisteringDriver.java:325)
	at com.alibaba.druid.pool.DruidAbstractDataSource.createPhysicalConnection(DruidAbstractDataSource.java:1513)
	at com.alibaba.druid.pool.DruidAbstractDataSource.createPhysicalConnection(DruidAbstractDataSource.java:1578)
	at com.alibaba.druid.pool.DruidDataSource$CreateConnectionThread.run(DruidDataSource.java:2466)
Caused by: java.net.ConnectException: Connection refused: connect
	at java.net.DualStackPlainSocketImpl.connect0(Native Method)
	at java.net.DualStackPlainSocketImpl.socketConnect(DualStackPlainSocketImpl.java:79)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.PlainSocketImpl.connect(PlainSocketImpl.java:172)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:589)
	at com.mysql.jdbc.StandardSocketFactory.connect(StandardSocketFactory.java:213)
	at com.mysql.jdbc.MysqlIO.<init>(MysqlIO.java:297)
	... 15 common frames omitted
13:43:28.673 [Druid-ConnectionPool-Create-445202766] ERROR com.alibaba.druid.pool.DruidDataSource - create connection SQLException, url: jdbc:mysql://127.0.0.1:3306/bitrade?characterEncoding=utf-8, errorCode 0, state 08S01
com.mysql.jdbc.exceptions.jdbc4.CommunicationsException: Communications link failure

The last packet sent successfully to the server was 0 milliseconds ago. The driver has not received any packets from the server.
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at com.mysql.jdbc.Util.handleNewInstance(Util.java:377)
	at com.mysql.jdbc.SQLError.createCommunicationsException(SQLError.java:1036)
	at com.mysql.jdbc.MysqlIO.<init>(MysqlIO.java:338)
	at com.mysql.jdbc.ConnectionImpl.coreConnect(ConnectionImpl.java:2232)
	at com.mysql.jdbc.ConnectionImpl.connectOneTryOnly(ConnectionImpl.java:2265)
	at com.mysql.jdbc.ConnectionImpl.createNewIO(ConnectionImpl.java:2064)
	at com.mysql.jdbc.ConnectionImpl.<init>(ConnectionImpl.java:790)
	at com.mysql.jdbc.JDBC4Connection.<init>(JDBC4Connection.java:44)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at com.mysql.jdbc.Util.handleNewInstance(Util.java:377)
	at com.mysql.jdbc.ConnectionImpl.getInstance(ConnectionImpl.java:395)
	at com.mysql.jdbc.NonRegisteringDriver.connect(NonRegisteringDriver.java:325)
	at com.alibaba.druid.pool.DruidAbstractDataSource.createPhysicalConnection(DruidAbstractDataSource.java:1513)
	at com.alibaba.druid.pool.DruidAbstractDataSource.createPhysicalConnection(DruidAbstractDataSource.java:1578)
	at com.alibaba.druid.pool.DruidDataSource$CreateConnectionThread.run(DruidDataSource.java:2466)
Caused by: java.net.ConnectException: Connection refused: connect
	at java.net.DualStackPlainSocketImpl.connect0(Native Method)
	at java.net.DualStackPlainSocketImpl.socketConnect(DualStackPlainSocketImpl.java:79)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.PlainSocketImpl.connect(PlainSocketImpl.java:172)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:589)
	at com.mysql.jdbc.StandardSocketFactory.connect(StandardSocketFactory.java:213)
	at com.mysql.jdbc.MysqlIO.<init>(MysqlIO.java:297)
	... 15 common frames omitted
13:43:31.194 [Druid-ConnectionPool-Create-445202766] ERROR com.alibaba.druid.pool.DruidDataSource - create connection SQLException, url: jdbc:mysql://127.0.0.1:3306/bitrade?characterEncoding=utf-8, errorCode 0, state 08S01
com.mysql.jdbc.exceptions.jdbc4.CommunicationsException: Communications link failure

The last packet sent successfully to the server was 0 milliseconds ago. The driver has not received any packets from the server.
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at com.mysql.jdbc.Util.handleNewInstance(Util.java:377)
	at com.mysql.jdbc.SQLError.createCommunicationsException(SQLError.java:1036)
	at com.mysql.jdbc.MysqlIO.<init>(MysqlIO.java:338)
	at com.mysql.jdbc.ConnectionImpl.coreConnect(ConnectionImpl.java:2232)
	at com.mysql.jdbc.ConnectionImpl.connectOneTryOnly(ConnectionImpl.java:2265)
	at com.mysql.jdbc.ConnectionImpl.createNewIO(ConnectionImpl.java:2064)
	at com.mysql.jdbc.ConnectionImpl.<init>(ConnectionImpl.java:790)
	at com.mysql.jdbc.JDBC4Connection.<init>(JDBC4Connection.java:44)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at com.mysql.jdbc.Util.handleNewInstance(Util.java:377)
	at com.mysql.jdbc.ConnectionImpl.getInstance(ConnectionImpl.java:395)
	at com.mysql.jdbc.NonRegisteringDriver.connect(NonRegisteringDriver.java:325)
	at com.alibaba.druid.pool.DruidAbstractDataSource.createPhysicalConnection(DruidAbstractDataSource.java:1513)
	at com.alibaba.druid.pool.DruidAbstractDataSource.createPhysicalConnection(DruidAbstractDataSource.java:1578)
	at com.alibaba.druid.pool.DruidDataSource$CreateConnectionThread.run(DruidDataSource.java:2466)
Caused by: java.net.ConnectException: Connection refused: connect
	at java.net.DualStackPlainSocketImpl.connect0(Native Method)
	at java.net.DualStackPlainSocketImpl.socketConnect(DualStackPlainSocketImpl.java:79)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.PlainSocketImpl.connect(PlainSocketImpl.java:172)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:589)
	at com.mysql.jdbc.StandardSocketFactory.connect(StandardSocketFactory.java:213)
	at com.mysql.jdbc.MysqlIO.<init>(MysqlIO.java:297)
	... 15 common frames omitted
13:43:33.721 [Druid-ConnectionPool-Create-445202766] ERROR com.alibaba.druid.pool.DruidDataSource - create connection SQLException, url: jdbc:mysql://127.0.0.1:3306/bitrade?characterEncoding=utf-8, errorCode 0, state 08S01
com.mysql.jdbc.exceptions.jdbc4.CommunicationsException: Communications link failure

The last packet sent successfully to the server was 0 milliseconds ago. The driver has not received any packets from the server.
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at com.mysql.jdbc.Util.handleNewInstance(Util.java:377)
	at com.mysql.jdbc.SQLError.createCommunicationsException(SQLError.java:1036)
	at com.mysql.jdbc.MysqlIO.<init>(MysqlIO.java:338)
	at com.mysql.jdbc.ConnectionImpl.coreConnect(ConnectionImpl.java:2232)
	at com.mysql.jdbc.ConnectionImpl.connectOneTryOnly(ConnectionImpl.java:2265)
	at com.mysql.jdbc.ConnectionImpl.createNewIO(ConnectionImpl.java:2064)
	at com.mysql.jdbc.ConnectionImpl.<init>(ConnectionImpl.java:790)
	at com.mysql.jdbc.JDBC4Connection.<init>(JDBC4Connection.java:44)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at com.mysql.jdbc.Util.handleNewInstance(Util.java:377)
	at com.mysql.jdbc.ConnectionImpl.getInstance(ConnectionImpl.java:395)
	at com.mysql.jdbc.NonRegisteringDriver.connect(NonRegisteringDriver.java:325)
	at com.alibaba.druid.pool.DruidAbstractDataSource.createPhysicalConnection(DruidAbstractDataSource.java:1513)
	at com.alibaba.druid.pool.DruidAbstractDataSource.createPhysicalConnection(DruidAbstractDataSource.java:1578)
	at com.alibaba.druid.pool.DruidDataSource$CreateConnectionThread.run(DruidDataSource.java:2466)
Caused by: java.net.ConnectException: Connection refused: connect
	at java.net.DualStackPlainSocketImpl.connect0(Native Method)
	at java.net.DualStackPlainSocketImpl.socketConnect(DualStackPlainSocketImpl.java:79)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.PlainSocketImpl.connect(PlainSocketImpl.java:172)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:589)
	at com.mysql.jdbc.StandardSocketFactory.connect(StandardSocketFactory.java:213)
	at com.mysql.jdbc.MysqlIO.<init>(MysqlIO.java:297)
	... 15 common frames omitted
13:43:36.268 [Druid-ConnectionPool-Create-445202766] ERROR com.alibaba.druid.pool.DruidDataSource - create connection SQLException, url: jdbc:mysql://127.0.0.1:3306/bitrade?characterEncoding=utf-8, errorCode 0, state 08S01
com.mysql.jdbc.exceptions.jdbc4.CommunicationsException: Communications link failure

The last packet sent successfully to the server was 0 milliseconds ago. The driver has not received any packets from the server.
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at com.mysql.jdbc.Util.handleNewInstance(Util.java:377)
	at com.mysql.jdbc.SQLError.createCommunicationsException(SQLError.java:1036)
	at com.mysql.jdbc.MysqlIO.<init>(MysqlIO.java:338)
	at com.mysql.jdbc.ConnectionImpl.coreConnect(ConnectionImpl.java:2232)
	at com.mysql.jdbc.ConnectionImpl.connectOneTryOnly(ConnectionImpl.java:2265)
	at com.mysql.jdbc.ConnectionImpl.createNewIO(ConnectionImpl.java:2064)
	at com.mysql.jdbc.ConnectionImpl.<init>(ConnectionImpl.java:790)
	at com.mysql.jdbc.JDBC4Connection.<init>(JDBC4Connection.java:44)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at com.mysql.jdbc.Util.handleNewInstance(Util.java:377)
	at com.mysql.jdbc.ConnectionImpl.getInstance(ConnectionImpl.java:395)
	at com.mysql.jdbc.NonRegisteringDriver.connect(NonRegisteringDriver.java:325)
	at com.alibaba.druid.pool.DruidAbstractDataSource.createPhysicalConnection(DruidAbstractDataSource.java:1513)
	at com.alibaba.druid.pool.DruidAbstractDataSource.createPhysicalConnection(DruidAbstractDataSource.java:1578)
	at com.alibaba.druid.pool.DruidDataSource$CreateConnectionThread.run(DruidDataSource.java:2466)
Caused by: java.net.ConnectException: Connection refused: connect
	at java.net.DualStackPlainSocketImpl.connect0(Native Method)
	at java.net.DualStackPlainSocketImpl.socketConnect(DualStackPlainSocketImpl.java:79)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.PlainSocketImpl.connect(PlainSocketImpl.java:172)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:589)
	at com.mysql.jdbc.StandardSocketFactory.connect(StandardSocketFactory.java:213)
	at com.mysql.jdbc.MysqlIO.<init>(MysqlIO.java:297)
	... 15 common frames omitted
13:43:38.801 [Druid-ConnectionPool-Create-445202766] ERROR com.alibaba.druid.pool.DruidDataSource - create connection SQLException, url: jdbc:mysql://127.0.0.1:3306/bitrade?characterEncoding=utf-8, errorCode 0, state 08S01
com.mysql.jdbc.exceptions.jdbc4.CommunicationsException: Communications link failure

The last packet sent successfully to the server was 0 milliseconds ago. The driver has not received any packets from the server.
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at com.mysql.jdbc.Util.handleNewInstance(Util.java:377)
	at com.mysql.jdbc.SQLError.createCommunicationsException(SQLError.java:1036)
	at com.mysql.jdbc.MysqlIO.<init>(MysqlIO.java:338)
	at com.mysql.jdbc.ConnectionImpl.coreConnect(ConnectionImpl.java:2232)
	at com.mysql.jdbc.ConnectionImpl.connectOneTryOnly(ConnectionImpl.java:2265)
	at com.mysql.jdbc.ConnectionImpl.createNewIO(ConnectionImpl.java:2064)
	at com.mysql.jdbc.ConnectionImpl.<init>(ConnectionImpl.java:790)
	at com.mysql.jdbc.JDBC4Connection.<init>(JDBC4Connection.java:44)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at com.mysql.jdbc.Util.handleNewInstance(Util.java:377)
	at com.mysql.jdbc.ConnectionImpl.getInstance(ConnectionImpl.java:395)
	at com.mysql.jdbc.NonRegisteringDriver.connect(NonRegisteringDriver.java:325)
	at com.alibaba.druid.pool.DruidAbstractDataSource.createPhysicalConnection(DruidAbstractDataSource.java:1513)
	at com.alibaba.druid.pool.DruidAbstractDataSource.createPhysicalConnection(DruidAbstractDataSource.java:1578)
	at com.alibaba.druid.pool.DruidDataSource$CreateConnectionThread.run(DruidDataSource.java:2466)
Caused by: java.net.ConnectException: Connection refused: connect
	at java.net.DualStackPlainSocketImpl.connect0(Native Method)
	at java.net.DualStackPlainSocketImpl.socketConnect(DualStackPlainSocketImpl.java:79)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.PlainSocketImpl.connect(PlainSocketImpl.java:172)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:589)
	at com.mysql.jdbc.StandardSocketFactory.connect(StandardSocketFactory.java:213)
	at com.mysql.jdbc.MysqlIO.<init>(MysqlIO.java:297)
	... 15 common frames omitted
13:43:41.312 [Druid-ConnectionPool-Create-445202766] ERROR com.alibaba.druid.pool.DruidDataSource - create connection SQLException, url: jdbc:mysql://127.0.0.1:3306/bitrade?characterEncoding=utf-8, errorCode 0, state 08S01
com.mysql.jdbc.exceptions.jdbc4.CommunicationsException: Communications link failure

The last packet sent successfully to the server was 0 milliseconds ago. The driver has not received any packets from the server.
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at com.mysql.jdbc.Util.handleNewInstance(Util.java:377)
	at com.mysql.jdbc.SQLError.createCommunicationsException(SQLError.java:1036)
	at com.mysql.jdbc.MysqlIO.<init>(MysqlIO.java:338)
	at com.mysql.jdbc.ConnectionImpl.coreConnect(ConnectionImpl.java:2232)
	at com.mysql.jdbc.ConnectionImpl.connectOneTryOnly(ConnectionImpl.java:2265)
	at com.mysql.jdbc.ConnectionImpl.createNewIO(ConnectionImpl.java:2064)
	at com.mysql.jdbc.ConnectionImpl.<init>(ConnectionImpl.java:790)
	at com.mysql.jdbc.JDBC4Connection.<init>(JDBC4Connection.java:44)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at com.mysql.jdbc.Util.handleNewInstance(Util.java:377)
	at com.mysql.jdbc.ConnectionImpl.getInstance(ConnectionImpl.java:395)
	at com.mysql.jdbc.NonRegisteringDriver.connect(NonRegisteringDriver.java:325)
	at com.alibaba.druid.pool.DruidAbstractDataSource.createPhysicalConnection(DruidAbstractDataSource.java:1513)
	at com.alibaba.druid.pool.DruidAbstractDataSource.createPhysicalConnection(DruidAbstractDataSource.java:1578)
	at com.alibaba.druid.pool.DruidDataSource$CreateConnectionThread.run(DruidDataSource.java:2466)
Caused by: java.net.ConnectException: Connection refused: connect
	at java.net.DualStackPlainSocketImpl.connect0(Native Method)
	at java.net.DualStackPlainSocketImpl.socketConnect(DualStackPlainSocketImpl.java:79)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.PlainSocketImpl.connect(PlainSocketImpl.java:172)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:589)
	at com.mysql.jdbc.StandardSocketFactory.connect(StandardSocketFactory.java:213)
	at com.mysql.jdbc.MysqlIO.<init>(MysqlIO.java:297)
	... 15 common frames omitted
13:45:21.908 [main] INFO  o.s.c.a.AnnotationConfigApplicationContext - Refreshing org.springframework.context.annotation.AnnotationConfigApplicationContext@6bbe2511: startup date [Tue Sep 10 13:45:21 CST 2019]; root of context hierarchy
13:45:22.024 [background-preinit] INFO  org.hibernate.validator.internal.util.Version - HV000001: Hibernate Validator 5.3.6.Final
13:45:22.093 [main] INFO  o.s.b.f.a.AutowiredAnnotationBeanPostProcessor - JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
13:45:22.146 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'configurationPropertiesRebinderAutoConfiguration' of type [org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration$$EnhancerBySpringCGLIB$$d0c10e6f] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
13:45:22.679 [main] INFO  cn.ztuo.bitrade.MarketApplication - No active profile set, falling back to default profiles: default
13:45:22.695 [main] INFO  o.s.b.c.e.AnnotationConfigEmbeddedWebApplicationContext - Refreshing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@7ad54c55: startup date [Tue Sep 10 13:45:22 CST 2019]; parent: org.springframework.context.annotation.AnnotationConfigApplicationContext@6bbe2511
13:45:23.379 [main] INFO  o.s.b.factory.support.DefaultListableBeanFactory - Overriding bean definition for bean 'redisUtil' with a different definition: replacing [Generic bean: class [cn.ztuo.bitrade.util.RedisUtil]; scope=singleton; abstract=false; lazyInit=false; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=null; destroyMethodName=null; defined in file [F:\ztuo_v2\ztuo_framework\core\target\classes\cn\ztuo\bitrade\util\RedisUtil.class]] with [Root bean: class [null]; scope=; abstract=false; lazyInit=false; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=redisConfig; factoryMethodName=redisUtil; initMethodName=null; destroyMethodName=(inferred); defined in class path resource [cn/ztuo/bitrade/config/RedisConfig.class]]
13:45:23.530 [main] INFO  o.s.d.r.config.RepositoryConfigurationDelegate - Multiple Spring Data modules found, entering strict repository configuration mode!
13:45:23.821 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data JPA - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.OrderDetailAggregationRepository.
13:45:23.833 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data JPA - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.ExchangeOrderDetailRepository.
13:45:23.833 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data JPA - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.MemberLogDao.
13:45:23.884 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data JPA - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.TradeRepository.
13:45:23.894 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data JPA - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.ExchangeTradeRepository.
13:45:24.047 [main] INFO  o.s.d.r.config.RepositoryConfigurationDelegate - Multiple Spring Data modules found, entering strict repository configuration mode!
13:45:24.323 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.AdvertiseDao.
13:45:24.323 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.MemberPromotionDao.
13:45:24.323 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.ReleaseBalanceDao.
13:45:24.323 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.AdminDao.
13:45:24.323 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.MemberLevelDao.
13:45:24.323 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.OrderDao.
13:45:24.323 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.MemberSignRecordDao.
13:45:24.323 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.AppRevisionDao.
13:45:24.323 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.IntegrationRecordDao.
13:45:24.323 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.MemberApplicationConfigDao.
13:45:24.323 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.SysPermissionDao.
13:45:24.323 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.DataDictionaryDao.
13:45:24.323 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.HotTransferRecordDao.
13:45:24.323 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.MemberDepositDao.
13:45:24.331 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.CountryDao.
13:45:24.331 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.DividendStartRecordDao.
13:45:24.331 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.MemberBonusDao.
13:45:24.331 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.EmptionRecordDao.
13:45:24.331 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.SysHelpDao.
13:45:24.333 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.LossThresholdRepository.
13:45:24.333 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.PaymentHistoryRepository.
13:45:24.333 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.FeedbackDao.
13:45:24.333 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.RewardActivitySettingDao.
13:45:24.333 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.AnnouncementDao.
13:45:24.333 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.AdminAccessLogDao.
13:45:24.333 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.BusinessCancelApplyDao.
13:45:24.333 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.IeoEmptionDao.
13:45:24.333 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.AppealDao.
13:45:24.333 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.GiftConfigDao.
13:45:24.333 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.LockPositionRecordDao.
13:45:24.333 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.RiskRecordRepository.
13:45:24.333 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.RewardWalletDao.
13:45:24.333 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.RewardPromotionSettingDao.
13:45:24.333 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.LeverWalletTransferRecordRepository.
13:45:24.333 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.CoinDao.
13:45:24.333 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.MemberApiKeyDao.
13:45:24.333 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.MemberTransactionDao.
13:45:24.333 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.SignDao.
13:45:24.333 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.SmsDao.
13:45:24.333 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.PlatformTransactionDao.
13:45:24.333 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.LegalWalletWithdrawDao.
13:45:24.333 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.ExchangeOrderRepository.
13:45:24.333 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.LeverCoinRepository.
13:45:24.333 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.MemberDao.
13:45:24.333 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.InitPlateDao.
13:45:24.333 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.MemberAddressDao.
13:45:24.333 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.RobotTransactionDao.
13:45:24.333 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.MemberApplicationDao.
13:45:24.333 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.FavorSymbolRepository.
13:45:24.333 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.LoanRecordRepository.
13:45:24.333 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.MemberWalletDao.
13:45:24.333 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.OtcWalletDao.
13:45:24.333 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.DepositRecordDao.
13:45:24.341 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.PoundageConvertEthDao.
13:45:24.341 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.SysAdvertiseDao.
13:45:24.341 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.TransferAddressDao.
13:45:24.341 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.ExchangeCoinRepository.
13:45:24.341 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.SysRoleDao.
13:45:24.341 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.WebsiteInformationDao.
13:45:24.341 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.OtcCoinDao.
13:45:24.341 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.TransferRecordDao.
13:45:24.341 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.GiftRecordDao.
13:45:24.341 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.DepartmentDao.
13:45:24.341 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.BusinessAuthDepositDao.
13:45:24.343 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.AirdropDao.
13:45:24.343 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.LeverWalletRepository.
13:45:24.343 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.MemberGradeDao.
13:45:24.343 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.RewardRecordDao.
13:45:24.343 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.WithdrawRecordDao.
13:45:24.343 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.LegalWalletRechargeDao.
13:45:24.343 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.BusinessAuthApplyDao.
13:45:24.362 [main] INFO  o.s.d.r.config.RepositoryConfigurationDelegate - Multiple Spring Data modules found, entering strict repository configuration mode!
13:45:24.629 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.AdvertiseDao.
13:45:24.629 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.MemberPromotionDao.
13:45:24.629 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.ReleaseBalanceDao.
13:45:24.629 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.AdminDao.
13:45:24.629 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.MemberLevelDao.
13:45:24.629 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.OrderDao.
13:45:24.629 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.MemberSignRecordDao.
13:45:24.629 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.AppRevisionDao.
13:45:24.629 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.OrderDetailAggregationRepository.
13:45:24.629 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.IntegrationRecordDao.
13:45:24.629 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.MemberApplicationConfigDao.
13:45:24.629 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.SysPermissionDao.
13:45:24.629 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.ExchangeOrderDetailRepository.
13:45:24.629 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.DataDictionaryDao.
13:45:24.629 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.HotTransferRecordDao.
13:45:24.629 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.MemberDepositDao.
13:45:24.629 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.CountryDao.
13:45:24.629 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.DividendStartRecordDao.
13:45:24.629 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.MemberBonusDao.
13:45:24.629 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.MemberLogDao.
13:45:24.629 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.EmptionRecordDao.
13:45:24.629 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.SysHelpDao.
13:45:24.629 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.LossThresholdRepository.
13:45:24.637 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.PaymentHistoryRepository.
13:45:24.637 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.FeedbackDao.
13:45:24.637 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.RewardActivitySettingDao.
13:45:24.637 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.AnnouncementDao.
13:45:24.637 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.AdminAccessLogDao.
13:45:24.637 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.BusinessCancelApplyDao.
13:45:24.637 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.IeoEmptionDao.
13:45:24.637 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.AppealDao.
13:45:24.637 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.GiftConfigDao.
13:45:24.637 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.LockPositionRecordDao.
13:45:24.639 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.RiskRecordRepository.
13:45:24.639 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.RewardWalletDao.
13:45:24.639 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.RewardPromotionSettingDao.
13:45:24.639 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.LeverWalletTransferRecordRepository.
13:45:24.639 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.CoinDao.
13:45:24.639 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.MemberApiKeyDao.
13:45:24.639 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.MemberTransactionDao.
13:45:24.639 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.SignDao.
13:45:24.639 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.SmsDao.
13:45:24.639 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.PlatformTransactionDao.
13:45:24.639 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.LegalWalletWithdrawDao.
13:45:24.639 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.ExchangeOrderRepository.
13:45:24.639 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.LeverCoinRepository.
13:45:24.639 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.MemberDao.
13:45:24.639 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.InitPlateDao.
13:45:24.639 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.MemberAddressDao.
13:45:24.639 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.RobotTransactionDao.
13:45:24.639 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.MemberApplicationDao.
13:45:24.639 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.FavorSymbolRepository.
13:45:24.639 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.LoanRecordRepository.
13:45:24.639 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.MemberWalletDao.
13:45:24.639 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.OtcWalletDao.
13:45:24.639 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.DepositRecordDao.
13:45:24.639 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.PoundageConvertEthDao.
13:45:24.639 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.SysAdvertiseDao.
13:45:24.639 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.TransferAddressDao.
13:45:24.639 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.ExchangeCoinRepository.
13:45:24.639 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.SysRoleDao.
13:45:24.639 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.WebsiteInformationDao.
13:45:24.639 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.TradeRepository.
13:45:24.639 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.OtcCoinDao.
13:45:24.639 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.TransferRecordDao.
13:45:24.639 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.GiftRecordDao.
13:45:24.639 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.DepartmentDao.
13:45:24.639 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.BusinessAuthDepositDao.
13:45:24.639 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.AirdropDao.
13:45:24.639 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.LeverWalletRepository.
13:45:24.639 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.MemberGradeDao.
13:45:24.639 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.RewardRecordDao.
13:45:24.639 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.WithdrawRecordDao.
13:45:24.639 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.ExchangeTradeRepository.
13:45:24.639 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.LegalWalletRechargeDao.
13:45:24.639 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.BusinessAuthApplyDao.
13:45:24.829 [main] INFO  o.springframework.cloud.context.scope.GenericScope - BeanFactory id=30c01683-e1c5-3dbf-93ce-833db208f136
13:45:24.864 [main] INFO  o.s.b.f.a.AutowiredAnnotationBeanPostProcessor - JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
13:45:24.898 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'cn.ztuo.aqmd.HawkNettyConfiguration' of type [cn.ztuo.aqmd.HawkNettyConfiguration$$EnhancerBySpringCGLIB$$20d6dd48] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
13:45:24.898 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.kafka.annotation.KafkaBootstrapConfiguration' of type [org.springframework.kafka.annotation.KafkaBootstrapConfiguration$$EnhancerBySpringCGLIB$$88591cf5] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
13:45:24.961 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'loginUserService' of type [cn.ztuo.aqmd.service.DefaultLoginUserService] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
13:45:24.961 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'hawkServerRealm' of type [cn.ztuo.aqmd.netty.shiro.realm.HawkServerRealm] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
13:45:24.961 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'sessionIdGenerator' of type [cn.ztuo.aqmd.netty.shiro.SequenceSessionIdGenerator] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
13:45:24.977 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'sessionDAO' of type [org.apache.shiro.session.mgt.eis.EnterpriseCacheSessionDAO] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
13:45:24.977 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'sessionManager' of type [cn.ztuo.aqmd.netty.shiro.session.DefaultHawkSessionManager] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
13:45:24.999 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'spring.cache-org.springframework.boot.autoconfigure.cache.CacheProperties' of type [org.springframework.boot.autoconfigure.cache.CacheProperties] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
13:45:24.999 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.boot.autoconfigure.cache.CacheAutoConfiguration' of type [org.springframework.boot.autoconfigure.cache.CacheAutoConfiguration$$EnhancerBySpringCGLIB$$f22d0634] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
13:45:25.014 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'cacheManagerCustomizers' of type [org.springframework.boot.autoconfigure.cache.CacheManagerCustomizers] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
13:45:25.014 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.boot.autoconfigure.cache.EhCacheCacheConfiguration' of type [org.springframework.boot.autoconfigure.cache.EhCacheCacheConfiguration$$EnhancerBySpringCGLIB$$8ccbd332] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
13:45:25.099 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'ehCacheCacheManager' of type [net.sf.ehcache.CacheManager] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
13:45:25.099 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'cacheManager' of type [org.springframework.cache.ehcache.EhCacheCacheManager] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
13:45:25.099 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'springCacheManagerWrapper' of type [cn.ztuo.aqmd.netty.shiro.cache.SpringCacheManagerWrapper] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
13:45:25.115 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'hawkSubjectFactory' of type [cn.ztuo.aqmd.netty.shiro.mgt.DefaultHawkSubjectFactory] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
13:45:25.130 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'securityManager' of type [cn.ztuo.aqmd.netty.shiro.mgt.DefaultHawkSecurityManager] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
13:45:25.146 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'methodInvokingFactoryBean' of type [org.springframework.beans.factory.config.MethodInvokingFactoryBean] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
13:45:25.230 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration' of type [org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration$$EnhancerBySpringCGLIB$$b4a70b72] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
13:45:25.263 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.cache.annotation.ProxyCachingConfiguration' of type [org.springframework.cache.annotation.ProxyCachingConfiguration$$EnhancerBySpringCGLIB$$fdb94190] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
13:45:25.279 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'cacheAutoConfigurationValidator' of type [org.springframework.boot.autoconfigure.cache.CacheAutoConfiguration$CacheManagerValidator] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
13:45:25.315 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration' of type [org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration$$EnhancerBySpringCGLIB$$d0c10e6f] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
13:45:25.578 [main] INFO  o.s.b.c.e.tomcat.TomcatEmbeddedServletContainer - Tomcat initialized with port(s): 6004 (http)
13:45:25.594 [main] INFO  org.apache.catalina.core.StandardService - Starting service [Tomcat]
13:45:25.594 [main] INFO  org.apache.catalina.core.StandardEngine - Starting Servlet Engine: Apache Tomcat/8.5.23
13:45:25.716 [localhost-startStop-1] INFO  o.a.c.c.C.[Tomcat].[localhost].[/market] - Initializing Spring embedded WebApplicationContext
13:45:25.716 [localhost-startStop-1] INFO  org.springframework.web.context.ContextLoader - Root WebApplicationContext: initialization completed in 3021 ms
13:45:25.932 [localhost-startStop-1] INFO  o.s.boot.web.servlet.FilterRegistrationBean - Mapping filter: 'characterEncodingFilter' to: [/*]
13:45:25.932 [localhost-startStop-1] INFO  o.s.boot.web.servlet.FilterRegistrationBean - Mapping filter: 'hiddenHttpMethodFilter' to: [/*]
13:45:25.932 [localhost-startStop-1] INFO  o.s.boot.web.servlet.FilterRegistrationBean - Mapping filter: 'httpPutFormContentFilter' to: [/*]
13:45:25.932 [localhost-startStop-1] INFO  o.s.boot.web.servlet.FilterRegistrationBean - Mapping filter: 'requestContextFilter' to: [/*]
13:45:25.932 [localhost-startStop-1] INFO  o.s.boot.web.servlet.FilterRegistrationBean - Mapping filter: 'corsFilter' to: [/*]
13:45:25.932 [localhost-startStop-1] INFO  o.s.boot.web.servlet.ServletRegistrationBean - Mapping servlet: 'dispatcherServlet' to [/]
13:45:26.302 [main] INFO  com.alibaba.druid.pool.DruidDataSource - {dataSource-1} inited
13:45:28.378 [Druid-ConnectionPool-Create-911998047] ERROR com.alibaba.druid.pool.DruidDataSource - create connection SQLException, url: jdbc:mysql://127.0.0.1:3306/test?characterEncoding=utf-8&serverTimezone=GMT%2B8, errorCode 0, state 08S01
com.mysql.jdbc.exceptions.jdbc4.CommunicationsException: Communications link failure

The last packet sent successfully to the server was 0 milliseconds ago. The driver has not received any packets from the server.
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at com.mysql.jdbc.Util.handleNewInstance(Util.java:377)
	at com.mysql.jdbc.SQLError.createCommunicationsException(SQLError.java:1036)
	at com.mysql.jdbc.MysqlIO.<init>(MysqlIO.java:338)
	at com.mysql.jdbc.ConnectionImpl.coreConnect(ConnectionImpl.java:2232)
	at com.mysql.jdbc.ConnectionImpl.connectOneTryOnly(ConnectionImpl.java:2265)
	at com.mysql.jdbc.ConnectionImpl.createNewIO(ConnectionImpl.java:2064)
	at com.mysql.jdbc.ConnectionImpl.<init>(ConnectionImpl.java:790)
	at com.mysql.jdbc.JDBC4Connection.<init>(JDBC4Connection.java:44)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at com.mysql.jdbc.Util.handleNewInstance(Util.java:377)
	at com.mysql.jdbc.ConnectionImpl.getInstance(ConnectionImpl.java:395)
	at com.mysql.jdbc.NonRegisteringDriver.connect(NonRegisteringDriver.java:325)
	at com.alibaba.druid.pool.DruidAbstractDataSource.createPhysicalConnection(DruidAbstractDataSource.java:1513)
	at com.alibaba.druid.pool.DruidAbstractDataSource.createPhysicalConnection(DruidAbstractDataSource.java:1578)
	at com.alibaba.druid.pool.DruidDataSource$CreateConnectionThread.run(DruidDataSource.java:2466)
Caused by: java.net.ConnectException: Connection refused: connect
	at java.net.DualStackPlainSocketImpl.connect0(Native Method)
	at java.net.DualStackPlainSocketImpl.socketConnect(DualStackPlainSocketImpl.java:79)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.PlainSocketImpl.connect(PlainSocketImpl.java:172)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:589)
	at com.mysql.jdbc.StandardSocketFactory.connect(StandardSocketFactory.java:213)
	at com.mysql.jdbc.MysqlIO.<init>(MysqlIO.java:297)
	... 15 common frames omitted
13:45:30.403 [Druid-ConnectionPool-Create-911998047] ERROR com.alibaba.druid.pool.DruidDataSource - create connection SQLException, url: jdbc:mysql://127.0.0.1:3306/test?characterEncoding=utf-8&serverTimezone=GMT%2B8, errorCode 0, state 08S01
com.mysql.jdbc.exceptions.jdbc4.CommunicationsException: Communications link failure

The last packet sent successfully to the server was 0 milliseconds ago. The driver has not received any packets from the server.
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at com.mysql.jdbc.Util.handleNewInstance(Util.java:377)
	at com.mysql.jdbc.SQLError.createCommunicationsException(SQLError.java:1036)
	at com.mysql.jdbc.MysqlIO.<init>(MysqlIO.java:338)
	at com.mysql.jdbc.ConnectionImpl.coreConnect(ConnectionImpl.java:2232)
	at com.mysql.jdbc.ConnectionImpl.connectOneTryOnly(ConnectionImpl.java:2265)
	at com.mysql.jdbc.ConnectionImpl.createNewIO(ConnectionImpl.java:2064)
	at com.mysql.jdbc.ConnectionImpl.<init>(ConnectionImpl.java:790)
	at com.mysql.jdbc.JDBC4Connection.<init>(JDBC4Connection.java:44)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at com.mysql.jdbc.Util.handleNewInstance(Util.java:377)
	at com.mysql.jdbc.ConnectionImpl.getInstance(ConnectionImpl.java:395)
	at com.mysql.jdbc.NonRegisteringDriver.connect(NonRegisteringDriver.java:325)
	at com.alibaba.druid.pool.DruidAbstractDataSource.createPhysicalConnection(DruidAbstractDataSource.java:1513)
	at com.alibaba.druid.pool.DruidAbstractDataSource.createPhysicalConnection(DruidAbstractDataSource.java:1578)
	at com.alibaba.druid.pool.DruidDataSource$CreateConnectionThread.run(DruidDataSource.java:2466)
Caused by: java.net.ConnectException: Connection refused: connect
	at java.net.DualStackPlainSocketImpl.connect0(Native Method)
	at java.net.DualStackPlainSocketImpl.socketConnect(DualStackPlainSocketImpl.java:79)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.PlainSocketImpl.connect(PlainSocketImpl.java:172)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:589)
	at com.mysql.jdbc.StandardSocketFactory.connect(StandardSocketFactory.java:213)
	at com.mysql.jdbc.MysqlIO.<init>(MysqlIO.java:297)
	... 15 common frames omitted
13:45:32.930 [Druid-ConnectionPool-Create-911998047] ERROR com.alibaba.druid.pool.DruidDataSource - create connection SQLException, url: jdbc:mysql://127.0.0.1:3306/test?characterEncoding=utf-8&serverTimezone=GMT%2B8, errorCode 0, state 08S01
com.mysql.jdbc.exceptions.jdbc4.CommunicationsException: Communications link failure

The last packet sent successfully to the server was 0 milliseconds ago. The driver has not received any packets from the server.
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at com.mysql.jdbc.Util.handleNewInstance(Util.java:377)
	at com.mysql.jdbc.SQLError.createCommunicationsException(SQLError.java:1036)
	at com.mysql.jdbc.MysqlIO.<init>(MysqlIO.java:338)
	at com.mysql.jdbc.ConnectionImpl.coreConnect(ConnectionImpl.java:2232)
	at com.mysql.jdbc.ConnectionImpl.connectOneTryOnly(ConnectionImpl.java:2265)
	at com.mysql.jdbc.ConnectionImpl.createNewIO(ConnectionImpl.java:2064)
	at com.mysql.jdbc.ConnectionImpl.<init>(ConnectionImpl.java:790)
	at com.mysql.jdbc.JDBC4Connection.<init>(JDBC4Connection.java:44)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at com.mysql.jdbc.Util.handleNewInstance(Util.java:377)
	at com.mysql.jdbc.ConnectionImpl.getInstance(ConnectionImpl.java:395)
	at com.mysql.jdbc.NonRegisteringDriver.connect(NonRegisteringDriver.java:325)
	at com.alibaba.druid.pool.DruidAbstractDataSource.createPhysicalConnection(DruidAbstractDataSource.java:1513)
	at com.alibaba.druid.pool.DruidAbstractDataSource.createPhysicalConnection(DruidAbstractDataSource.java:1578)
	at com.alibaba.druid.pool.DruidDataSource$CreateConnectionThread.run(DruidDataSource.java:2466)
Caused by: java.net.ConnectException: Connection refused: connect
	at java.net.DualStackPlainSocketImpl.connect0(Native Method)
	at java.net.DualStackPlainSocketImpl.socketConnect(DualStackPlainSocketImpl.java:79)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.PlainSocketImpl.connect(PlainSocketImpl.java:172)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:589)
	at com.mysql.jdbc.StandardSocketFactory.connect(StandardSocketFactory.java:213)
	at com.mysql.jdbc.MysqlIO.<init>(MysqlIO.java:297)
	... 15 common frames omitted
13:45:35.464 [Druid-ConnectionPool-Create-911998047] ERROR com.alibaba.druid.pool.DruidDataSource - create connection SQLException, url: jdbc:mysql://127.0.0.1:3306/test?characterEncoding=utf-8&serverTimezone=GMT%2B8, errorCode 0, state 08S01
com.mysql.jdbc.exceptions.jdbc4.CommunicationsException: Communications link failure

The last packet sent successfully to the server was 0 milliseconds ago. The driver has not received any packets from the server.
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at com.mysql.jdbc.Util.handleNewInstance(Util.java:377)
	at com.mysql.jdbc.SQLError.createCommunicationsException(SQLError.java:1036)
	at com.mysql.jdbc.MysqlIO.<init>(MysqlIO.java:338)
	at com.mysql.jdbc.ConnectionImpl.coreConnect(ConnectionImpl.java:2232)
	at com.mysql.jdbc.ConnectionImpl.connectOneTryOnly(ConnectionImpl.java:2265)
	at com.mysql.jdbc.ConnectionImpl.createNewIO(ConnectionImpl.java:2064)
	at com.mysql.jdbc.ConnectionImpl.<init>(ConnectionImpl.java:790)
	at com.mysql.jdbc.JDBC4Connection.<init>(JDBC4Connection.java:44)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at com.mysql.jdbc.Util.handleNewInstance(Util.java:377)
	at com.mysql.jdbc.ConnectionImpl.getInstance(ConnectionImpl.java:395)
	at com.mysql.jdbc.NonRegisteringDriver.connect(NonRegisteringDriver.java:325)
	at com.alibaba.druid.pool.DruidAbstractDataSource.createPhysicalConnection(DruidAbstractDataSource.java:1513)
	at com.alibaba.druid.pool.DruidAbstractDataSource.createPhysicalConnection(DruidAbstractDataSource.java:1578)
	at com.alibaba.druid.pool.DruidDataSource$CreateConnectionThread.run(DruidDataSource.java:2466)
Caused by: java.net.ConnectException: Connection refused: connect
	at java.net.DualStackPlainSocketImpl.connect0(Native Method)
	at java.net.DualStackPlainSocketImpl.socketConnect(DualStackPlainSocketImpl.java:79)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.PlainSocketImpl.connect(PlainSocketImpl.java:172)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:589)
	at com.mysql.jdbc.StandardSocketFactory.connect(StandardSocketFactory.java:213)
	at com.mysql.jdbc.MysqlIO.<init>(MysqlIO.java:297)
	... 15 common frames omitted
13:46:36.474 [main] INFO  o.s.c.a.AnnotationConfigApplicationContext - Refreshing org.springframework.context.annotation.AnnotationConfigApplicationContext@6bbe2511: startup date [Tue Sep 10 13:46:36 CST 2019]; root of context hierarchy
13:46:36.595 [background-preinit] INFO  org.hibernate.validator.internal.util.Version - HV000001: Hibernate Validator 5.3.6.Final
13:46:36.676 [main] INFO  o.s.b.f.a.AutowiredAnnotationBeanPostProcessor - JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
13:46:36.727 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'configurationPropertiesRebinderAutoConfiguration' of type [org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration$$EnhancerBySpringCGLIB$$d0c10e6f] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
13:46:37.260 [main] INFO  cn.ztuo.bitrade.MarketApplication - No active profile set, falling back to default profiles: default
13:46:37.276 [main] INFO  o.s.b.c.e.AnnotationConfigEmbeddedWebApplicationContext - Refreshing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@7ad54c55: startup date [Tue Sep 10 13:46:37 CST 2019]; parent: org.springframework.context.annotation.AnnotationConfigApplicationContext@6bbe2511
13:46:37.946 [main] INFO  o.s.b.factory.support.DefaultListableBeanFactory - Overriding bean definition for bean 'redisUtil' with a different definition: replacing [Generic bean: class [cn.ztuo.bitrade.util.RedisUtil]; scope=singleton; abstract=false; lazyInit=false; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=null; destroyMethodName=null; defined in file [F:\ztuo_v2\ztuo_framework\core\target\classes\cn\ztuo\bitrade\util\RedisUtil.class]] with [Root bean: class [null]; scope=; abstract=false; lazyInit=false; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=redisConfig; factoryMethodName=redisUtil; initMethodName=null; destroyMethodName=(inferred); defined in class path resource [cn/ztuo/bitrade/config/RedisConfig.class]]
13:46:38.109 [main] INFO  o.s.d.r.config.RepositoryConfigurationDelegate - Multiple Spring Data modules found, entering strict repository configuration mode!
13:46:38.402 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data JPA - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.OrderDetailAggregationRepository.
13:46:38.402 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data JPA - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.ExchangeOrderDetailRepository.
13:46:38.412 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data JPA - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.MemberLogDao.
13:46:38.452 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data JPA - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.TradeRepository.
13:46:38.463 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data JPA - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.ExchangeTradeRepository.
13:46:38.615 [main] INFO  o.s.d.r.config.RepositoryConfigurationDelegate - Multiple Spring Data modules found, entering strict repository configuration mode!
13:46:38.887 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.AdvertiseDao.
13:46:38.887 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.MemberPromotionDao.
13:46:38.887 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.ReleaseBalanceDao.
13:46:38.896 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.AdminDao.
13:46:38.896 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.MemberLevelDao.
13:46:38.896 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.OrderDao.
13:46:38.896 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.MemberSignRecordDao.
13:46:38.896 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.AppRevisionDao.
13:46:38.896 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.IntegrationRecordDao.
13:46:38.896 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.MemberApplicationConfigDao.
13:46:38.898 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.SysPermissionDao.
13:46:38.898 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.DataDictionaryDao.
13:46:38.898 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.HotTransferRecordDao.
13:46:38.898 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.MemberDepositDao.
13:46:38.898 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.CountryDao.
13:46:38.898 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.DividendStartRecordDao.
13:46:38.898 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.MemberBonusDao.
13:46:38.898 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.EmptionRecordDao.
13:46:38.898 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.SysHelpDao.
13:46:38.898 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.LossThresholdRepository.
13:46:38.898 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.PaymentHistoryRepository.
13:46:38.898 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.FeedbackDao.
13:46:38.898 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.RewardActivitySettingDao.
13:46:38.898 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.AnnouncementDao.
13:46:38.898 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.AdminAccessLogDao.
13:46:38.898 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.BusinessCancelApplyDao.
13:46:38.898 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.IeoEmptionDao.
13:46:38.898 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.AppealDao.
13:46:38.898 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.GiftConfigDao.
13:46:38.898 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.LockPositionRecordDao.
13:46:38.898 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.RiskRecordRepository.
13:46:38.898 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.RewardWalletDao.
13:46:38.898 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.RewardPromotionSettingDao.
13:46:38.898 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.LeverWalletTransferRecordRepository.
13:46:38.898 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.CoinDao.
13:46:38.898 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.MemberApiKeyDao.
13:46:38.898 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.MemberTransactionDao.
13:46:38.898 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.SignDao.
13:46:38.898 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.SmsDao.
13:46:38.898 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.PlatformTransactionDao.
13:46:38.898 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.LegalWalletWithdrawDao.
13:46:38.898 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.ExchangeOrderRepository.
13:46:38.898 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.LeverCoinRepository.
13:46:38.898 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.MemberDao.
13:46:38.898 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.InitPlateDao.
13:46:38.898 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.MemberAddressDao.
13:46:38.898 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.RobotTransactionDao.
13:46:38.898 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.MemberApplicationDao.
13:46:38.906 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.FavorSymbolRepository.
13:46:38.906 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.LoanRecordRepository.
13:46:38.906 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.MemberWalletDao.
13:46:38.906 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.OtcWalletDao.
13:46:38.906 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.DepositRecordDao.
13:46:38.906 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.PoundageConvertEthDao.
13:46:38.906 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.SysAdvertiseDao.
13:46:38.906 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.TransferAddressDao.
13:46:38.906 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.ExchangeCoinRepository.
13:46:38.908 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.SysRoleDao.
13:46:38.908 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.WebsiteInformationDao.
13:46:38.908 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.OtcCoinDao.
13:46:38.908 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.TransferRecordDao.
13:46:38.908 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.GiftRecordDao.
13:46:38.908 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.DepartmentDao.
13:46:38.908 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.BusinessAuthDepositDao.
13:46:38.908 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.AirdropDao.
13:46:38.908 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.LeverWalletRepository.
13:46:38.908 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.MemberGradeDao.
13:46:38.908 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.RewardRecordDao.
13:46:38.908 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.WithdrawRecordDao.
13:46:38.908 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.LegalWalletRechargeDao.
13:46:38.908 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.BusinessAuthApplyDao.
13:46:38.926 [main] INFO  o.s.d.r.config.RepositoryConfigurationDelegate - Multiple Spring Data modules found, entering strict repository configuration mode!
13:46:39.182 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.AdvertiseDao.
13:46:39.182 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.MemberPromotionDao.
13:46:39.182 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.ReleaseBalanceDao.
13:46:39.182 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.AdminDao.
13:46:39.182 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.MemberLevelDao.
13:46:39.182 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.OrderDao.
13:46:39.182 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.MemberSignRecordDao.
13:46:39.182 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.AppRevisionDao.
13:46:39.182 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.OrderDetailAggregationRepository.
13:46:39.182 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.IntegrationRecordDao.
13:46:39.182 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.MemberApplicationConfigDao.
13:46:39.182 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.SysPermissionDao.
13:46:39.182 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.ExchangeOrderDetailRepository.
13:46:39.182 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.DataDictionaryDao.
13:46:39.190 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.HotTransferRecordDao.
13:46:39.190 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.MemberDepositDao.
13:46:39.190 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.CountryDao.
13:46:39.190 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.DividendStartRecordDao.
13:46:39.190 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.MemberBonusDao.
13:46:39.190 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.MemberLogDao.
13:46:39.190 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.EmptionRecordDao.
13:46:39.190 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.SysHelpDao.
13:46:39.190 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.LossThresholdRepository.
13:46:39.190 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.PaymentHistoryRepository.
13:46:39.190 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.FeedbackDao.
13:46:39.192 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.RewardActivitySettingDao.
13:46:39.192 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.AnnouncementDao.
13:46:39.192 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.AdminAccessLogDao.
13:46:39.192 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.BusinessCancelApplyDao.
13:46:39.192 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.IeoEmptionDao.
13:46:39.192 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.AppealDao.
13:46:39.192 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.GiftConfigDao.
13:46:39.192 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.LockPositionRecordDao.
13:46:39.192 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.RiskRecordRepository.
13:46:39.192 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.RewardWalletDao.
13:46:39.192 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.RewardPromotionSettingDao.
13:46:39.192 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.LeverWalletTransferRecordRepository.
13:46:39.192 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.CoinDao.
13:46:39.192 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.MemberApiKeyDao.
13:46:39.192 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.MemberTransactionDao.
13:46:39.192 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.SignDao.
13:46:39.192 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.SmsDao.
13:46:39.192 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.PlatformTransactionDao.
13:46:39.192 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.LegalWalletWithdrawDao.
13:46:39.192 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.ExchangeOrderRepository.
13:46:39.192 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.LeverCoinRepository.
13:46:39.192 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.MemberDao.
13:46:39.192 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.InitPlateDao.
13:46:39.192 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.MemberAddressDao.
13:46:39.192 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.RobotTransactionDao.
13:46:39.192 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.MemberApplicationDao.
13:46:39.192 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.FavorSymbolRepository.
13:46:39.192 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.LoanRecordRepository.
13:46:39.192 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.MemberWalletDao.
13:46:39.192 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.OtcWalletDao.
13:46:39.192 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.DepositRecordDao.
13:46:39.192 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.PoundageConvertEthDao.
13:46:39.192 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.SysAdvertiseDao.
13:46:39.192 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.TransferAddressDao.
13:46:39.192 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.ExchangeCoinRepository.
13:46:39.192 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.SysRoleDao.
13:46:39.192 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.WebsiteInformationDao.
13:46:39.192 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.TradeRepository.
13:46:39.192 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.OtcCoinDao.
13:46:39.192 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.TransferRecordDao.
13:46:39.192 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.GiftRecordDao.
13:46:39.192 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.DepartmentDao.
13:46:39.192 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.BusinessAuthDepositDao.
13:46:39.192 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.AirdropDao.
13:46:39.200 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.LeverWalletRepository.
13:46:39.200 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.MemberGradeDao.
13:46:39.200 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.RewardRecordDao.
13:46:39.200 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.WithdrawRecordDao.
13:46:39.200 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.ExchangeTradeRepository.
13:46:39.200 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.LegalWalletRechargeDao.
13:46:39.200 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.BusinessAuthApplyDao.
13:46:39.382 [main] INFO  o.springframework.cloud.context.scope.GenericScope - BeanFactory id=30c01683-e1c5-3dbf-93ce-833db208f136
13:46:39.411 [main] INFO  o.s.b.f.a.AutowiredAnnotationBeanPostProcessor - JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
13:46:39.451 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'cn.ztuo.aqmd.HawkNettyConfiguration' of type [cn.ztuo.aqmd.HawkNettyConfiguration$$EnhancerBySpringCGLIB$$20d6dd48] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
13:46:39.451 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.kafka.annotation.KafkaBootstrapConfiguration' of type [org.springframework.kafka.annotation.KafkaBootstrapConfiguration$$EnhancerBySpringCGLIB$$88591cf5] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
13:46:39.498 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'loginUserService' of type [cn.ztuo.aqmd.service.DefaultLoginUserService] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
13:46:39.498 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'hawkServerRealm' of type [cn.ztuo.aqmd.netty.shiro.realm.HawkServerRealm] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
13:46:39.513 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'sessionIdGenerator' of type [cn.ztuo.aqmd.netty.shiro.SequenceSessionIdGenerator] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
13:46:39.513 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'sessionDAO' of type [org.apache.shiro.session.mgt.eis.EnterpriseCacheSessionDAO] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
13:46:39.532 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'sessionManager' of type [cn.ztuo.aqmd.netty.shiro.session.DefaultHawkSessionManager] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
13:46:39.544 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'spring.cache-org.springframework.boot.autoconfigure.cache.CacheProperties' of type [org.springframework.boot.autoconfigure.cache.CacheProperties] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
13:46:39.554 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.boot.autoconfigure.cache.CacheAutoConfiguration' of type [org.springframework.boot.autoconfigure.cache.CacheAutoConfiguration$$EnhancerBySpringCGLIB$$f22d0634] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
13:46:39.554 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'cacheManagerCustomizers' of type [org.springframework.boot.autoconfigure.cache.CacheManagerCustomizers] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
13:46:39.564 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.boot.autoconfigure.cache.EhCacheCacheConfiguration' of type [org.springframework.boot.autoconfigure.cache.EhCacheCacheConfiguration$$EnhancerBySpringCGLIB$$8ccbd332] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
13:46:39.656 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'ehCacheCacheManager' of type [net.sf.ehcache.CacheManager] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
13:46:39.664 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'cacheManager' of type [org.springframework.cache.ehcache.EhCacheCacheManager] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
13:46:39.664 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'springCacheManagerWrapper' of type [cn.ztuo.aqmd.netty.shiro.cache.SpringCacheManagerWrapper] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
13:46:39.676 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'hawkSubjectFactory' of type [cn.ztuo.aqmd.netty.shiro.mgt.DefaultHawkSubjectFactory] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
13:46:39.694 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'securityManager' of type [cn.ztuo.aqmd.netty.shiro.mgt.DefaultHawkSecurityManager] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
13:46:39.706 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'methodInvokingFactoryBean' of type [org.springframework.beans.factory.config.MethodInvokingFactoryBean] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
13:46:39.795 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration' of type [org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration$$EnhancerBySpringCGLIB$$b4a70b72] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
13:46:39.828 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.cache.annotation.ProxyCachingConfiguration' of type [org.springframework.cache.annotation.ProxyCachingConfiguration$$EnhancerBySpringCGLIB$$fdb94190] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
13:46:39.838 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'cacheAutoConfigurationValidator' of type [org.springframework.boot.autoconfigure.cache.CacheAutoConfiguration$CacheManagerValidator] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
13:46:39.868 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration' of type [org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration$$EnhancerBySpringCGLIB$$d0c10e6f] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
13:46:40.140 [main] INFO  o.s.b.c.e.tomcat.TomcatEmbeddedServletContainer - Tomcat initialized with port(s): 6004 (http)
13:46:40.150 [main] INFO  org.apache.catalina.core.StandardService - Starting service [Tomcat]
13:46:40.152 [main] INFO  org.apache.catalina.core.StandardEngine - Starting Servlet Engine: Apache Tomcat/8.5.23
13:46:40.270 [localhost-startStop-1] INFO  o.a.c.c.C.[Tomcat].[localhost].[/market] - Initializing Spring embedded WebApplicationContext
13:46:40.270 [localhost-startStop-1] INFO  org.springframework.web.context.ContextLoader - Root WebApplicationContext: initialization completed in 2994 ms
13:46:40.486 [localhost-startStop-1] INFO  o.s.boot.web.servlet.FilterRegistrationBean - Mapping filter: 'characterEncodingFilter' to: [/*]
13:46:40.486 [localhost-startStop-1] INFO  o.s.boot.web.servlet.FilterRegistrationBean - Mapping filter: 'hiddenHttpMethodFilter' to: [/*]
13:46:40.486 [localhost-startStop-1] INFO  o.s.boot.web.servlet.FilterRegistrationBean - Mapping filter: 'httpPutFormContentFilter' to: [/*]
13:46:40.486 [localhost-startStop-1] INFO  o.s.boot.web.servlet.FilterRegistrationBean - Mapping filter: 'requestContextFilter' to: [/*]
13:46:40.486 [localhost-startStop-1] INFO  o.s.boot.web.servlet.FilterRegistrationBean - Mapping filter: 'corsFilter' to: [/*]
13:46:40.486 [localhost-startStop-1] INFO  o.s.boot.web.servlet.ServletRegistrationBean - Mapping servlet: 'dispatcherServlet' to [/]
13:46:40.871 [main] INFO  com.alibaba.druid.pool.DruidDataSource - {dataSource-1} inited
13:46:41.153 [main] INFO  o.s.orm.jpa.LocalContainerEntityManagerFactoryBean - Building JPA container EntityManagerFactory for persistence unit 'default'
13:46:41.153 [main] INFO  org.hibernate.jpa.internal.util.LogHelper - HHH000204: Processing PersistenceUnitInfo [
	name: default
	...]
13:46:41.222 [main] INFO  org.hibernate.Version - HHH000412: Hibernate Core {5.0.12.Final}
13:46:41.222 [main] INFO  org.hibernate.cfg.Environment - HHH000206: hibernate.properties not found
13:46:41.224 [main] INFO  org.hibernate.cfg.Environment - HHH000021: Bytecode provider name : javassist
13:46:41.263 [main] INFO  org.hibernate.annotations.common.Version - HCANN000001: Hibernate Commons Annotations {5.0.1.Final}
13:46:41.415 [main] INFO  org.hibernate.dialect.Dialect - HHH000400: Using dialect: org.hibernate.dialect.MySQL5Dialect
13:46:41.997 [main] INFO  org.hibernate.tuple.PojoInstantiator - HHH000182: No default (no-argument) constructor for class: cn.ztuo.bitrade.entity.RiskRecord (class must be instantiated by Interceptor)
13:46:42.329 [main] INFO  o.s.orm.jpa.LocalContainerEntityManagerFactoryBean - Initialized JPA EntityManagerFactory for persistence unit 'default'
13:46:42.897 [main] INFO  org.mongodb.driver.cluster - Cluster created with settings {hosts=[localhost:27017], mode=SINGLE, requiredClusterType=UNKNOWN, serverSelectionTimeout='30000 ms', maxWaitQueueSize=500}
13:46:43.028 [main] WARN  o.s.data.mongodb.core.convert.CustomConversions - Registering converter from class java.math.BigDecimal to class org.bson.types.Decimal128 as reading converter although it doesn't convert from a Mongo supported type! You might wanna check you annotation setup at the converter implementation.
13:46:43.028 [main] WARN  o.s.data.mongodb.core.convert.CustomConversions - Registering converter from class org.bson.types.Decimal128 to class java.math.BigDecimal as writing converter although it doesn't convert to a Mongo supported type! You might wanna check you annotation setup at the converter implementation.
13:46:43.044 [cluster-ClusterId{value='5d7738c231d7591f58312c57', description='null'}-localhost:27017] INFO  org.mongodb.driver.connection - Opened connection [connectionId{localValue:1, serverValue:1}] to localhost:27017
13:46:43.047 [cluster-ClusterId{value='5d7738c231d7591f58312c57', description='null'}-localhost:27017] INFO  org.mongodb.driver.cluster - Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, version=ServerVersion{versionList=[3, 6, 3]}, minWireVersion=0, maxWireVersion=6, maxDocumentSize=16777216, roundTripTimeNanos=625900}
13:46:43.266 [main] INFO  o.s.scheduling.concurrent.ThreadPoolTaskExecutor - Initializing ExecutorService  'clientInboundChannelExecutor'
13:46:43.282 [main] INFO  o.s.scheduling.concurrent.ThreadPoolTaskExecutor - Initializing ExecutorService  'clientOutboundChannelExecutor'
13:46:43.313 [main] INFO  cn.ztuo.aqmd.core.context.HawkContext - 注册指令20021#1
13:46:43.313 [main] INFO  cn.ztuo.aqmd.core.context.HawkContext - 注册指令20002#1
13:46:43.313 [main] INFO  cn.ztuo.aqmd.core.context.HawkContext - 注册指令20001#1
13:46:43.313 [main] INFO  cn.ztuo.aqmd.core.context.HawkContext - 注册指令20022#1
13:46:43.752 [main] INFO  o.h.hql.internal.QueryTranslatorFactoryInitiator - HHH000397: Using ASTQueryTranslatorFactory
13:46:44.053 [main] INFO  cn.ztuo.bitrade.config.ProcessorConfig - ====initialized CoinProcessorFactory start==================================
13:46:44.454 [main] INFO  cn.ztuo.bitrade.config.ProcessorConfig - exchange-coin result:[ExchangeCoin(symbol=BTC/USDT, coinSymbol=BTC, baseSymbol=USDT, enable=1, fee=0.0010, baseFee=null, sort=0, coinScale=8, baseCoinScale=8, minSellPrice=0E-8, enableMarketSell=IS_TRUE, enableMarketBuy=IS_TRUE, maxTradingTime=0, maxTradingOrder=0, flag=0, minTurnover=0E-8, zone=0, minVolume=0E-8, maxVolume=0E-8, defaultSymbol=0)]
13:46:44.454 [main] INFO  cn.ztuo.bitrade.processor.CoinProcessorFactory - CoinProcessorFactory addProcessor = BTC/USDT
13:46:44.454 [main] INFO  cn.ztuo.bitrade.config.ProcessorConfig - ====initialized CoinProcessorFactory completed====
13:46:44.454 [main] INFO  cn.ztuo.bitrade.config.ProcessorConfig - CoinProcessorFactory = 
13:46:44.955 [main] INFO  cn.ztuo.bitrade.config.WaitingOrderConfig - init waiting order factory,symbol=BTC/USDT
13:46:44.955 [main] INFO  cn.ztuo.bitrade.waiting.WaitingOrder - init waiting for symbol BTC/USDT
13:46:44.955 [main] INFO  cn.ztuo.bitrade.config.WaitingOrderConfig - 初始化结束=WaitingOrder(symbol=BTC/USDT, buyTriggerPriceQueue={}, sellTriggerPriceQueue={}, ready=false)
13:46:46.203 [main] INFO  o.s.scheduling.concurrent.ThreadPoolTaskScheduler - Initializing ExecutorService  'messageBrokerTaskScheduler'
13:46:46.233 [main] INFO  o.s.w.s.server.support.WebSocketHandlerMapping - Mapped URL path [/market-ws/**] onto handler of type [class org.springframework.web.socket.sockjs.support.SockJsHttpRequestHandler]
13:46:46.259 [main] INFO  o.s.scheduling.concurrent.ThreadPoolTaskExecutor - Initializing ExecutorService  'brokerChannelExecutor'
13:46:46.435 [main] INFO  org.mongodb.driver.cluster - Cluster created with settings {hosts=[localhost:27017], mode=SINGLE, requiredClusterType=UNKNOWN, serverSelectionTimeout='30000 ms', maxWaitQueueSize=500}
13:46:46.459 [cluster-ClusterId{value='5d7738c631d7591f58312c58', description='null'}-localhost:27017] INFO  org.mongodb.driver.connection - Opened connection [connectionId{localValue:2, serverValue:2}] to localhost:27017
13:46:46.459 [cluster-ClusterId{value='5d7738c631d7591f58312c58', description='null'}-localhost:27017] INFO  org.mongodb.driver.cluster - Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, version=ServerVersion{versionList=[3, 6, 3]}, minWireVersion=0, maxWireVersion=6, maxDocumentSize=16777216, roundTripTimeNanos=379500}
13:46:46.491 [main] WARN  com.netflix.config.sources.URLConfigurationSource - No URLs will be polled as dynamic configuration sources.
13:46:46.491 [main] INFO  com.netflix.config.sources.URLConfigurationSource - To enable URLs as dynamic configuration sources, define System property archaius.configurationSource.additionalUrls or make config.properties available on classpath.
13:46:46.491 [main] WARN  com.netflix.config.sources.URLConfigurationSource - No URLs will be polled as dynamic configuration sources.
13:46:46.491 [main] INFO  com.netflix.config.sources.URLConfigurationSource - To enable URLs as dynamic configuration sources, define System property archaius.configurationSource.additionalUrls or make config.properties available on classpath.
13:46:46.691 [main] INFO  o.s.w.s.m.m.a.RequestMappingHandlerAdapter - Looking for @ControllerAdvice: org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@7ad54c55: startup date [Tue Sep 10 13:46:37 CST 2019]; parent: org.springframework.context.annotation.AnnotationConfigApplicationContext@6bbe2511
13:46:46.760 [main] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/exchange-rate/{legalCoin}/{coin}]}" onto public cn.ztuo.bitrade.util.MessageResult cn.ztuo.bitrade.controller.ExchangeRateController.getUsdExchangeRate(java.lang.String,java.lang.String)
13:46:46.760 [main] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/exchange-rate/{fromUnit}-{toUnit}]}" onto public cn.ztuo.bitrade.util.MessageResult cn.ztuo.bitrade.controller.ExchangeRateController.getUsdCnyRate(java.lang.String,java.lang.String)
13:46:46.760 [main] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/symbol-info]}" onto public cn.ztuo.bitrade.entity.ExchangeCoin cn.ztuo.bitrade.controller.MarketController.findSymbol(java.lang.String)
13:46:46.760 [main] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/symbol-thumb-trend]}" onto public com.alibaba.fastjson.JSONArray cn.ztuo.bitrade.controller.MarketController.findSymbolThumbWithTrend()
13:46:46.760 [main] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/default/symbol],methods=[GET]}" onto public cn.ztuo.bitrade.util.MessageResult cn.ztuo.bitrade.controller.MarketController.findDefaultSymbol()
13:46:46.760 [main] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/exchange-plate-full]}" onto public java.util.Map<java.lang.String, com.alibaba.fastjson.JSONObject> cn.ztuo.bitrade.controller.MarketController.findTradePlateFull(java.lang.String)
13:46:46.760 [main] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/exchange-plate-mini]}" onto public java.util.Map<java.lang.String, com.alibaba.fastjson.JSONObject> cn.ztuo.bitrade.controller.MarketController.findTradePlateMini(java.lang.String)
13:46:46.760 [main] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/find/waiting]}" onto public cn.ztuo.bitrade.entity.ExchangeOrder cn.ztuo.bitrade.controller.MarketController.findWaitingOrder(java.lang.String,java.lang.String,cn.ztuo.bitrade.entity.ExchangeOrderDirection)
13:46:46.760 [main] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/symbol]}" onto public java.util.List<cn.ztuo.bitrade.entity.ExchangeCoin> cn.ztuo.bitrade.controller.MarketController.findAllSymbol()
13:46:46.760 [main] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/history]}" onto public com.alibaba.fastjson.JSONArray cn.ztuo.bitrade.controller.MarketController.findKHistory(java.lang.String,long,long,java.lang.String)
13:46:46.760 [main] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/symbol-thumb]}" onto public java.util.List<cn.ztuo.bitrade.entity.CoinThumb> cn.ztuo.bitrade.controller.MarketController.findSymbolThumb(java.lang.Boolean)
13:46:46.760 [main] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/latest-trade]}" onto public java.util.List<cn.ztuo.bitrade.entity.ExchangeTrade> cn.ztuo.bitrade.controller.MarketController.latestTrade(java.lang.String,int)
13:46:46.760 [main] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/exchange-plate]}" onto public java.util.Map<java.lang.String, java.util.List<cn.ztuo.bitrade.entity.TradePlateItem>> cn.ztuo.bitrade.controller.MarketController.findTradePlate(java.lang.String)
13:46:46.760 [main] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/overview]}" onto public java.util.Map<java.lang.String, java.util.List<cn.ztuo.bitrade.entity.CoinThumb>> cn.ztuo.bitrade.controller.MarketController.overview()
13:46:46.760 [main] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/captcha]}" onto public void cn.ztuo.bitrade.controller.CaptchaController.genCaptcha(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse) throws java.io.IOException
13:46:46.776 [main] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
13:46:46.776 [main] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
13:46:46.836 [main] INFO  o.s.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/webjars/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
13:46:46.836 [main] INFO  o.s.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
13:46:46.860 [main] INFO  o.s.w.s.m.m.a.ExceptionHandlerExceptionResolver - Detected @ExceptionHandler methods in exceptionControllerAdvice
13:46:46.905 [main] INFO  o.s.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/**/favicon.ico] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
13:46:47.494 [main] INFO  cn.ztuo.aqmd.core.context.HawkContext - 注册指令11002#1
13:46:47.494 [main] INFO  cn.ztuo.aqmd.core.context.HawkContext - 注册指令11004#1
13:46:47.494 [main] INFO  cn.ztuo.aqmd.core.context.HawkContext - 增加过滤器class cn.ztuo.aqmd.netty.filter.AccessAuthFilter
13:46:47.494 [main] INFO  cn.ztuo.aqmd.core.context.HawkContext - 增加过滤器class cn.ztuo.aqmd.netty.filter.DelegatingHawkFilterProxy
13:46:48.257 [main] WARN  o.s.c.s.e.EurekaStarterDeprecationWarningAutoConfiguration - spring-cloud-starter-eureka is deprecated as of Spring Cloud Netflix 1.4.0, please migrate to spring-cloud-starter-netflix-eureka
13:46:48.500 [main] INFO  o.s.jmx.export.annotation.AnnotationMBeanExporter - Registering beans for JMX exposure on startup
13:46:48.508 [main] INFO  o.s.jmx.export.annotation.AnnotationMBeanExporter - Bean with name 'dataSource' has been autodetected for JMX exposure
13:46:48.510 [main] INFO  o.s.jmx.export.annotation.AnnotationMBeanExporter - Bean with name 'environmentManager' has been autodetected for JMX exposure
13:46:48.519 [main] INFO  o.s.jmx.export.annotation.AnnotationMBeanExporter - Bean with name 'configurationPropertiesRebinder' has been autodetected for JMX exposure
13:46:48.520 [main] INFO  o.s.jmx.export.annotation.AnnotationMBeanExporter - Bean with name 'refreshScope' has been autodetected for JMX exposure
13:46:48.521 [main] INFO  o.s.jmx.export.annotation.AnnotationMBeanExporter - Located managed bean 'environmentManager': registering with JMX server as MBean [org.springframework.cloud.context.environment:name=environmentManager,type=EnvironmentManager]
13:46:48.529 [main] INFO  o.s.jmx.export.annotation.AnnotationMBeanExporter - Located managed bean 'refreshScope': registering with JMX server as MBean [org.springframework.cloud.context.scope.refresh:name=refreshScope,type=RefreshScope]
13:46:48.541 [main] INFO  o.s.jmx.export.annotation.AnnotationMBeanExporter - Located managed bean 'configurationPropertiesRebinder': registering with JMX server as MBean [org.springframework.cloud.context.properties:name=configurationPropertiesRebinder,context=7ad54c55,type=ConfigurationPropertiesRebinder]
13:46:48.549 [main] INFO  o.s.jmx.export.annotation.AnnotationMBeanExporter - Located MBean 'dataSource': registering with JMX server as MBean [com.alibaba.druid.pool:name=dataSource,type=DruidDataSource]
13:46:48.753 [main] INFO  o.s.context.support.DefaultLifecycleProcessor - Starting beans in phase 0
13:46:48.764 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:46:48.803 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-1
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:46:48.803 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.0.0
13:46:48.803 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : b8642491e78c5a13
13:46:48.803 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:46:48.803 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-2
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:46:48.803 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.0.0
13:46:48.818 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : b8642491e78c5a13
13:46:48.818 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:46:48.818 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-3
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:46:48.818 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.0.0
13:46:48.818 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : b8642491e78c5a13
13:46:48.818 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:46:48.818 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-4
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:46:48.818 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.0.0
13:46:48.818 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : b8642491e78c5a13
13:46:48.818 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:46:48.818 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-5
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:46:48.818 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.0.0
13:46:48.818 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : b8642491e78c5a13
13:46:48.818 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:46:48.818 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-6
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:46:48.818 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.0.0
13:46:48.818 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : b8642491e78c5a13
13:46:48.818 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:46:48.818 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-7
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:46:48.818 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.0.0
13:46:48.818 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : b8642491e78c5a13
13:46:48.818 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:46:48.834 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-8
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:46:48.834 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.0.0
13:46:48.834 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : b8642491e78c5a13
13:46:48.834 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:46:48.834 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-9
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:46:48.834 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.0.0
13:46:48.834 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : b8642491e78c5a13
13:46:48.834 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:46:48.834 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-10
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:46:48.834 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.0.0
13:46:48.834 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : b8642491e78c5a13
13:46:48.834 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:46:48.834 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-11
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:46:48.834 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.0.0
13:46:48.834 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : b8642491e78c5a13
13:46:48.834 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:46:48.834 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-12
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:46:48.834 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.0.0
13:46:48.834 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : b8642491e78c5a13
13:46:48.834 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:46:48.834 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-13
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:46:48.834 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.0.0
13:46:48.834 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : b8642491e78c5a13
13:46:48.834 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:46:48.834 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-14
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:46:48.834 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.0.0
13:46:48.834 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : b8642491e78c5a13
13:46:48.834 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:46:48.850 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-15
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:46:48.850 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.0.0
13:46:48.850 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : b8642491e78c5a13
13:46:48.850 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:46:48.850 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-16
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:46:48.850 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.0.0
13:46:48.850 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : b8642491e78c5a13
13:46:48.850 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:46:48.850 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-17
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:46:48.850 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.0.0
13:46:48.850 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : b8642491e78c5a13
13:46:48.850 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:46:48.850 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-18
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:46:48.850 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.0.0
13:46:48.850 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : b8642491e78c5a13
13:46:48.850 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:46:48.850 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-19
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:46:48.850 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.0.0
13:46:48.850 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : b8642491e78c5a13
13:46:48.850 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:46:48.850 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-20
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:46:48.850 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.0.0
13:46:48.850 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : b8642491e78c5a13
13:46:48.850 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:46:48.850 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-21
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:46:48.850 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.0.0
13:46:48.850 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : b8642491e78c5a13
13:46:48.850 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:46:48.850 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-22
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:46:48.850 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.0.0
13:46:48.850 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : b8642491e78c5a13
13:46:48.850 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:46:48.850 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-23
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:46:48.850 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.0.0
13:46:48.850 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : b8642491e78c5a13
13:46:48.850 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:46:48.850 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-24
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:46:48.850 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.0.0
13:46:48.850 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : b8642491e78c5a13
13:46:48.850 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:46:48.865 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-25
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:46:48.865 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.0.0
13:46:48.865 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : b8642491e78c5a13
13:46:48.865 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:46:48.865 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-26
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:46:48.865 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.0.0
13:46:48.865 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : b8642491e78c5a13
13:46:48.865 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:46:48.865 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-27
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:46:48.865 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.0.0
13:46:48.865 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : b8642491e78c5a13
13:46:48.868 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:46:48.868 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-28
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:46:48.868 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.0.0
13:46:48.868 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : b8642491e78c5a13
13:46:48.868 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:46:48.868 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-29
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:46:48.868 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.0.0
13:46:48.868 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : b8642491e78c5a13
13:46:48.868 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:46:48.868 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-30
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:46:48.868 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.0.0
13:46:48.868 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : b8642491e78c5a13
13:46:48.868 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:46:48.868 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-31
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:46:48.868 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.0.0
13:46:48.868 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : b8642491e78c5a13
13:46:48.868 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:46:48.868 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-32
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:46:48.868 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.0.0
13:46:48.868 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : b8642491e78c5a13
13:46:48.868 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:46:48.868 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-33
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:46:48.868 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.0.0
13:46:48.868 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : b8642491e78c5a13
13:46:48.868 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:46:48.868 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-34
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:46:48.868 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.0.0
13:46:48.868 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : b8642491e78c5a13
13:46:48.868 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:46:48.868 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-35
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:46:48.868 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.0.0
13:46:48.868 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : b8642491e78c5a13
13:46:48.868 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:46:48.868 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-36
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:46:48.868 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.0.0
13:46:48.868 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : b8642491e78c5a13
13:46:48.868 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:46:48.868 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-37
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:46:48.868 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.0.0
13:46:48.868 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : b8642491e78c5a13
13:46:48.868 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:46:48.868 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-38
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:46:48.868 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.0.0
13:46:48.868 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : b8642491e78c5a13
13:46:48.868 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:46:48.868 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-39
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:46:48.884 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.0.0
13:46:48.884 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : b8642491e78c5a13
13:46:48.884 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:46:48.884 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-40
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:46:48.884 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.0.0
13:46:48.884 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : b8642491e78c5a13
13:46:48.884 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:46:48.884 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-41
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:46:48.884 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.0.0
13:46:48.884 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : b8642491e78c5a13
13:46:48.884 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:46:48.884 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-42
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:46:48.884 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.0.0
13:46:48.884 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : b8642491e78c5a13
13:46:48.884 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:46:48.884 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-43
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:46:48.884 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.0.0
13:46:48.884 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : b8642491e78c5a13
13:46:48.884 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:46:48.884 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-44
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:46:48.884 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.0.0
13:46:48.884 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : b8642491e78c5a13
13:46:48.884 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:46:48.884 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-45
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:46:48.884 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.0.0
13:46:48.884 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : b8642491e78c5a13
13:46:48.884 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:46:48.884 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-46
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:46:48.884 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.0.0
13:46:48.884 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : b8642491e78c5a13
13:46:48.899 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:46:48.899 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-47
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:46:48.899 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.0.0
13:46:48.899 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : b8642491e78c5a13
13:46:48.899 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:46:48.902 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-48
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:46:48.902 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.0.0
13:46:48.902 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : b8642491e78c5a13
13:46:48.902 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:46:48.902 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-49
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:46:48.902 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.0.0
13:46:48.902 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : b8642491e78c5a13
13:46:48.902 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:46:48.902 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-50
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:46:48.902 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.0.0
13:46:48.902 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : b8642491e78c5a13
13:46:48.902 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:46:48.902 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-51
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:46:48.902 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.0.0
13:46:48.902 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : b8642491e78c5a13
13:46:48.902 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:46:48.902 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-52
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:46:48.902 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.0.0
13:46:48.902 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : b8642491e78c5a13
13:46:48.902 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:46:48.902 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-53
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:46:48.902 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.0.0
13:46:48.902 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : b8642491e78c5a13
13:46:48.902 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:46:48.902 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-54
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:46:48.902 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.0.0
13:46:48.902 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : b8642491e78c5a13
13:46:48.902 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:46:48.902 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-55
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:46:48.902 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.0.0
13:46:48.902 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : b8642491e78c5a13
13:46:48.902 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:46:48.917 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-56
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:46:48.917 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.0.0
13:46:48.917 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : b8642491e78c5a13
13:46:48.917 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:46:48.917 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-57
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:46:48.917 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.0.0
13:46:48.917 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : b8642491e78c5a13
13:46:48.917 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:46:48.917 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-58
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:46:48.917 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.0.0
13:46:48.917 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : b8642491e78c5a13
13:46:48.917 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:46:48.917 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-59
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:46:48.917 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.0.0
13:46:48.917 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : b8642491e78c5a13
13:46:48.917 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:46:48.917 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-60
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:46:48.917 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.0.0
13:46:48.917 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : b8642491e78c5a13
13:46:48.917 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:46:48.917 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-61
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:46:48.917 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.0.0
13:46:48.917 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : b8642491e78c5a13
13:46:48.917 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:46:48.917 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-62
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:46:48.917 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.0.0
13:46:48.917 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : b8642491e78c5a13
13:46:48.917 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:46:48.917 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-63
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:46:48.917 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.0.0
13:46:48.917 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : b8642491e78c5a13
13:46:48.917 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:46:48.917 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-64
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:46:48.917 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.0.0
13:46:48.917 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : b8642491e78c5a13
13:46:48.917 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:46:48.917 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-65
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:46:48.917 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.0.0
13:46:48.917 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : b8642491e78c5a13
13:46:48.933 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:46:48.933 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-66
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:46:48.933 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.0.0
13:46:48.933 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : b8642491e78c5a13
13:46:48.933 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:46:48.933 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-67
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:46:48.933 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.0.0
13:46:48.933 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : b8642491e78c5a13
13:46:48.933 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:46:48.933 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-68
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:46:48.933 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.0.0
13:46:48.933 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : b8642491e78c5a13
13:46:48.933 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:46:48.933 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-69
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:46:48.933 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.0.0
13:46:48.933 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : b8642491e78c5a13
13:46:48.933 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:46:48.933 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-70
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:46:48.933 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.0.0
13:46:48.933 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : b8642491e78c5a13
13:46:48.933 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:46:48.933 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-71
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:46:48.933 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.0.0
13:46:48.933 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : b8642491e78c5a13
13:46:48.933 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:46:48.933 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-72
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:46:48.933 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.0.0
13:46:48.933 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : b8642491e78c5a13
13:46:48.949 [main] INFO  o.s.cloud.netflix.eureka.InstanceInfoFactory - Setting initial instance status as: STARTING
13:46:48.984 [main] INFO  com.netflix.discovery.DiscoveryClient - Initializing Eureka in region us-east-1
13:46:49.084 [main] INFO  c.n.discovery.provider.DiscoveryJerseyProvider - Using JSON encoding codec LegacyJacksonJson
13:46:49.084 [main] INFO  c.n.discovery.provider.DiscoveryJerseyProvider - Using JSON decoding codec LegacyJacksonJson
13:46:49.169 [org.springframework.kafka.KafkaListenerEndpointContainer#6-8-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Discovered coordinator 112.74.59.207:9092 (id: 2147483647 rack: null) for group default-group.
13:46:49.169 [org.springframework.kafka.KafkaListenerEndpointContainer#6-5-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Discovered coordinator 112.74.59.207:9092 (id: 2147483647 rack: null) for group default-group.
13:46:49.169 [org.springframework.kafka.KafkaListenerEndpointContainer#6-7-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Discovered coordinator 112.74.59.207:9092 (id: 2147483647 rack: null) for group default-group.
13:46:49.169 [org.springframework.kafka.KafkaListenerEndpointContainer#6-5-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:46:49.169 [org.springframework.kafka.KafkaListenerEndpointContainer#6-8-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:46:49.169 [org.springframework.kafka.KafkaListenerEndpointContainer#6-7-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:46:49.169 [org.springframework.kafka.KafkaListenerEndpointContainer#6-7-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:46:49.169 [org.springframework.kafka.KafkaListenerEndpointContainer#6-8-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:46:49.169 [org.springframework.kafka.KafkaListenerEndpointContainer#6-5-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:46:49.169 [org.springframework.kafka.KafkaListenerEndpointContainer#6-7-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:46:49.169 [org.springframework.kafka.KafkaListenerEndpointContainer#6-8-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:46:49.169 [org.springframework.kafka.KafkaListenerEndpointContainer#6-5-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:46:49.185 [org.springframework.kafka.KafkaListenerEndpointContainer#1-6-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Discovered coordinator 112.74.59.207:9092 (id: 2147483647 rack: null) for group default-group.
13:46:49.185 [org.springframework.kafka.KafkaListenerEndpointContainer#1-6-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:46:49.185 [org.springframework.kafka.KafkaListenerEndpointContainer#1-6-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:46:49.185 [org.springframework.kafka.KafkaListenerEndpointContainer#1-6-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:46:49.185 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Discovered coordinator 112.74.59.207:9092 (id: 2147483647 rack: null) for group default-group.
13:46:49.185 [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Discovered coordinator 112.74.59.207:9092 (id: 2147483647 rack: null) for group default-group.
13:46:49.185 [org.springframework.kafka.KafkaListenerEndpointContainer#6-2-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Discovered coordinator 112.74.59.207:9092 (id: 2147483647 rack: null) for group default-group.
13:46:49.185 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:46:49.185 [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:46:49.185 [org.springframework.kafka.KafkaListenerEndpointContainer#6-2-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:46:49.185 [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:46:49.185 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:46:49.185 [org.springframework.kafka.KafkaListenerEndpointContainer#6-2-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:46:49.185 [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:46:49.185 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:46:49.185 [org.springframework.kafka.KafkaListenerEndpointContainer#6-2-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:46:49.185 [org.springframework.kafka.KafkaListenerEndpointContainer#6-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Discovered coordinator 112.74.59.207:9092 (id: 2147483647 rack: null) for group default-group.
13:46:49.185 [org.springframework.kafka.KafkaListenerEndpointContainer#6-3-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:46:49.185 [org.springframework.kafka.KafkaListenerEndpointContainer#6-3-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:46:49.185 [org.springframework.kafka.KafkaListenerEndpointContainer#6-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:46:49.185 [org.springframework.kafka.KafkaListenerEndpointContainer#1-7-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Discovered coordinator 112.74.59.207:9092 (id: 2147483647 rack: null) for group default-group.
13:46:49.185 [org.springframework.kafka.KafkaListenerEndpointContainer#1-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Discovered coordinator 112.74.59.207:9092 (id: 2147483647 rack: null) for group default-group.
13:46:49.185 [org.springframework.kafka.KafkaListenerEndpointContainer#6-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Discovered coordinator 112.74.59.207:9092 (id: 2147483647 rack: null) for group default-group.
13:46:49.185 [org.springframework.kafka.KafkaListenerEndpointContainer#1-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Discovered coordinator 112.74.59.207:9092 (id: 2147483647 rack: null) for group default-group.
13:46:49.185 [org.springframework.kafka.KafkaListenerEndpointContainer#1-2-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Discovered coordinator 112.74.59.207:9092 (id: 2147483647 rack: null) for group default-group.
13:46:49.185 [org.springframework.kafka.KafkaListenerEndpointContainer#1-7-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:46:49.185 [org.springframework.kafka.KafkaListenerEndpointContainer#1-7-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:46:49.185 [org.springframework.kafka.KafkaListenerEndpointContainer#1-4-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:46:49.185 [org.springframework.kafka.KafkaListenerEndpointContainer#1-7-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:46:49.185 [org.springframework.kafka.KafkaListenerEndpointContainer#1-4-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:46:49.185 [org.springframework.kafka.KafkaListenerEndpointContainer#6-4-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:46:49.185 [org.springframework.kafka.KafkaListenerEndpointContainer#1-2-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:46:49.185 [org.springframework.kafka.KafkaListenerEndpointContainer#1-3-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:46:49.185 [org.springframework.kafka.KafkaListenerEndpointContainer#1-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:46:49.185 [org.springframework.kafka.KafkaListenerEndpointContainer#6-4-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:46:49.185 [org.springframework.kafka.KafkaListenerEndpointContainer#1-2-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:46:49.185 [org.springframework.kafka.KafkaListenerEndpointContainer#6-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:46:49.185 [org.springframework.kafka.KafkaListenerEndpointContainer#1-3-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:46:49.185 [org.springframework.kafka.KafkaListenerEndpointContainer#1-2-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:46:49.185 [org.springframework.kafka.KafkaListenerEndpointContainer#1-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:46:49.185 [org.springframework.kafka.KafkaListenerEndpointContainer#0-7-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Discovered coordinator 112.74.59.207:9092 (id: 2147483647 rack: null) for group default-group.
13:46:49.185 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Discovered coordinator 112.74.59.207:9092 (id: 2147483647 rack: null) for group default-group.
13:46:49.185 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Discovered coordinator 112.74.59.207:9092 (id: 2147483647 rack: null) for group default-group.
13:46:49.185 [org.springframework.kafka.KafkaListenerEndpointContainer#6-6-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Discovered coordinator 112.74.59.207:9092 (id: 2147483647 rack: null) for group default-group.
13:46:49.185 [org.springframework.kafka.KafkaListenerEndpointContainer#0-7-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:46:49.185 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:46:49.185 [org.springframework.kafka.KafkaListenerEndpointContainer#6-6-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:46:49.185 [org.springframework.kafka.KafkaListenerEndpointContainer#0-7-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:46:49.185 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:46:49.185 [org.springframework.kafka.KafkaListenerEndpointContainer#0-7-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:46:49.185 [org.springframework.kafka.KafkaListenerEndpointContainer#0-5-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Discovered coordinator 112.74.59.207:9092 (id: 2147483647 rack: null) for group default-group.
13:46:49.185 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:46:49.185 [org.springframework.kafka.KafkaListenerEndpointContainer#6-6-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:46:49.185 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:46:49.185 [org.springframework.kafka.KafkaListenerEndpointContainer#6-6-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:46:49.185 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:46:49.185 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:46:49.185 [org.springframework.kafka.KafkaListenerEndpointContainer#0-5-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:46:49.185 [org.springframework.kafka.KafkaListenerEndpointContainer#0-5-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:46:49.185 [org.springframework.kafka.KafkaListenerEndpointContainer#0-5-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:46:49.185 [org.springframework.kafka.KafkaListenerEndpointContainer#0-8-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Discovered coordinator 112.74.59.207:9092 (id: 2147483647 rack: null) for group default-group.
13:46:49.185 [org.springframework.kafka.KafkaListenerEndpointContainer#0-8-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:46:49.185 [org.springframework.kafka.KafkaListenerEndpointContainer#1-5-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Discovered coordinator 112.74.59.207:9092 (id: 2147483647 rack: null) for group default-group.
13:46:49.185 [org.springframework.kafka.KafkaListenerEndpointContainer#6-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Discovered coordinator 112.74.59.207:9092 (id: 2147483647 rack: null) for group default-group.
13:46:49.185 [org.springframework.kafka.KafkaListenerEndpointContainer#0-8-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:46:49.185 [org.springframework.kafka.KafkaListenerEndpointContainer#0-8-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:46:49.185 [org.springframework.kafka.KafkaListenerEndpointContainer#1-5-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:46:49.185 [org.springframework.kafka.KafkaListenerEndpointContainer#6-1-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:46:49.185 [org.springframework.kafka.KafkaListenerEndpointContainer#1-5-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:46:49.185 [org.springframework.kafka.KafkaListenerEndpointContainer#6-1-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:46:49.185 [org.springframework.kafka.KafkaListenerEndpointContainer#1-5-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:46:49.185 [org.springframework.kafka.KafkaListenerEndpointContainer#6-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:46:49.207 [main] INFO  c.n.discovery.provider.DiscoveryJerseyProvider - Using XML encoding codec XStreamXml
13:46:49.207 [main] INFO  c.n.discovery.provider.DiscoveryJerseyProvider - Using XML decoding codec XStreamXml
13:46:49.235 [org.springframework.kafka.KafkaListenerEndpointContainer#0-6-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Discovered coordinator 112.74.59.207:9092 (id: 2147483647 rack: null) for group default-group.
13:46:49.235 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Discovered coordinator 112.74.59.207:9092 (id: 2147483647 rack: null) for group default-group.
13:46:49.235 [org.springframework.kafka.KafkaListenerEndpointContainer#1-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Discovered coordinator 112.74.59.207:9092 (id: 2147483647 rack: null) for group default-group.
13:46:49.235 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:46:49.235 [org.springframework.kafka.KafkaListenerEndpointContainer#0-6-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:46:49.235 [org.springframework.kafka.KafkaListenerEndpointContainer#0-6-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:46:49.235 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:46:49.235 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Discovered coordinator 112.74.59.207:9092 (id: 2147483647 rack: null) for group default-group.
13:46:49.235 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:46:49.235 [org.springframework.kafka.KafkaListenerEndpointContainer#0-6-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:46:49.235 [org.springframework.kafka.KafkaListenerEndpointContainer#1-1-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:46:49.235 [org.springframework.kafka.KafkaListenerEndpointContainer#1-1-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:46:49.235 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:46:49.235 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:46:49.235 [org.springframework.kafka.KafkaListenerEndpointContainer#1-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:46:49.235 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:46:49.285 [org.springframework.kafka.KafkaListenerEndpointContainer#4-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Discovered coordinator 112.74.59.207:9092 (id: 2147483647 rack: null) for group default-group.
13:46:49.285 [org.springframework.kafka.KafkaListenerEndpointContainer#7-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Discovered coordinator 112.74.59.207:9092 (id: 2147483647 rack: null) for group default-group.
13:46:49.285 [org.springframework.kafka.KafkaListenerEndpointContainer#7-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Discovered coordinator 112.74.59.207:9092 (id: 2147483647 rack: null) for group default-group.
13:46:49.285 [org.springframework.kafka.KafkaListenerEndpointContainer#7-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Discovered coordinator 112.74.59.207:9092 (id: 2147483647 rack: null) for group default-group.
13:46:49.285 [org.springframework.kafka.KafkaListenerEndpointContainer#7-2-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Discovered coordinator 112.74.59.207:9092 (id: 2147483647 rack: null) for group default-group.
13:46:49.285 [org.springframework.kafka.KafkaListenerEndpointContainer#7-1-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:46:49.285 [org.springframework.kafka.KafkaListenerEndpointContainer#2-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Discovered coordinator 112.74.59.207:9092 (id: 2147483647 rack: null) for group default-group.
13:46:49.285 [org.springframework.kafka.KafkaListenerEndpointContainer#7-6-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Discovered coordinator 112.74.59.207:9092 (id: 2147483647 rack: null) for group default-group.
13:46:49.285 [org.springframework.kafka.KafkaListenerEndpointContainer#4-4-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:46:49.285 [org.springframework.kafka.KafkaListenerEndpointContainer#4-4-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:46:49.285 [org.springframework.kafka.KafkaListenerEndpointContainer#7-1-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:46:49.285 [org.springframework.kafka.KafkaListenerEndpointContainer#4-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Discovered coordinator 112.74.59.207:9092 (id: 2147483647 rack: null) for group default-group.
13:46:49.285 [org.springframework.kafka.KafkaListenerEndpointContainer#7-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:46:49.285 [org.springframework.kafka.KafkaListenerEndpointContainer#7-2-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:46:49.285 [org.springframework.kafka.KafkaListenerEndpointContainer#7-2-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:46:49.285 [org.springframework.kafka.KafkaListenerEndpointContainer#7-6-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:46:49.285 [org.springframework.kafka.KafkaListenerEndpointContainer#2-1-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:46:49.285 [org.springframework.kafka.KafkaListenerEndpointContainer#7-6-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:46:49.285 [org.springframework.kafka.KafkaListenerEndpointContainer#2-1-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:46:49.285 [org.springframework.kafka.KafkaListenerEndpointContainer#2-6-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Discovered coordinator 112.74.59.207:9092 (id: 2147483647 rack: null) for group default-group.
13:46:49.285 [org.springframework.kafka.KafkaListenerEndpointContainer#7-0-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:46:49.285 [org.springframework.kafka.KafkaListenerEndpointContainer#3-7-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Discovered coordinator 112.74.59.207:9092 (id: 2147483647 rack: null) for group default-group.
13:46:49.285 [org.springframework.kafka.KafkaListenerEndpointContainer#4-6-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Discovered coordinator 112.74.59.207:9092 (id: 2147483647 rack: null) for group default-group.
13:46:49.285 [org.springframework.kafka.KafkaListenerEndpointContainer#4-3-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:46:49.285 [org.springframework.kafka.KafkaListenerEndpointContainer#4-3-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:46:49.285 [org.springframework.kafka.KafkaListenerEndpointContainer#4-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:46:49.285 [org.springframework.kafka.KafkaListenerEndpointContainer#2-6-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:46:49.285 [org.springframework.kafka.KafkaListenerEndpointContainer#2-6-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:46:49.285 [org.springframework.kafka.KafkaListenerEndpointContainer#4-6-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:46:49.285 [org.springframework.kafka.KafkaListenerEndpointContainer#2-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Discovered coordinator 112.74.59.207:9092 (id: 2147483647 rack: null) for group default-group.
13:46:49.285 [org.springframework.kafka.KafkaListenerEndpointContainer#3-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Discovered coordinator 112.74.59.207:9092 (id: 2147483647 rack: null) for group default-group.
13:46:49.285 [org.springframework.kafka.KafkaListenerEndpointContainer#2-8-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Discovered coordinator 112.74.59.207:9092 (id: 2147483647 rack: null) for group default-group.
13:46:49.285 [org.springframework.kafka.KafkaListenerEndpointContainer#3-2-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Discovered coordinator 112.74.59.207:9092 (id: 2147483647 rack: null) for group default-group.
13:46:49.285 [org.springframework.kafka.KafkaListenerEndpointContainer#2-4-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:46:49.285 [org.springframework.kafka.KafkaListenerEndpointContainer#2-4-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:46:49.285 [org.springframework.kafka.KafkaListenerEndpointContainer#3-4-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:46:49.285 [org.springframework.kafka.KafkaListenerEndpointContainer#2-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:46:49.285 [org.springframework.kafka.KafkaListenerEndpointContainer#3-4-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:46:49.285 [org.springframework.kafka.KafkaListenerEndpointContainer#3-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:46:49.285 [org.springframework.kafka.KafkaListenerEndpointContainer#4-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Discovered coordinator 112.74.59.207:9092 (id: 2147483647 rack: null) for group default-group.
13:46:49.285 [org.springframework.kafka.KafkaListenerEndpointContainer#2-8-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:46:49.285 [org.springframework.kafka.KafkaListenerEndpointContainer#2-8-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:46:49.285 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Discovered coordinator 112.74.59.207:9092 (id: 2147483647 rack: null) for group default-group.
13:46:49.285 [org.springframework.kafka.KafkaListenerEndpointContainer#2-8-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:46:49.285 [org.springframework.kafka.KafkaListenerEndpointContainer#4-5-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Discovered coordinator 112.74.59.207:9092 (id: 2147483647 rack: null) for group default-group.
13:46:49.285 [org.springframework.kafka.KafkaListenerEndpointContainer#3-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Discovered coordinator 112.74.59.207:9092 (id: 2147483647 rack: null) for group default-group.
13:46:49.285 [org.springframework.kafka.KafkaListenerEndpointContainer#2-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:46:49.285 [org.springframework.kafka.KafkaListenerEndpointContainer#7-7-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Discovered coordinator 112.74.59.207:9092 (id: 2147483647 rack: null) for group default-group.
13:46:49.285 [org.springframework.kafka.KafkaListenerEndpointContainer#4-7-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Discovered coordinator 112.74.59.207:9092 (id: 2147483647 rack: null) for group default-group.
13:46:49.285 [org.springframework.kafka.KafkaListenerEndpointContainer#4-5-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:46:49.285 [org.springframework.kafka.KafkaListenerEndpointContainer#4-5-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:46:49.285 [org.springframework.kafka.KafkaListenerEndpointContainer#4-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Discovered coordinator 112.74.59.207:9092 (id: 2147483647 rack: null) for group default-group.
13:46:49.285 [org.springframework.kafka.KafkaListenerEndpointContainer#4-2-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Discovered coordinator 112.74.59.207:9092 (id: 2147483647 rack: null) for group default-group.
13:46:49.285 [org.springframework.kafka.KafkaListenerEndpointContainer#4-5-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:46:49.285 [org.springframework.kafka.KafkaListenerEndpointContainer#7-3-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:46:49.285 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Discovered coordinator 112.74.59.207:9092 (id: 2147483647 rack: null) for group default-group.
13:46:49.285 [org.springframework.kafka.KafkaListenerEndpointContainer#4-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:46:49.285 [org.springframework.kafka.KafkaListenerEndpointContainer#7-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Discovered coordinator 112.74.59.207:9092 (id: 2147483647 rack: null) for group default-group.
13:46:49.285 [org.springframework.kafka.KafkaListenerEndpointContainer#7-8-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Discovered coordinator 112.74.59.207:9092 (id: 2147483647 rack: null) for group default-group.
13:46:49.285 [org.springframework.kafka.KafkaListenerEndpointContainer#7-2-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:46:49.285 [org.springframework.kafka.KafkaListenerEndpointContainer#7-6-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:46:49.285 [org.springframework.kafka.KafkaListenerEndpointContainer#4-2-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:46:49.285 [org.springframework.kafka.KafkaListenerEndpointContainer#2-7-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Discovered coordinator 112.74.59.207:9092 (id: 2147483647 rack: null) for group default-group.
13:46:49.285 [org.springframework.kafka.KafkaListenerEndpointContainer#4-2-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:46:49.285 [org.springframework.kafka.KafkaListenerEndpointContainer#7-0-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:46:49.285 [org.springframework.kafka.KafkaListenerEndpointContainer#3-5-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Discovered coordinator 112.74.59.207:9092 (id: 2147483647 rack: null) for group default-group.
13:46:49.285 [org.springframework.kafka.KafkaListenerEndpointContainer#4-2-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:46:49.285 [org.springframework.kafka.KafkaListenerEndpointContainer#7-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:46:49.285 [org.springframework.kafka.KafkaListenerEndpointContainer#3-7-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:46:49.285 [org.springframework.kafka.KafkaListenerEndpointContainer#7-4-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:46:49.285 [org.springframework.kafka.KafkaListenerEndpointContainer#3-7-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:46:49.285 [org.springframework.kafka.KafkaListenerEndpointContainer#7-4-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:46:49.285 [org.springframework.kafka.KafkaListenerEndpointContainer#2-6-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:46:49.285 [org.springframework.kafka.KafkaListenerEndpointContainer#4-6-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:46:49.285 [org.springframework.kafka.KafkaListenerEndpointContainer#2-5-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Discovered coordinator 112.74.59.207:9092 (id: 2147483647 rack: null) for group default-group.
13:46:49.285 [org.springframework.kafka.KafkaListenerEndpointContainer#4-6-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:46:49.285 [org.springframework.kafka.KafkaListenerEndpointContainer#2-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Discovered coordinator 112.74.59.207:9092 (id: 2147483647 rack: null) for group default-group.
13:46:49.285 [org.springframework.kafka.KafkaListenerEndpointContainer#3-8-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Discovered coordinator 112.74.59.207:9092 (id: 2147483647 rack: null) for group default-group.
13:46:49.285 [org.springframework.kafka.KafkaListenerEndpointContainer#3-2-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:46:49.285 [org.springframework.kafka.KafkaListenerEndpointContainer#3-5-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:46:49.285 [org.springframework.kafka.KafkaListenerEndpointContainer#3-2-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:46:49.285 [org.springframework.kafka.KafkaListenerEndpointContainer#4-0-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:46:49.285 [org.springframework.kafka.KafkaListenerEndpointContainer#4-8-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Discovered coordinator 112.74.59.207:9092 (id: 2147483647 rack: null) for group default-group.
13:46:49.285 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:46:49.285 [org.springframework.kafka.KafkaListenerEndpointContainer#3-3-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:46:49.285 [org.springframework.kafka.KafkaListenerEndpointContainer#7-5-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Discovered coordinator 112.74.59.207:9092 (id: 2147483647 rack: null) for group default-group.
13:46:49.285 [org.springframework.kafka.KafkaListenerEndpointContainer#7-7-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:46:49.285 [org.springframework.kafka.KafkaListenerEndpointContainer#7-3-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:46:49.285 [org.springframework.kafka.KafkaListenerEndpointContainer#7-7-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:46:49.285 [org.springframework.kafka.KafkaListenerEndpointContainer#2-3-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:46:49.285 [org.springframework.kafka.KafkaListenerEndpointContainer#4-7-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:46:49.285 [org.springframework.kafka.KafkaListenerEndpointContainer#4-1-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:46:49.285 [org.springframework.kafka.KafkaListenerEndpointContainer#7-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:46:49.285 [org.springframework.kafka.KafkaListenerEndpointContainer#7-7-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:46:49.285 [org.springframework.kafka.KafkaListenerEndpointContainer#3-7-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:46:49.285 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:46:49.285 [org.springframework.kafka.KafkaListenerEndpointContainer#4-1-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:46:49.285 [org.springframework.kafka.KafkaListenerEndpointContainer#7-8-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:46:49.285 [org.springframework.kafka.KafkaListenerEndpointContainer#3-5-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:46:49.285 [org.springframework.kafka.KafkaListenerEndpointContainer#3-2-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:46:49.285 [org.springframework.kafka.KafkaListenerEndpointContainer#7-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:46:49.285 [org.springframework.kafka.KafkaListenerEndpointContainer#2-7-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:46:49.285 [org.springframework.kafka.KafkaListenerEndpointContainer#7-5-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:46:49.285 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:46:49.285 [org.springframework.kafka.KafkaListenerEndpointContainer#7-8-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:46:49.285 [org.springframework.kafka.KafkaListenerEndpointContainer#3-3-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:46:49.285 [org.springframework.kafka.KafkaListenerEndpointContainer#3-5-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:46:49.285 [org.springframework.kafka.KafkaListenerEndpointContainer#7-8-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:46:49.285 [org.springframework.kafka.KafkaListenerEndpointContainer#2-7-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:46:49.285 [org.springframework.kafka.KafkaListenerEndpointContainer#7-5-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:46:49.285 [org.springframework.kafka.KafkaListenerEndpointContainer#2-3-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:46:49.285 [org.springframework.kafka.KafkaListenerEndpointContainer#4-0-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:46:49.285 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:46:49.285 [org.springframework.kafka.KafkaListenerEndpointContainer#2-5-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:46:49.285 [org.springframework.kafka.KafkaListenerEndpointContainer#4-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:46:49.285 [org.springframework.kafka.KafkaListenerEndpointContainer#3-8-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:46:49.285 [org.springframework.kafka.KafkaListenerEndpointContainer#2-7-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:46:49.285 [org.springframework.kafka.KafkaListenerEndpointContainer#3-8-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:46:49.285 [org.springframework.kafka.KafkaListenerEndpointContainer#4-7-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:46:49.285 [org.springframework.kafka.KafkaListenerEndpointContainer#4-8-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:46:49.285 [org.springframework.kafka.KafkaListenerEndpointContainer#4-7-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:46:49.285 [org.springframework.kafka.KafkaListenerEndpointContainer#4-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:46:49.285 [org.springframework.kafka.KafkaListenerEndpointContainer#4-8-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:46:49.285 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:46:49.285 [org.springframework.kafka.KafkaListenerEndpointContainer#4-8-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:46:49.285 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:46:49.285 [org.springframework.kafka.KafkaListenerEndpointContainer#2-5-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:46:49.285 [org.springframework.kafka.KafkaListenerEndpointContainer#2-5-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:46:49.285 [org.springframework.kafka.KafkaListenerEndpointContainer#3-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:46:49.285 [org.springframework.kafka.KafkaListenerEndpointContainer#7-5-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:46:49.285 [org.springframework.kafka.KafkaListenerEndpointContainer#2-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:46:49.285 [org.springframework.kafka.KafkaListenerEndpointContainer#3-8-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:46:49.302 [org.springframework.kafka.KafkaListenerEndpointContainer#2-2-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Discovered coordinator 112.74.59.207:9092 (id: 2147483647 rack: null) for group default-group.
13:46:49.302 [org.springframework.kafka.KafkaListenerEndpointContainer#3-6-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Discovered coordinator 112.74.59.207:9092 (id: 2147483647 rack: null) for group default-group.
13:46:49.302 [org.springframework.kafka.KafkaListenerEndpointContainer#3-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Discovered coordinator 112.74.59.207:9092 (id: 2147483647 rack: null) for group default-group.
13:46:49.302 [org.springframework.kafka.KafkaListenerEndpointContainer#2-2-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:46:49.302 [org.springframework.kafka.KafkaListenerEndpointContainer#3-1-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:46:49.302 [org.springframework.kafka.KafkaListenerEndpointContainer#3-6-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:46:49.302 [org.springframework.kafka.KafkaListenerEndpointContainer#3-1-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:46:49.302 [org.springframework.kafka.KafkaListenerEndpointContainer#2-2-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:46:49.302 [org.springframework.kafka.KafkaListenerEndpointContainer#3-6-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:46:49.302 [org.springframework.kafka.KafkaListenerEndpointContainer#3-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:46:49.302 [org.springframework.kafka.KafkaListenerEndpointContainer#2-2-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:46:49.302 [org.springframework.kafka.KafkaListenerEndpointContainer#3-6-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:46:49.302 [org.springframework.kafka.KafkaListenerEndpointContainer#5-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Discovered coordinator 112.74.59.207:9092 (id: 2147483647 rack: null) for group default-group.
13:46:49.302 [org.springframework.kafka.KafkaListenerEndpointContainer#5-0-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:46:49.302 [org.springframework.kafka.KafkaListenerEndpointContainer#5-0-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:46:49.302 [org.springframework.kafka.KafkaListenerEndpointContainer#5-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:46:49.302 [org.springframework.kafka.KafkaListenerEndpointContainer#5-5-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Discovered coordinator 112.74.59.207:9092 (id: 2147483647 rack: null) for group default-group.
13:46:49.302 [org.springframework.kafka.KafkaListenerEndpointContainer#5-6-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Discovered coordinator 112.74.59.207:9092 (id: 2147483647 rack: null) for group default-group.
13:46:49.302 [org.springframework.kafka.KafkaListenerEndpointContainer#5-2-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Discovered coordinator 112.74.59.207:9092 (id: 2147483647 rack: null) for group default-group.
13:46:49.302 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Discovered coordinator 112.74.59.207:9092 (id: 2147483647 rack: null) for group default-group.
13:46:49.302 [org.springframework.kafka.KafkaListenerEndpointContainer#5-5-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:46:49.302 [org.springframework.kafka.KafkaListenerEndpointContainer#5-5-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:46:49.302 [org.springframework.kafka.KafkaListenerEndpointContainer#5-6-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:46:49.302 [org.springframework.kafka.KafkaListenerEndpointContainer#5-2-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:46:49.302 [org.springframework.kafka.KafkaListenerEndpointContainer#5-5-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:46:49.302 [org.springframework.kafka.KafkaListenerEndpointContainer#5-2-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:46:49.302 [org.springframework.kafka.KafkaListenerEndpointContainer#5-6-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:46:49.302 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:46:49.302 [org.springframework.kafka.KafkaListenerEndpointContainer#5-2-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:46:49.302 [org.springframework.kafka.KafkaListenerEndpointContainer#5-6-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:46:49.302 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:46:49.302 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:46:49.302 [org.springframework.kafka.KafkaListenerEndpointContainer#5-7-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Discovered coordinator 112.74.59.207:9092 (id: 2147483647 rack: null) for group default-group.
13:46:49.302 [org.springframework.kafka.KafkaListenerEndpointContainer#5-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Discovered coordinator 112.74.59.207:9092 (id: 2147483647 rack: null) for group default-group.
13:46:49.302 [org.springframework.kafka.KafkaListenerEndpointContainer#5-7-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:46:49.302 [org.springframework.kafka.KafkaListenerEndpointContainer#5-1-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:46:49.302 [org.springframework.kafka.KafkaListenerEndpointContainer#5-7-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:46:49.302 [org.springframework.kafka.KafkaListenerEndpointContainer#5-1-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:46:49.302 [org.springframework.kafka.KafkaListenerEndpointContainer#5-7-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:46:49.302 [org.springframework.kafka.KafkaListenerEndpointContainer#5-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:46:49.302 [org.springframework.kafka.KafkaListenerEndpointContainer#5-8-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Discovered coordinator 112.74.59.207:9092 (id: 2147483647 rack: null) for group default-group.
13:46:49.302 [org.springframework.kafka.KafkaListenerEndpointContainer#5-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Discovered coordinator 112.74.59.207:9092 (id: 2147483647 rack: null) for group default-group.
13:46:49.302 [org.springframework.kafka.KafkaListenerEndpointContainer#5-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Discovered coordinator 112.74.59.207:9092 (id: 2147483647 rack: null) for group default-group.
13:46:49.302 [org.springframework.kafka.KafkaListenerEndpointContainer#5-4-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:46:49.302 [org.springframework.kafka.KafkaListenerEndpointContainer#5-8-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:46:49.302 [org.springframework.kafka.KafkaListenerEndpointContainer#5-3-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:46:49.302 [org.springframework.kafka.KafkaListenerEndpointContainer#5-8-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:46:49.302 [org.springframework.kafka.KafkaListenerEndpointContainer#5-3-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:46:49.302 [org.springframework.kafka.KafkaListenerEndpointContainer#5-4-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:46:49.302 [org.springframework.kafka.KafkaListenerEndpointContainer#5-8-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:46:49.302 [org.springframework.kafka.KafkaListenerEndpointContainer#5-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:46:49.302 [org.springframework.kafka.KafkaListenerEndpointContainer#5-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:46:49.385 [org.springframework.kafka.KafkaListenerEndpointContainer#1-8-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Discovered coordinator 112.74.59.207:9092 (id: 2147483647 rack: null) for group default-group.
13:46:49.385 [org.springframework.kafka.KafkaListenerEndpointContainer#1-8-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:46:49.385 [org.springframework.kafka.KafkaListenerEndpointContainer#1-8-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:46:49.385 [org.springframework.kafka.KafkaListenerEndpointContainer#1-8-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:46:49.486 [main] INFO  c.n.d.shared.resolver.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
13:46:49.634 [main] INFO  com.netflix.discovery.DiscoveryClient - Disable delta property : false
13:46:49.634 [main] INFO  com.netflix.discovery.DiscoveryClient - Single vip registry refresh property : null
13:46:49.634 [main] INFO  com.netflix.discovery.DiscoveryClient - Force full registry fetch : false
13:46:49.634 [main] INFO  com.netflix.discovery.DiscoveryClient - Application is null : false
13:46:49.634 [main] INFO  com.netflix.discovery.DiscoveryClient - Registered Applications size is zero : true
13:46:49.634 [main] INFO  com.netflix.discovery.DiscoveryClient - Application version is -1: true
13:46:49.634 [main] INFO  com.netflix.discovery.DiscoveryClient - Getting all instance registry info from the eureka server
13:46:49.803 [main] INFO  com.netflix.discovery.DiscoveryClient - The response status is 200
13:46:49.803 [main] INFO  com.netflix.discovery.DiscoveryClient - Starting heartbeat executor: renew interval is: 30
13:46:49.819 [main] INFO  com.netflix.discovery.InstanceInfoReplicator - InstanceInfoReplicator onDemand update allowed rate per min is 4
13:46:49.819 [main] INFO  com.netflix.discovery.DiscoveryClient - Discovery Client initialized at timestamp 1568094409819 with initial instances count: 0
13:46:49.819 [main] INFO  o.s.c.n.e.serviceregistry.EurekaServiceRegistry - Registering application bitrade-market with eureka with status UP
13:46:49.819 [main] INFO  com.netflix.discovery.DiscoveryClient - Saw local status change event StatusChangeEvent [timestamp=1568094409819, current=UP, previous=STARTING]
13:46:49.834 [DiscoveryClient-InstanceInfoReplicator-0] INFO  com.netflix.discovery.DiscoveryClient - DiscoveryClient_BITRADE-MARKET/wxpker-computer:bitrade-market:6004: registering service...
13:46:49.834 [main] INFO  o.s.context.support.DefaultLifecycleProcessor - Starting beans in phase 2147483647
13:46:49.834 [main] INFO  o.s.m.simp.broker.SimpleBrokerMessageHandler - Starting...
13:46:49.834 [main] INFO  o.s.m.simp.broker.SimpleBrokerMessageHandler - BrokerAvailabilityEvent[available=true, SimpleBrokerMessageHandler [DefaultSubscriptionRegistry[cache[0 destination(s)], registry[0 sessions]]]]
13:46:49.834 [main] INFO  o.s.m.simp.broker.SimpleBrokerMessageHandler - Started.
13:46:49.850 [main] INFO  cn.ztuo.bitrade.ApplicationEvent - ====初始化CoinExchangeRate====
13:46:49.850 [main] INFO  cn.ztuo.bitrade.component.CoinExchangeRate - rate map:{CNHUSD=0.14925, USDCNH=6.7}
13:46:49.850 [main] INFO  cn.ztuo.bitrade.ApplicationEvent - legalAnchoredCoins:{USDT=USD}
13:46:49.850 [main] INFO  cn.ztuo.bitrade.ApplicationEvent - ====初始化CoinProcessor====
13:46:49.850 [main] INFO  cn.ztuo.bitrade.processor.DefaultCoinProcessor - initializeThumb from 1568044800000 to 1568094360000
13:46:49.919 [main] INFO  org.mongodb.driver.connection - Opened connection [connectionId{localValue:3, serverValue:3}] to localhost:27017
13:46:49.934 [main] INFO  cn.ztuo.bitrade.processor.DefaultCoinProcessor - symbol = BTC/USDT ,baseCoin = USDT
13:46:49.934 [main] INFO  cn.ztuo.bitrade.processor.DefaultCoinProcessor - setBaseUsdRate = 
13:46:49.934 [main] INFO  cn.ztuo.bitrade.processor.DefaultCoinProcessor - setUsdRate = 
13:46:49.934 [main] INFO  cn.ztuo.bitrade.config.WaitingOrderEvent - ======initialize waitingOrder======
13:46:49.934 [DiscoveryClient-InstanceInfoReplicator-0] INFO  com.netflix.discovery.DiscoveryClient - DiscoveryClient_BITRADE-MARKET/wxpker-computer:bitrade-market:6004 - registration status: 204
13:46:49.950 [main] INFO  cn.ztuo.bitrade.config.WaitingOrderEvent - 待挂单数量=0
13:46:49.950 [main] INFO  cn.ztuo.bitrade.config.WaitingOrderEvent - 初始化完毕waitingOrder=WaitingOrder(symbol=BTC/USDT, buyTriggerPriceQueue={}, sellTriggerPriceQueue={}, ready=false)
13:46:49.950 [main] INFO  org.apache.coyote.http11.Http11NioProtocol - Initializing ProtocolHandler ["http-nio-6004"]
13:46:49.972 [main] INFO  org.apache.coyote.http11.Http11NioProtocol - Starting ProtocolHandler ["http-nio-6004"]
13:46:49.972 [main] INFO  org.apache.tomcat.util.net.NioSelectorPool - Using a shared selector for servlet write/read
13:46:49.988 [main] INFO  o.s.b.c.e.tomcat.TomcatEmbeddedServletContainer - Tomcat started on port(s): 6004 (http)
13:46:49.988 [main] INFO  o.s.c.n.e.s.EurekaAutoServiceRegistration - Updating port to 6004
13:46:50.003 [main] INFO  cn.ztuo.bitrade.MarketApplication - Started MarketApplication in 14.264 seconds (JVM running for 15.27)
13:46:50.377 [Thread-34] INFO  cn.ztuo.aqmd.netty.server.NettyServer - Server started at port 28901
13:46:52.351 [org.springframework.kafka.KafkaListenerEndpointContainer#5-5-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 44
13:46:52.351 [org.springframework.kafka.KafkaListenerEndpointContainer#3-2-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 44
13:46:52.351 [org.springframework.kafka.KafkaListenerEndpointContainer#1-6-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 44
13:46:52.351 [org.springframework.kafka.KafkaListenerEndpointContainer#2-6-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 44
13:46:52.351 [org.springframework.kafka.KafkaListenerEndpointContainer#2-7-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 44
13:46:52.351 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 44
13:46:52.351 [org.springframework.kafka.KafkaListenerEndpointContainer#1-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 44
13:46:52.351 [org.springframework.kafka.KafkaListenerEndpointContainer#3-5-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 44
13:46:52.351 [org.springframework.kafka.KafkaListenerEndpointContainer#6-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 44
13:46:52.351 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 44
13:46:52.351 [org.springframework.kafka.KafkaListenerEndpointContainer#3-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 44
13:46:52.351 [org.springframework.kafka.KafkaListenerEndpointContainer#7-8-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 44
13:46:52.351 [org.springframework.kafka.KafkaListenerEndpointContainer#1-8-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 44
13:46:52.351 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 44
13:46:52.351 [org.springframework.kafka.KafkaListenerEndpointContainer#4-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 44
13:46:52.351 [org.springframework.kafka.KafkaListenerEndpointContainer#7-7-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 44
13:46:52.351 [org.springframework.kafka.KafkaListenerEndpointContainer#7-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 44
13:46:52.351 [org.springframework.kafka.KafkaListenerEndpointContainer#7-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 44
13:46:52.351 [org.springframework.kafka.KafkaListenerEndpointContainer#0-5-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 44
13:46:52.351 [org.springframework.kafka.KafkaListenerEndpointContainer#0-6-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 44
13:46:52.351 [org.springframework.kafka.KafkaListenerEndpointContainer#5-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 44
13:46:52.351 [org.springframework.kafka.KafkaListenerEndpointContainer#1-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 44
13:46:52.351 [org.springframework.kafka.KafkaListenerEndpointContainer#4-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 44
13:46:52.351 [org.springframework.kafka.KafkaListenerEndpointContainer#6-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 44
13:46:52.351 [org.springframework.kafka.KafkaListenerEndpointContainer#2-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 44
13:46:52.351 [org.springframework.kafka.KafkaListenerEndpointContainer#5-1-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:46:52.351 [org.springframework.kafka.KafkaListenerEndpointContainer#0-7-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 44
13:46:52.351 [org.springframework.kafka.KafkaListenerEndpointContainer#2-4-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:46:52.351 [org.springframework.kafka.KafkaListenerEndpointContainer#7-3-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:46:52.351 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 44
13:46:52.351 [org.springframework.kafka.KafkaListenerEndpointContainer#5-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 44
13:46:52.351 [org.springframework.kafka.KafkaListenerEndpointContainer#1-2-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 44
13:46:52.351 [org.springframework.kafka.KafkaListenerEndpointContainer#5-8-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 44
13:46:52.351 [org.springframework.kafka.KafkaListenerEndpointContainer#2-8-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 44
13:46:52.351 [org.springframework.kafka.KafkaListenerEndpointContainer#3-7-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 44
13:46:52.351 [org.springframework.kafka.KafkaListenerEndpointContainer#6-6-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 44
13:46:52.351 [org.springframework.kafka.KafkaListenerEndpointContainer#0-7-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:46:52.351 [org.springframework.kafka.KafkaListenerEndpointContainer#7-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 44
13:46:52.351 [org.springframework.kafka.KafkaListenerEndpointContainer#1-1-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:46:52.351 [org.springframework.kafka.KafkaListenerEndpointContainer#7-4-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:46:52.351 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:46:52.351 [org.springframework.kafka.KafkaListenerEndpointContainer#4-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 44
13:46:52.351 [org.springframework.kafka.KafkaListenerEndpointContainer#2-7-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:46:52.351 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 44
13:46:52.351 [org.springframework.kafka.KafkaListenerEndpointContainer#5-4-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:46:52.351 [org.springframework.kafka.KafkaListenerEndpointContainer#3-2-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:46:52.351 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 44
13:46:52.351 [org.springframework.kafka.KafkaListenerEndpointContainer#1-6-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:46:52.351 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:46:52.351 [org.springframework.kafka.KafkaListenerEndpointContainer#0-8-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 44
13:46:52.351 [org.springframework.kafka.KafkaListenerEndpointContainer#4-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 44
13:46:52.351 [org.springframework.kafka.KafkaListenerEndpointContainer#0-8-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:46:52.351 [org.springframework.kafka.KafkaListenerEndpointContainer#6-8-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 44
13:46:52.351 [org.springframework.kafka.KafkaListenerEndpointContainer#6-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 44
13:46:52.351 [org.springframework.kafka.KafkaListenerEndpointContainer#3-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 44
13:46:52.351 [org.springframework.kafka.KafkaListenerEndpointContainer#6-4-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:46:52.351 [org.springframework.kafka.KafkaListenerEndpointContainer#5-8-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:46:52.351 [org.springframework.kafka.KafkaListenerEndpointContainer#7-3-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:46:52.351 [org.springframework.kafka.KafkaListenerEndpointContainer#7-6-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 44
13:46:52.351 [org.springframework.kafka.KafkaListenerEndpointContainer#2-8-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:46:52.351 [org.springframework.kafka.KafkaListenerEndpointContainer#5-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 44
13:46:52.351 [org.springframework.kafka.KafkaListenerEndpointContainer#4-2-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 44
13:46:52.351 [org.springframework.kafka.KafkaListenerEndpointContainer#5-3-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:46:52.351 [org.springframework.kafka.KafkaListenerEndpointContainer#2-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 44
13:46:52.351 [org.springframework.kafka.KafkaListenerEndpointContainer#4-2-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:46:52.351 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 44
13:46:52.351 [org.springframework.kafka.KafkaListenerEndpointContainer#2-2-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 44
13:46:52.351 [org.springframework.kafka.KafkaListenerEndpointContainer#4-1-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:46:52.351 [org.springframework.kafka.KafkaListenerEndpointContainer#7-7-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:46:52.351 [org.springframework.kafka.KafkaListenerEndpointContainer#1-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 44
13:46:52.351 [org.springframework.kafka.KafkaListenerEndpointContainer#5-6-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 44
13:46:52.351 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:46:52.351 [org.springframework.kafka.KafkaListenerEndpointContainer#0-5-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:46:52.351 [org.springframework.kafka.KafkaListenerEndpointContainer#6-1-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:46:52.351 [org.springframework.kafka.KafkaListenerEndpointContainer#4-6-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 44
13:46:52.351 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [exchange-order-cancel-success-0] for group default-group
13:46:52.366 [org.springframework.kafka.KafkaListenerEndpointContainer#4-6-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:46:52.351 [org.springframework.kafka.KafkaListenerEndpointContainer#1-4-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:46:52.366 [org.springframework.kafka.KafkaListenerEndpointContainer#4-6-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:46:52.351 [org.springframework.kafka.KafkaListenerEndpointContainer#4-0-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [exchange-trade-plate-0] for group default-group
13:46:52.351 [org.springframework.kafka.KafkaListenerEndpointContainer#5-8-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:46:52.351 [org.springframework.kafka.KafkaListenerEndpointContainer#6-4-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:46:52.351 [org.springframework.kafka.KafkaListenerEndpointContainer#1-8-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:46:52.351 [org.springframework.kafka.KafkaListenerEndpointContainer#2-6-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:46:52.367 [org.springframework.kafka.KafkaListenerEndpointContainer#1-8-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:46:52.351 [org.springframework.kafka.KafkaListenerEndpointContainer#1-2-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:46:52.351 [org.springframework.kafka.KafkaListenerEndpointContainer#2-8-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:46:52.367 [org.springframework.kafka.KafkaListenerEndpointContainer#1-2-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:46:52.351 [org.springframework.kafka.KafkaListenerEndpointContainer#6-6-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:46:52.351 [org.springframework.kafka.KafkaListenerEndpointContainer#5-7-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 44
13:46:52.351 [org.springframework.kafka.KafkaListenerEndpointContainer#5-2-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 44
13:46:52.351 [org.springframework.kafka.KafkaListenerEndpointContainer#2-3-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:46:52.351 [org.springframework.kafka.KafkaListenerEndpointContainer#0-6-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:46:52.351 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:46:52.366 [org.springframework.kafka.KafkaListenerEndpointContainer#4-1-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:46:52.351 [org.springframework.kafka.KafkaListenerEndpointContainer#4-4-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:46:52.351 [org.springframework.kafka.KafkaListenerEndpointContainer#7-8-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:46:52.366 [org.springframework.kafka.KafkaListenerEndpointContainer#6-1-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:46:52.351 [org.springframework.kafka.KafkaListenerEndpointContainer#2-7-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:46:52.351 [org.springframework.kafka.KafkaListenerEndpointContainer#5-1-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:46:52.351 [org.springframework.kafka.KafkaListenerEndpointContainer#5-5-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:46:52.351 [org.springframework.kafka.KafkaListenerEndpointContainer#0-8-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:46:52.369 [org.springframework.kafka.KafkaListenerEndpointContainer#5-5-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:46:52.351 [org.springframework.kafka.KafkaListenerEndpointContainer#1-7-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 44
13:46:52.351 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [exchange-trade-mocker-0] for group default-group
13:46:52.351 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:46:52.366 [org.springframework.kafka.KafkaListenerEndpointContainer#1-4-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:46:52.351 [org.springframework.kafka.KafkaListenerEndpointContainer#7-0-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [exchange-waiting-order-0] for group default-group
13:46:52.351 [org.springframework.kafka.KafkaListenerEndpointContainer#4-3-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:46:52.351 [org.springframework.kafka.KafkaListenerEndpointContainer#2-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 44
13:46:52.351 [org.springframework.kafka.KafkaListenerEndpointContainer#0-7-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:46:52.351 [org.springframework.kafka.KafkaListenerEndpointContainer#6-3-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:46:52.351 [org.springframework.kafka.KafkaListenerEndpointContainer#3-5-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:46:52.351 [org.springframework.kafka.KafkaListenerEndpointContainer#3-3-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:46:52.370 [org.springframework.kafka.KafkaListenerEndpointContainer#3-5-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:46:52.351 [org.springframework.kafka.KafkaListenerEndpointContainer#3-7-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:46:52.367 [org.springframework.kafka.KafkaListenerEndpointContainer#6-6-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:46:52.367 [org.springframework.kafka.KafkaListenerEndpointContainer#5-7-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:46:52.351 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:46:52.351 [org.springframework.kafka.KafkaListenerEndpointContainer#3-4-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:46:52.351 [org.springframework.kafka.KafkaListenerEndpointContainer#1-5-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 44
13:46:52.351 [org.springframework.kafka.KafkaListenerEndpointContainer#2-4-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:46:52.367 [org.springframework.kafka.KafkaListenerEndpointContainer#5-2-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:46:52.367 [org.springframework.kafka.KafkaListenerEndpointContainer#2-3-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:46:52.351 [org.springframework.kafka.KafkaListenerEndpointContainer#5-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 44
13:46:52.351 [org.springframework.kafka.KafkaListenerEndpointContainer#7-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 44
13:46:52.351 [org.springframework.kafka.KafkaListenerEndpointContainer#4-2-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:46:52.371 [org.springframework.kafka.KafkaListenerEndpointContainer#5-0-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [exchange-trade-0] for group default-group
13:46:52.351 [org.springframework.kafka.KafkaListenerEndpointContainer#7-2-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 44
13:46:52.351 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 44
13:46:52.351 [org.springframework.kafka.KafkaListenerEndpointContainer#1-1-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:46:52.351 [org.springframework.kafka.KafkaListenerEndpointContainer#5-4-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:46:52.369 [org.springframework.kafka.KafkaListenerEndpointContainer#7-8-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:46:52.351 [org.springframework.kafka.KafkaListenerEndpointContainer#7-5-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 44
13:46:52.351 [org.springframework.kafka.KafkaListenerEndpointContainer#7-4-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:46:52.351 [org.springframework.kafka.KafkaListenerEndpointContainer#6-7-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 44
13:46:52.369 [org.springframework.kafka.KafkaListenerEndpointContainer#1-7-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:46:52.351 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [exchange-market-symbol-0] for group default-group
13:46:52.351 [org.springframework.kafka.KafkaListenerEndpointContainer#6-8-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:46:52.366 [org.springframework.kafka.KafkaListenerEndpointContainer#7-7-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:46:52.372 [org.springframework.kafka.KafkaListenerEndpointContainer#6-8-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:46:52.366 [org.springframework.kafka.KafkaListenerEndpointContainer#1-3-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:46:52.366 [org.springframework.kafka.KafkaListenerEndpointContainer#5-6-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:46:52.370 [org.springframework.kafka.KafkaListenerEndpointContainer#2-1-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:46:52.351 [org.springframework.kafka.KafkaListenerEndpointContainer#3-2-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:46:52.370 [org.springframework.kafka.KafkaListenerEndpointContainer#3-3-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:46:52.351 [org.springframework.kafka.KafkaListenerEndpointContainer#6-5-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 44
13:46:52.366 [org.springframework.kafka.KafkaListenerEndpointContainer#4-7-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 44
13:46:52.367 [org.springframework.kafka.KafkaListenerEndpointContainer#2-6-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:46:52.351 [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 44
13:46:52.370 [org.springframework.kafka.KafkaListenerEndpointContainer#3-7-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:46:52.373 [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [exchange-waiting-order-cancel-0] for group default-group
13:46:52.351 [org.springframework.kafka.KafkaListenerEndpointContainer#1-6-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:46:52.371 [org.springframework.kafka.KafkaListenerEndpointContainer#1-5-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:46:52.351 [org.springframework.kafka.KafkaListenerEndpointContainer#7-6-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:46:52.370 [org.springframework.kafka.KafkaListenerEndpointContainer#6-3-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:46:52.371 [org.springframework.kafka.KafkaListenerEndpointContainer#5-7-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:46:52.351 [org.springframework.kafka.KafkaListenerEndpointContainer#5-3-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:46:52.351 [org.springframework.kafka.KafkaListenerEndpointContainer#3-6-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 44
13:46:52.372 [org.springframework.kafka.KafkaListenerEndpointContainer#7-5-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:46:52.371 [org.springframework.kafka.KafkaListenerEndpointContainer#7-2-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:46:52.371 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [exchange-order-completed-0] for group default-group
13:46:52.351 [org.springframework.kafka.KafkaListenerEndpointContainer#2-5-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 44
13:46:52.351 [org.springframework.kafka.KafkaListenerEndpointContainer#4-8-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 44
13:46:52.366 [org.springframework.kafka.KafkaListenerEndpointContainer#3-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 44
13:46:52.372 [org.springframework.kafka.KafkaListenerEndpointContainer#6-7-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:46:52.366 [org.springframework.kafka.KafkaListenerEndpointContainer#2-2-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:46:52.372 [org.springframework.kafka.KafkaListenerEndpointContainer#1-3-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:46:52.366 [org.springframework.kafka.KafkaListenerEndpointContainer#0-5-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:46:52.372 [org.springframework.kafka.KafkaListenerEndpointContainer#2-1-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:46:52.366 [org.springframework.kafka.KafkaListenerEndpointContainer#4-5-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 44
13:46:52.366 [org.springframework.kafka.KafkaListenerEndpointContainer#6-2-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 44
13:46:52.366 [org.springframework.kafka.KafkaListenerEndpointContainer#3-8-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 44
13:46:52.373 [org.springframework.kafka.KafkaListenerEndpointContainer#6-5-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:46:52.373 [org.springframework.kafka.KafkaListenerEndpointContainer#4-7-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:46:52.374 [org.springframework.kafka.KafkaListenerEndpointContainer#6-5-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:46:52.368 [org.springframework.kafka.KafkaListenerEndpointContainer#0-6-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:46:52.369 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:46:52.369 [org.springframework.kafka.KafkaListenerEndpointContainer#4-4-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:46:52.370 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:46:52.370 [org.springframework.kafka.KafkaListenerEndpointContainer#4-3-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:46:52.373 [org.springframework.kafka.KafkaListenerEndpointContainer#1-5-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:46:52.371 [org.springframework.kafka.KafkaListenerEndpointContainer#3-4-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:46:52.371 [org.springframework.kafka.KafkaListenerEndpointContainer#5-2-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:46:52.371 [org.springframework.kafka.KafkaListenerEndpointContainer#7-1-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:46:52.374 [org.springframework.kafka.KafkaListenerEndpointContainer#3-6-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:46:52.372 [org.springframework.kafka.KafkaListenerEndpointContainer#1-7-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:46:52.374 [org.springframework.kafka.KafkaListenerEndpointContainer#7-5-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:46:52.372 [org.springframework.kafka.KafkaListenerEndpointContainer#5-6-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:46:52.374 [org.springframework.kafka.KafkaListenerEndpointContainer#7-2-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:46:52.374 [org.springframework.kafka.KafkaListenerEndpointContainer#7-6-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:46:52.374 [org.springframework.kafka.KafkaListenerEndpointContainer#2-5-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:46:52.374 [org.springframework.kafka.KafkaListenerEndpointContainer#4-8-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:46:52.374 [org.springframework.kafka.KafkaListenerEndpointContainer#3-1-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:46:52.374 [org.springframework.kafka.KafkaListenerEndpointContainer#6-7-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:46:52.374 [org.springframework.kafka.KafkaListenerEndpointContainer#3-1-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:46:52.374 [org.springframework.kafka.KafkaListenerEndpointContainer#2-2-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:46:52.374 [org.springframework.kafka.KafkaListenerEndpointContainer#4-5-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:46:52.374 [org.springframework.kafka.KafkaListenerEndpointContainer#6-2-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:46:52.374 [org.springframework.kafka.KafkaListenerEndpointContainer#3-8-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:46:52.374 [org.springframework.kafka.KafkaListenerEndpointContainer#6-2-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:46:52.374 [org.springframework.kafka.KafkaListenerEndpointContainer#4-7-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:46:52.374 [org.springframework.kafka.KafkaListenerEndpointContainer#7-1-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:46:52.374 [org.springframework.kafka.KafkaListenerEndpointContainer#3-6-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:46:52.374 [org.springframework.kafka.KafkaListenerEndpointContainer#2-5-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:46:52.374 [org.springframework.kafka.KafkaListenerEndpointContainer#4-8-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:46:52.374 [org.springframework.kafka.KafkaListenerEndpointContainer#4-5-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:46:52.374 [org.springframework.kafka.KafkaListenerEndpointContainer#3-8-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:46:52.536 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[exchange-order-cancel-success-0]
13:46:52.536 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[exchange-trade-mocker-0]
13:46:52.536 [org.springframework.kafka.KafkaListenerEndpointContainer#5-0-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[exchange-trade-0]
13:46:52.536 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[exchange-market-symbol-0]
13:46:52.536 [org.springframework.kafka.KafkaListenerEndpointContainer#7-0-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[exchange-waiting-order-0]
13:46:52.552 [org.springframework.kafka.KafkaListenerEndpointContainer#4-0-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[exchange-trade-plate-0]
13:46:52.568 [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[exchange-waiting-order-cancel-0]
13:46:52.583 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[exchange-order-completed-0]
13:46:52.611 [org.springframework.kafka.KafkaListenerEndpointContainer#5-0-L-1] INFO  cn.ztuo.bitrade.consumer.ExchangeTradeConsumer - exchange-trade topic=exchange-trade,key=BTC/USDT,value=[{"amount":11.00000000,"buyOrderId":"E156760513100994","buyTurnover":12221.0000000000000000,"direction":"SELL","price":1111.00000000,"sellOrderId":"E156760513977674","sellTurnover":12221.0000000000000000,"symbol":"BTC/USDT","time":1567605139841}]
13:46:52.626 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-L-1] INFO  cn.ztuo.bitrade.consumer.ExchangeTradeConsumer - exchange-order-completed topic=exchange-order-completed,accessKey=BTC/USDT,value=[{"amount":11.00000000,"baseSymbol":"USDT","coinSymbol":"BTC","completed":true,"direction":"BUY","marginTrade":"IS_FALSE","memberId":2,"orderId":"E156760513100994","orderResource":"CUSTOMER","price":1111.00000000,"status":"TRADING","symbol":"BTC/USDT","time":1567605131008,"tradedAmount":11.00000000,"triggerPrice":0,"turnover":12221.0000000000000000,"type":"LIMIT_PRICE"},{"amount":11.00000000,"baseSymbol":"USDT","coinSymbol":"BTC","completed":true,"direction":"SELL","marginTrade":"IS_FALSE","memberId":2,"orderId":"E156760513977674","orderResource":"CUSTOMER","price":222.00000000,"status":"TRADING","symbol":"BTC/USDT","time":1567605139776,"tradedAmount":11.00000000,"triggerPrice":0,"turnover":12221.0000000000000000,"type":"LIMIT_PRICE"}]
13:46:52.637 [org.springframework.kafka.KafkaListenerEndpointContainer#5-0-L-1] INFO  cn.ztuo.bitrade.processor.DefaultCoinProcessor - 处理今日概况信息
13:46:52.637 [org.springframework.kafka.KafkaListenerEndpointContainer#5-0-L-1] INFO  cn.ztuo.bitrade.processor.DefaultCoinProcessor - handleThumb symbol = BTC/USDT
13:46:52.637 [org.springframework.kafka.KafkaListenerEndpointContainer#5-0-L-1] INFO  cn.ztuo.bitrade.processor.DefaultCoinProcessor - thumb = CoinThumb(symbol=BTC/USDT, open=1111.00000000, high=1111.00000000, low=1111.00000000, close=1111.00000000, chg=0.0000, change=0E-8, volume=11.0000, turnover=12221.0000, lastDayClose=0, usdRate=1111.00000000, baseUsdRate=1, closeStr=1111.00000000, trend=null, proportion=null)
13:46:52.670 [org.springframework.kafka.KafkaListenerEndpointContainer#4-0-L-1] INFO  cn.ztuo.bitrade.consumer.ExchangeTradeConsumer - exchange-trade-plate topic=exchange-trade-plate,accessKey=BTC/USDT
13:46:52.674 [org.springframework.kafka.KafkaListenerEndpointContainer#4-0-L-1] INFO  cn.ztuo.bitrade.consumer.ExchangeTradeConsumer - exchange-trade-plate topic=exchange-trade-plate,accessKey=BTC/USDT
13:46:52.674 [org.springframework.kafka.KafkaListenerEndpointContainer#4-0-L-1] INFO  cn.ztuo.bitrade.consumer.ExchangeTradeConsumer - exchange-trade-plate topic=exchange-trade-plate,accessKey=BTC/USDT
13:46:52.674 [org.springframework.kafka.KafkaListenerEndpointContainer#4-0-L-1] INFO  cn.ztuo.bitrade.consumer.ExchangeTradeConsumer - exchange-trade-plate topic=exchange-trade-plate,accessKey=BTC/USDT
13:46:52.674 [org.springframework.kafka.KafkaListenerEndpointContainer#4-0-L-1] INFO  cn.ztuo.bitrade.consumer.ExchangeTradeConsumer - exchange-trade-plate topic=exchange-trade-plate,accessKey=BTC/USDT
13:46:52.674 [org.springframework.kafka.KafkaListenerEndpointContainer#4-0-L-1] INFO  cn.ztuo.bitrade.consumer.ExchangeTradeConsumer - exchange-trade-plate topic=exchange-trade-plate,accessKey=BTC/USDT
13:46:52.674 [org.springframework.kafka.KafkaListenerEndpointContainer#4-0-L-1] INFO  cn.ztuo.bitrade.consumer.ExchangeTradeConsumer - exchange-trade-plate topic=exchange-trade-plate,accessKey=BTC/USDT
13:46:52.674 [org.springframework.kafka.KafkaListenerEndpointContainer#4-0-L-1] INFO  cn.ztuo.bitrade.consumer.ExchangeTradeConsumer - exchange-trade-plate topic=exchange-trade-plate,accessKey=BTC/USDT
13:46:52.674 [org.springframework.kafka.KafkaListenerEndpointContainer#4-0-L-1] INFO  cn.ztuo.bitrade.consumer.ExchangeTradeConsumer - exchange-trade-plate topic=exchange-trade-plate,accessKey=BTC/USDT
13:46:52.674 [org.springframework.kafka.KafkaListenerEndpointContainer#4-0-L-1] INFO  cn.ztuo.bitrade.consumer.ExchangeTradeConsumer - exchange-trade-plate topic=exchange-trade-plate,accessKey=BTC/USDT
13:46:52.694 [org.springframework.kafka.KafkaListenerEndpointContainer#5-0-L-1] INFO  cn.ztuo.bitrade.consumer.ExchangeTradeConsumer - complete exchange process,83ms used!
13:46:52.694 [org.springframework.kafka.KafkaListenerEndpointContainer#5-0-L-1] INFO  cn.ztuo.bitrade.consumer.ExchangeTradeConsumer - exchange-trade topic=exchange-trade,key=BTC/USDT,value=[{"amount":1.00000000,"buyOrderId":"E156764983506733","buyTurnover":55555.0000000000000000,"direction":"BUY","price":55555.00000000,"sellOrderId":"E156764900155650","sellTurnover":55555.0000000000000000,"symbol":"BTC/USDT","time":1567649835202}]
13:46:52.694 [org.springframework.kafka.KafkaListenerEndpointContainer#5-0-L-1] INFO  cn.ztuo.bitrade.processor.DefaultCoinProcessor - 处理今日概况信息
13:46:52.694 [org.springframework.kafka.KafkaListenerEndpointContainer#5-0-L-1] INFO  cn.ztuo.bitrade.processor.DefaultCoinProcessor - handleThumb symbol = BTC/USDT
13:46:52.694 [org.springframework.kafka.KafkaListenerEndpointContainer#5-0-L-1] INFO  cn.ztuo.bitrade.processor.DefaultCoinProcessor - thumb = CoinThumb(symbol=BTC/USDT, open=1111.00000000, high=55555.00000000, low=1111.00000000, close=55555.00000000, chg=49.0046, change=54444.00000000, volume=12.0000, turnover=67776.0000, lastDayClose=0, usdRate=55555.00000000, baseUsdRate=1, closeStr=55555.00000000, trend=null, proportion=null)
13:46:52.694 [org.springframework.kafka.KafkaListenerEndpointContainer#5-0-L-1] INFO  cn.ztuo.bitrade.consumer.ExchangeTradeConsumer - complete exchange process,0ms used!
13:46:52.694 [org.springframework.kafka.KafkaListenerEndpointContainer#5-0-L-1] INFO  cn.ztuo.bitrade.consumer.ExchangeTradeConsumer - exchange-trade topic=exchange-trade,key=BTC/USDT,value=[{"amount":10.00000000,"buyOrderId":"E156765052968483","buyTurnover":555550.0000000000000000,"direction":"BUY","price":55555.00000000,"sellOrderId":"E156764900155650","sellTurnover":555550.0000000000000000,"symbol":"BTC/USDT","time":1567650529791},{"amount":10.00000000,"buyOrderId":"E156765052968483","buyTurnover":555550.0000000000000000,"direction":"BUY","price":55555.00000000,"sellOrderId":"E156765052408657","sellTurnover":555550.0000000000000000,"symbol":"BTC/USDT","time":1567650529791}]
13:46:52.694 [org.springframework.kafka.KafkaListenerEndpointContainer#5-0-L-1] INFO  cn.ztuo.bitrade.processor.DefaultCoinProcessor - 处理今日概况信息
13:46:52.694 [org.springframework.kafka.KafkaListenerEndpointContainer#5-0-L-1] INFO  cn.ztuo.bitrade.processor.DefaultCoinProcessor - handleThumb symbol = BTC/USDT
13:46:52.694 [org.springframework.kafka.KafkaListenerEndpointContainer#5-0-L-1] INFO  cn.ztuo.bitrade.processor.DefaultCoinProcessor - thumb = CoinThumb(symbol=BTC/USDT, open=1111.00000000, high=55555.00000000, low=1111.00000000, close=55555.00000000, chg=49.0046, change=54444.00000000, volume=22.0000, turnover=623326.0000, lastDayClose=0, usdRate=55555.00000000, baseUsdRate=1, closeStr=55555.00000000, trend=null, proportion=null)
13:46:52.694 [org.springframework.kafka.KafkaListenerEndpointContainer#5-0-L-1] INFO  cn.ztuo.bitrade.processor.DefaultCoinProcessor - 处理今日概况信息
13:46:52.694 [org.springframework.kafka.KafkaListenerEndpointContainer#5-0-L-1] INFO  cn.ztuo.bitrade.processor.DefaultCoinProcessor - handleThumb symbol = BTC/USDT
13:46:52.694 [org.springframework.kafka.KafkaListenerEndpointContainer#5-0-L-1] INFO  cn.ztuo.bitrade.processor.DefaultCoinProcessor - thumb = CoinThumb(symbol=BTC/USDT, open=1111.00000000, high=55555.00000000, low=1111.00000000, close=55555.00000000, chg=49.0046, change=54444.00000000, volume=32.0000, turnover=1178876.0000, lastDayClose=0, usdRate=55555.00000000, baseUsdRate=1, closeStr=55555.00000000, trend=null, proportion=null)
13:46:52.694 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-L-1] INFO  cn.ztuo.bitrade.consumer.ExchangeTradeConsumer - exchange-order-completed topic=exchange-order-completed,accessKey=BTC/USDT,value=[{"amount":1.00000000,"baseSymbol":"USDT","coinSymbol":"BTC","completed":true,"direction":"BUY","marginTrade":"IS_FALSE","memberId":2,"orderId":"E156764983506733","orderResource":"CUSTOMER","price":77777.00000000,"status":"TRADING","symbol":"BTC/USDT","time":1567649835067,"tradedAmount":1.00000000,"triggerPrice":0,"turnover":55555.0000000000000000,"type":"LIMIT_PRICE"}]
13:46:52.694 [pool-2-thread-1] INFO  cn.ztuo.bitrade.service.ExchangeOrderService - processExchangeTrade,trade = {"amount":11.00000000,"buyOrderId":"E156760513100994","buyTurnover":12221.0000000000000000,"direction":"SELL","price":1111.00000000,"sellOrderId":"E156760513977674","sellTurnover":12221.0000000000000000,"symbol":"BTC/USDT","time":1567605139841}
13:46:52.694 [org.springframework.kafka.KafkaListenerEndpointContainer#5-0-L-1] INFO  cn.ztuo.bitrade.consumer.ExchangeTradeConsumer - complete exchange process,0ms used!
13:46:52.694 [pool-2-thread-2] INFO  cn.ztuo.bitrade.service.ExchangeOrderService - processExchangeTrade,trade = {"amount":1.00000000,"buyOrderId":"E156764983506733","buyTurnover":55555.0000000000000000,"direction":"BUY","price":55555.00000000,"sellOrderId":"E156764900155650","sellTurnover":55555.0000000000000000,"symbol":"BTC/USDT","time":1567649835202}
13:46:52.710 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-L-1] INFO  cn.ztuo.bitrade.consumer.ExchangeTradeConsumer - exchange-order-completed topic=exchange-order-completed,accessKey=BTC/USDT,value=[{"amount":11.00000000,"baseSymbol":"USDT","coinSymbol":"BTC","completed":true,"direction":"SELL","marginTrade":"IS_FALSE","memberId":2,"orderId":"E156764900155650","orderResource":"CUSTOMER","price":55555.00000000,"status":"TRADING","symbol":"BTC/USDT","time":1567649001556,"tradedAmount":11.00000000,"triggerPrice":0,"turnover":611105.0000000000000000,"type":"LIMIT_PRICE"},{"amount":10.00000000,"baseSymbol":"USDT","coinSymbol":"BTC","completed":true,"direction":"SELL","marginTrade":"IS_FALSE","memberId":2,"orderId":"E156765052408657","orderResource":"CUSTOMER","price":55555.00000000,"status":"TRADING","symbol":"BTC/USDT","time":1567650524086,"tradedAmount":10.00000000,"triggerPrice":0,"turnover":555550.0000000000000000,"type":"LIMIT_PRICE"},{"amount":20.00000000,"baseSymbol":"USDT","coinSymbol":"BTC","completed":true,"direction":"BUY","marginTrade":"IS_FALSE","memberId":2,"orderId":"E156765052968483","orderResource":"CUSTOMER","price":55555.00000000,"status":"TRADING","symbol":"BTC/USDT","time":1567650529684,"tradedAmount":20.00000000,"triggerPrice":0,"turnover":1111100.0000000000000000,"type":"LIMIT_PRICE"}]
13:46:52.710 [pool-2-thread-3] INFO  cn.ztuo.bitrade.service.ExchangeOrderService - processExchangeTrade,trade = {"amount":10.00000000,"buyOrderId":"E156765052968483","buyTurnover":555550.0000000000000000,"direction":"BUY","price":55555.00000000,"sellOrderId":"E156764900155650","sellTurnover":555550.0000000000000000,"symbol":"BTC/USDT","time":1567650529791}
13:46:52.737 [pool-2-thread-3] INFO  cn.ztuo.bitrade.core.DB - [SQL]： select id from member_wallet where member_id = ? for update;; params [2]
13:46:52.737 [pool-2-thread-2] INFO  cn.ztuo.bitrade.core.DB - [SQL]： select id from member_wallet where member_id = ? for update;; params [2]
13:46:52.737 [pool-2-thread-1] INFO  cn.ztuo.bitrade.core.DB - [SQL]： select id from member_wallet where member_id = ? for update;; params [2]
13:46:52.752 [pool-2-thread-1] INFO  cn.ztuo.bitrade.consumer.ExchangeTradeConsumer - 撮合模块ERROR={}
java.lang.NullPointerException: null
	at cn.ztuo.bitrade.service.ExchangeOrderService.processOrder(ExchangeOrderService.java:252)
	at cn.ztuo.bitrade.service.ExchangeOrderService.processExchangeTrade(ExchangeOrderService.java:224)
	at cn.ztuo.bitrade.service.ExchangeOrderService$$FastClassBySpringCGLIB$$82c91a6b.invoke(<generated>)
	at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:204)
	at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:738)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)
	at org.springframework.transaction.interceptor.TransactionInterceptor$1.proceedWithInvocation(TransactionInterceptor.java:99)
	at org.springframework.transaction.interceptor.TransactionAspectSupport.invokeWithinTransaction(TransactionAspectSupport.java:282)
	at org.springframework.transaction.interceptor.TransactionInterceptor.invoke(TransactionInterceptor.java:96)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)
	at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:673)
	at cn.ztuo.bitrade.service.ExchangeOrderService$$EnhancerBySpringCGLIB$$273012a7.processExchangeTrade(<generated>)
	at cn.ztuo.bitrade.consumer.ExchangeTradeConsumer$HandleTradeThread.run(ExchangeTradeConsumer.java:221)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run$$$capture(FutureTask.java:266)
	at java.util.concurrent.FutureTask.run(FutureTask.java)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
13:46:52.752 [pool-2-thread-2] INFO  cn.ztuo.bitrade.consumer.ExchangeTradeConsumer - 撮合模块ERROR={}
java.lang.NullPointerException: null
	at cn.ztuo.bitrade.service.ExchangeOrderService.processOrder(ExchangeOrderService.java:252)
	at cn.ztuo.bitrade.service.ExchangeOrderService.processExchangeTrade(ExchangeOrderService.java:224)
	at cn.ztuo.bitrade.service.ExchangeOrderService$$FastClassBySpringCGLIB$$82c91a6b.invoke(<generated>)
	at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:204)
	at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:738)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)
	at org.springframework.transaction.interceptor.TransactionInterceptor$1.proceedWithInvocation(TransactionInterceptor.java:99)
	at org.springframework.transaction.interceptor.TransactionAspectSupport.invokeWithinTransaction(TransactionAspectSupport.java:282)
	at org.springframework.transaction.interceptor.TransactionInterceptor.invoke(TransactionInterceptor.java:96)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)
	at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:673)
	at cn.ztuo.bitrade.service.ExchangeOrderService$$EnhancerBySpringCGLIB$$273012a7.processExchangeTrade(<generated>)
	at cn.ztuo.bitrade.consumer.ExchangeTradeConsumer$HandleTradeThread.run(ExchangeTradeConsumer.java:221)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run$$$capture(FutureTask.java:266)
	at java.util.concurrent.FutureTask.run(FutureTask.java)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
13:46:52.752 [pool-2-thread-3] INFO  cn.ztuo.bitrade.consumer.ExchangeTradeConsumer - 撮合模块ERROR={}
java.lang.NullPointerException: null
	at cn.ztuo.bitrade.service.ExchangeOrderService.processOrder(ExchangeOrderService.java:252)
	at cn.ztuo.bitrade.service.ExchangeOrderService.processExchangeTrade(ExchangeOrderService.java:224)
	at cn.ztuo.bitrade.service.ExchangeOrderService$$FastClassBySpringCGLIB$$82c91a6b.invoke(<generated>)
	at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:204)
	at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:738)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)
	at org.springframework.transaction.interceptor.TransactionInterceptor$1.proceedWithInvocation(TransactionInterceptor.java:99)
	at org.springframework.transaction.interceptor.TransactionAspectSupport.invokeWithinTransaction(TransactionAspectSupport.java:282)
	at org.springframework.transaction.interceptor.TransactionInterceptor.invoke(TransactionInterceptor.java:96)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)
	at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:673)
	at cn.ztuo.bitrade.service.ExchangeOrderService$$EnhancerBySpringCGLIB$$273012a7.processExchangeTrade(<generated>)
	at cn.ztuo.bitrade.consumer.ExchangeTradeConsumer$HandleTradeThread.run(ExchangeTradeConsumer.java:221)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run$$$capture(FutureTask.java:266)
	at java.util.concurrent.FutureTask.run(FutureTask.java)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
13:46:52.868 [MessageBroker-8] INFO  cn.ztuo.bitrade.job.ExchangePushJob - ====处理盘口推送信息===
13:46:52.883 [MessageBroker-8] INFO  cn.ztuo.bitrade.handler.NettyHandler - 推送盘口信息
13:46:52.883 [MessageBroker-8] INFO  cn.ztuo.bitrade.handler.NettyHandler - chanelSet:null
13:46:52.887 [MessageBroker-8] INFO  cn.ztuo.bitrade.handler.NettyHandler - 推送深度信息
13:46:52.887 [MessageBroker-8] INFO  cn.ztuo.bitrade.job.ExchangePushJob - ====处理盘口推送信息===
13:46:52.887 [MessageBroker-8] INFO  cn.ztuo.bitrade.job.ExchangePushJob - ====处理盘口推送信息===
13:46:52.887 [MessageBroker-8] INFO  cn.ztuo.bitrade.job.ExchangePushJob - ====处理盘口推送信息===
13:46:52.887 [MessageBroker-8] INFO  cn.ztuo.bitrade.job.ExchangePushJob - ====处理盘口推送信息===
13:46:52.887 [MessageBroker-8] INFO  cn.ztuo.bitrade.job.ExchangePushJob - ====处理盘口推送信息===
13:46:52.887 [MessageBroker-8] INFO  cn.ztuo.bitrade.job.ExchangePushJob - ====处理盘口推送信息===
13:46:52.887 [MessageBroker-8] INFO  cn.ztuo.bitrade.handler.NettyHandler - 推送盘口信息
13:46:52.887 [MessageBroker-8] INFO  cn.ztuo.bitrade.handler.NettyHandler - chanelSet:null
13:46:52.887 [MessageBroker-8] INFO  cn.ztuo.bitrade.handler.NettyHandler - 推送深度信息
13:46:52.887 [MessageBroker-8] INFO  cn.ztuo.bitrade.job.ExchangePushJob - ====处理盘口推送信息===
13:46:52.887 [MessageBroker-8] INFO  cn.ztuo.bitrade.job.ExchangePushJob - ====处理盘口推送信息===
13:46:52.887 [MessageBroker-8] INFO  cn.ztuo.bitrade.job.ExchangePushJob - ====处理盘口推送信息===
13:47:00.030 [MessageBroker-4] INFO  cn.ztuo.bitrade.job.KLineGeneratorJob - 分钟K线:Tue Sep 10 13:47:00 CST 2019
13:47:00.035 [MessageBroker-4] INFO  cn.ztuo.bitrade.job.KLineGeneratorJob - 生成BTC/USDT分钟k线:{}
13:47:00.040 [MessageBroker-4] INFO  cn.ztuo.bitrade.processor.DefaultCoinProcessor - auto generate 1min kline in 13:47:00,data={"closePrice":55555.00000000,"count":4,"highestPrice":55555.00000000,"lowestPrice":1111.00000000,"openPrice":1111.00000000,"period":"1min","time":1568094420000,"turnover":1178876.0000000000000000,"volume":32.00000000}
13:47:19.822 [DiscoveryClient-CacheRefreshExecutor-0] INFO  com.netflix.discovery.DiscoveryClient - Disable delta property : false
13:47:19.822 [DiscoveryClient-CacheRefreshExecutor-0] INFO  com.netflix.discovery.DiscoveryClient - Single vip registry refresh property : null
13:47:19.822 [DiscoveryClient-CacheRefreshExecutor-0] INFO  com.netflix.discovery.DiscoveryClient - Force full registry fetch : false
13:47:19.822 [DiscoveryClient-CacheRefreshExecutor-0] INFO  com.netflix.discovery.DiscoveryClient - Application is null : false
13:47:19.822 [DiscoveryClient-CacheRefreshExecutor-0] INFO  com.netflix.discovery.DiscoveryClient - Registered Applications size is zero : true
13:47:19.822 [DiscoveryClient-CacheRefreshExecutor-0] INFO  com.netflix.discovery.DiscoveryClient - Application version is -1: false
13:47:19.822 [DiscoveryClient-CacheRefreshExecutor-0] INFO  com.netflix.discovery.DiscoveryClient - Getting all instance registry info from the eureka server
13:47:19.879 [DiscoveryClient-CacheRefreshExecutor-0] INFO  com.netflix.discovery.DiscoveryClient - The response status is 200
13:47:46.278 [MessageBroker-9] INFO  o.s.web.socket.config.WebSocketMessageBrokerStats - WebSocketSession[0 current WS(0)-HttpStream(0)-HttpPoll(0), 0 total, 0 closed abnormally (0 connect failure, 0 send limit, 0 transport error)], stompSubProtocol[processed CONNECT(0)-CONNECTED(0)-DISCONNECT(0)], stompBrokerRelay[null], inboundChannel[pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 0], outboundChannelpool size = 0, active threads = 0, queued tasks = 0, completed tasks = 0], sockJsScheduler[pool size = 12, active threads = 1, queued tasks = 8, completed tasks = 453]
13:48:00.014 [MessageBroker-4] INFO  cn.ztuo.bitrade.job.KLineGeneratorJob - 分钟K线:Tue Sep 10 13:48:00 CST 2019
13:48:00.014 [MessageBroker-4] INFO  cn.ztuo.bitrade.job.KLineGeneratorJob - 生成BTC/USDT分钟k线:{}
13:48:00.014 [MessageBroker-4] INFO  cn.ztuo.bitrade.processor.DefaultCoinProcessor - auto generate 1min kline in 13:48:00,data={"closePrice":0,"count":0,"highestPrice":0,"lowestPrice":0,"openPrice":0,"period":"1min","time":1568094480000,"turnover":0,"volume":0}
13:49:00.006 [MessageBroker-4] INFO  cn.ztuo.bitrade.job.KLineGeneratorJob - 分钟K线:Tue Sep 10 13:49:00 CST 2019
13:49:00.006 [MessageBroker-4] INFO  cn.ztuo.bitrade.job.KLineGeneratorJob - 生成BTC/USDT分钟k线:{}
13:49:00.006 [MessageBroker-4] INFO  cn.ztuo.bitrade.processor.DefaultCoinProcessor - auto generate 1min kline in 13:49:00,data={"closePrice":0,"count":0,"highestPrice":0,"lowestPrice":0,"openPrice":0,"period":"1min","time":1568094540000,"turnover":0,"volume":0}
13:50:00.017 [MessageBroker-11] INFO  cn.ztuo.bitrade.job.KLineGeneratorJob - 分钟K线:Tue Sep 10 13:50:00 CST 2019
13:50:00.017 [MessageBroker-11] INFO  cn.ztuo.bitrade.job.KLineGeneratorJob - 生成BTC/USDT分钟k线:{}
13:50:00.017 [MessageBroker-11] INFO  cn.ztuo.bitrade.processor.DefaultCoinProcessor - auto generate 1min kline in 13:50:00,data={"closePrice":0,"count":0,"highestPrice":0,"lowestPrice":0,"openPrice":0,"period":"1min","time":1568094600000,"turnover":0,"volume":0}
13:50:00.032 [MessageBroker-11] INFO  cn.ztuo.bitrade.processor.DefaultCoinProcessor - time range from 2019-09-10 13:45:00 to 2019-09-10 13:50:00
13:50:00.063 [MessageBroker-11] INFO  cn.ztuo.bitrade.processor.DefaultCoinProcessor - time range from 2019-09-10 13:40:00 to 2019-09-10 13:50:00
13:51:00.026 [MessageBroker-12] INFO  cn.ztuo.bitrade.job.KLineGeneratorJob - 分钟K线:Tue Sep 10 13:51:00 CST 2019
13:51:00.026 [MessageBroker-12] INFO  cn.ztuo.bitrade.job.KLineGeneratorJob - 生成BTC/USDT分钟k线:{}
13:51:00.026 [MessageBroker-12] INFO  cn.ztuo.bitrade.processor.DefaultCoinProcessor - auto generate 1min kline in 13:51:00,data={"closePrice":0,"count":0,"highestPrice":0,"lowestPrice":0,"openPrice":0,"period":"1min","time":1568094660000,"turnover":0,"volume":0}
13:51:49.653 [AsyncResolver-bootstrap-executor-0] INFO  c.n.d.shared.resolver.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
13:51:53.435 [org.springframework.kafka.KafkaListenerEndpointContainer#0-5-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:51:53.435 [org.springframework.kafka.KafkaListenerEndpointContainer#4-2-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:51:53.435 [org.springframework.kafka.KafkaListenerEndpointContainer#0-5-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:51:53.435 [org.springframework.kafka.KafkaListenerEndpointContainer#3-4-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:51:53.435 [org.springframework.kafka.KafkaListenerEndpointContainer#4-2-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:51:53.435 [org.springframework.kafka.KafkaListenerEndpointContainer#3-4-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:51:53.435 [org.springframework.kafka.KafkaListenerEndpointContainer#0-5-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:51:53.435 [org.springframework.kafka.KafkaListenerEndpointContainer#3-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:51:53.435 [org.springframework.kafka.KafkaListenerEndpointContainer#4-2-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:51:53.435 [org.springframework.kafka.KafkaListenerEndpointContainer#1-4-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:51:53.435 [org.springframework.kafka.KafkaListenerEndpointContainer#1-4-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:51:53.435 [org.springframework.kafka.KafkaListenerEndpointContainer#3-5-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:51:53.435 [org.springframework.kafka.KafkaListenerEndpointContainer#4-1-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:51:53.435 [org.springframework.kafka.KafkaListenerEndpointContainer#3-5-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:51:53.435 [org.springframework.kafka.KafkaListenerEndpointContainer#4-1-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:51:53.435 [org.springframework.kafka.KafkaListenerEndpointContainer#3-5-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:51:53.435 [org.springframework.kafka.KafkaListenerEndpointContainer#7-3-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:51:53.435 [org.springframework.kafka.KafkaListenerEndpointContainer#7-3-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:51:53.435 [org.springframework.kafka.KafkaListenerEndpointContainer#6-6-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:51:53.435 [org.springframework.kafka.KafkaListenerEndpointContainer#6-6-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:51:53.435 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:51:53.435 [org.springframework.kafka.KafkaListenerEndpointContainer#6-6-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:51:53.435 [org.springframework.kafka.KafkaListenerEndpointContainer#1-2-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:51:53.435 [org.springframework.kafka.KafkaListenerEndpointContainer#1-2-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:51:53.435 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:51:53.435 [org.springframework.kafka.KafkaListenerEndpointContainer#1-2-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:51:53.435 [org.springframework.kafka.KafkaListenerEndpointContainer#2-2-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:51:53.435 [org.springframework.kafka.KafkaListenerEndpointContainer#2-4-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:51:53.435 [org.springframework.kafka.KafkaListenerEndpointContainer#2-2-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:51:53.435 [org.springframework.kafka.KafkaListenerEndpointContainer#2-4-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:51:53.435 [org.springframework.kafka.KafkaListenerEndpointContainer#7-7-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:51:53.435 [org.springframework.kafka.KafkaListenerEndpointContainer#2-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:51:53.435 [org.springframework.kafka.KafkaListenerEndpointContainer#7-7-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:51:53.435 [org.springframework.kafka.KafkaListenerEndpointContainer#1-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:51:53.435 [org.springframework.kafka.KafkaListenerEndpointContainer#5-5-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:51:53.435 [org.springframework.kafka.KafkaListenerEndpointContainer#7-7-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:51:53.435 [org.springframework.kafka.KafkaListenerEndpointContainer#7-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:51:53.435 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:51:53.435 [org.springframework.kafka.KafkaListenerEndpointContainer#2-2-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:51:53.435 [org.springframework.kafka.KafkaListenerEndpointContainer#4-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:51:53.435 [org.springframework.kafka.KafkaListenerEndpointContainer#5-5-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:51:53.435 [org.springframework.kafka.KafkaListenerEndpointContainer#5-5-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:51:53.435 [org.springframework.kafka.KafkaListenerEndpointContainer#5-6-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:51:53.435 [org.springframework.kafka.KafkaListenerEndpointContainer#1-8-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:51:53.435 [org.springframework.kafka.KafkaListenerEndpointContainer#5-2-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:51:53.435 [org.springframework.kafka.KafkaListenerEndpointContainer#5-2-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:51:53.435 [org.springframework.kafka.KafkaListenerEndpointContainer#1-8-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:51:53.435 [org.springframework.kafka.KafkaListenerEndpointContainer#1-8-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:51:53.435 [org.springframework.kafka.KafkaListenerEndpointContainer#1-3-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:51:53.435 [org.springframework.kafka.KafkaListenerEndpointContainer#1-3-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:51:53.435 [org.springframework.kafka.KafkaListenerEndpointContainer#5-6-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:51:53.435 [org.springframework.kafka.KafkaListenerEndpointContainer#5-2-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:51:53.435 [org.springframework.kafka.KafkaListenerEndpointContainer#5-6-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:51:53.435 [org.springframework.kafka.KafkaListenerEndpointContainer#1-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:51:53.435 [org.springframework.kafka.KafkaListenerEndpointContainer#5-7-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:51:53.435 [org.springframework.kafka.KafkaListenerEndpointContainer#5-7-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:51:53.435 [org.springframework.kafka.KafkaListenerEndpointContainer#5-7-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:51:53.435 [org.springframework.kafka.KafkaListenerEndpointContainer#4-6-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:51:53.435 [org.springframework.kafka.KafkaListenerEndpointContainer#3-3-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:51:53.435 [org.springframework.kafka.KafkaListenerEndpointContainer#3-3-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:51:53.435 [org.springframework.kafka.KafkaListenerEndpointContainer#3-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:51:53.435 [org.springframework.kafka.KafkaListenerEndpointContainer#7-1-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:51:53.435 [org.springframework.kafka.KafkaListenerEndpointContainer#7-1-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:51:53.435 [org.springframework.kafka.KafkaListenerEndpointContainer#4-6-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:51:53.435 [org.springframework.kafka.KafkaListenerEndpointContainer#7-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:51:53.435 [org.springframework.kafka.KafkaListenerEndpointContainer#4-6-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:51:53.435 [org.springframework.kafka.KafkaListenerEndpointContainer#6-1-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:51:53.435 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:51:53.435 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:51:53.435 [org.springframework.kafka.KafkaListenerEndpointContainer#6-1-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:51:53.435 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:51:53.435 [org.springframework.kafka.KafkaListenerEndpointContainer#5-8-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:51:53.435 [org.springframework.kafka.KafkaListenerEndpointContainer#5-4-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:51:53.435 [org.springframework.kafka.KafkaListenerEndpointContainer#6-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:51:53.435 [org.springframework.kafka.KafkaListenerEndpointContainer#5-4-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:51:53.435 [org.springframework.kafka.KafkaListenerEndpointContainer#5-8-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:51:53.435 [org.springframework.kafka.KafkaListenerEndpointContainer#5-8-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:51:53.435 [org.springframework.kafka.KafkaListenerEndpointContainer#2-6-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:51:53.435 [org.springframework.kafka.KafkaListenerEndpointContainer#5-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:51:53.435 [org.springframework.kafka.KafkaListenerEndpointContainer#2-6-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:51:53.435 [org.springframework.kafka.KafkaListenerEndpointContainer#7-8-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:51:53.435 [org.springframework.kafka.KafkaListenerEndpointContainer#2-3-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:51:53.435 [org.springframework.kafka.KafkaListenerEndpointContainer#7-8-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:51:53.435 [org.springframework.kafka.KafkaListenerEndpointContainer#2-6-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:51:53.435 [org.springframework.kafka.KafkaListenerEndpointContainer#2-7-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:51:53.435 [org.springframework.kafka.KafkaListenerEndpointContainer#0-7-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:51:53.435 [org.springframework.kafka.KafkaListenerEndpointContainer#2-3-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:51:53.435 [org.springframework.kafka.KafkaListenerEndpointContainer#0-7-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:51:53.435 [org.springframework.kafka.KafkaListenerEndpointContainer#2-7-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:51:53.435 [org.springframework.kafka.KafkaListenerEndpointContainer#3-8-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:51:53.435 [org.springframework.kafka.KafkaListenerEndpointContainer#6-7-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:51:53.435 [org.springframework.kafka.KafkaListenerEndpointContainer#3-8-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:51:53.435 [org.springframework.kafka.KafkaListenerEndpointContainer#2-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:51:53.435 [org.springframework.kafka.KafkaListenerEndpointContainer#7-8-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:51:53.435 [org.springframework.kafka.KafkaListenerEndpointContainer#0-7-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:51:53.435 [org.springframework.kafka.KafkaListenerEndpointContainer#2-7-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:51:53.435 [org.springframework.kafka.KafkaListenerEndpointContainer#3-8-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:51:53.435 [org.springframework.kafka.KafkaListenerEndpointContainer#6-7-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:51:53.435 [org.springframework.kafka.KafkaListenerEndpointContainer#6-7-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:51:53.435 [org.springframework.kafka.KafkaListenerEndpointContainer#0-6-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:51:53.435 [org.springframework.kafka.KafkaListenerEndpointContainer#4-7-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:51:53.435 [org.springframework.kafka.KafkaListenerEndpointContainer#4-7-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:51:53.435 [org.springframework.kafka.KafkaListenerEndpointContainer#2-8-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:51:53.435 [org.springframework.kafka.KafkaListenerEndpointContainer#4-5-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:51:53.435 [org.springframework.kafka.KafkaListenerEndpointContainer#4-7-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:51:53.435 [org.springframework.kafka.KafkaListenerEndpointContainer#4-5-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:51:53.435 [org.springframework.kafka.KafkaListenerEndpointContainer#3-2-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:51:53.435 [org.springframework.kafka.KafkaListenerEndpointContainer#6-2-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:51:53.435 [org.springframework.kafka.KafkaListenerEndpointContainer#7-5-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:51:53.435 [org.springframework.kafka.KafkaListenerEndpointContainer#6-2-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:51:53.435 [org.springframework.kafka.KafkaListenerEndpointContainer#0-6-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:51:53.435 [org.springframework.kafka.KafkaListenerEndpointContainer#2-8-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:51:53.435 [org.springframework.kafka.KafkaListenerEndpointContainer#0-6-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:51:53.435 [org.springframework.kafka.KafkaListenerEndpointContainer#2-8-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:51:53.435 [org.springframework.kafka.KafkaListenerEndpointContainer#6-2-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:51:53.435 [org.springframework.kafka.KafkaListenerEndpointContainer#4-5-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:51:53.435 [org.springframework.kafka.KafkaListenerEndpointContainer#3-2-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:51:53.435 [org.springframework.kafka.KafkaListenerEndpointContainer#7-5-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:51:53.435 [org.springframework.kafka.KafkaListenerEndpointContainer#7-5-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:51:53.435 [org.springframework.kafka.KafkaListenerEndpointContainer#3-2-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:51:53.435 [org.springframework.kafka.KafkaListenerEndpointContainer#7-4-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:51:53.435 [org.springframework.kafka.KafkaListenerEndpointContainer#5-3-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:51:53.435 [org.springframework.kafka.KafkaListenerEndpointContainer#5-3-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:51:53.435 [org.springframework.kafka.KafkaListenerEndpointContainer#7-4-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:51:53.435 [org.springframework.kafka.KafkaListenerEndpointContainer#1-5-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:51:53.435 [org.springframework.kafka.KafkaListenerEndpointContainer#7-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:51:53.435 [org.springframework.kafka.KafkaListenerEndpointContainer#0-8-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:51:53.435 [org.springframework.kafka.KafkaListenerEndpointContainer#5-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:51:53.435 [org.springframework.kafka.KafkaListenerEndpointContainer#0-8-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:51:53.435 [org.springframework.kafka.KafkaListenerEndpointContainer#1-5-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:51:53.435 [org.springframework.kafka.KafkaListenerEndpointContainer#0-8-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:51:53.435 [org.springframework.kafka.KafkaListenerEndpointContainer#1-5-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:51:53.435 [org.springframework.kafka.KafkaListenerEndpointContainer#6-5-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:51:53.435 [org.springframework.kafka.KafkaListenerEndpointContainer#4-8-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:51:53.435 [org.springframework.kafka.KafkaListenerEndpointContainer#6-5-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:51:53.435 [org.springframework.kafka.KafkaListenerEndpointContainer#4-8-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:51:53.435 [org.springframework.kafka.KafkaListenerEndpointContainer#7-2-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:51:53.435 [org.springframework.kafka.KafkaListenerEndpointContainer#2-5-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:51:53.435 [org.springframework.kafka.KafkaListenerEndpointContainer#6-5-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:51:53.435 [org.springframework.kafka.KafkaListenerEndpointContainer#4-8-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:51:53.435 [org.springframework.kafka.KafkaListenerEndpointContainer#7-2-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:51:53.435 [org.springframework.kafka.KafkaListenerEndpointContainer#7-2-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:51:53.435 [org.springframework.kafka.KafkaListenerEndpointContainer#2-5-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:51:53.435 [org.springframework.kafka.KafkaListenerEndpointContainer#2-5-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:51:53.435 [org.springframework.kafka.KafkaListenerEndpointContainer#6-8-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:51:53.435 [org.springframework.kafka.KafkaListenerEndpointContainer#2-1-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:51:53.435 [org.springframework.kafka.KafkaListenerEndpointContainer#6-8-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:51:53.435 [org.springframework.kafka.KafkaListenerEndpointContainer#6-8-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:51:53.435 [org.springframework.kafka.KafkaListenerEndpointContainer#2-1-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:51:53.435 [org.springframework.kafka.KafkaListenerEndpointContainer#2-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:51:53.505 [org.springframework.kafka.KafkaListenerEndpointContainer#5-1-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:51:53.505 [org.springframework.kafka.KafkaListenerEndpointContainer#3-7-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:51:53.505 [org.springframework.kafka.KafkaListenerEndpointContainer#6-3-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:51:53.505 [org.springframework.kafka.KafkaListenerEndpointContainer#3-7-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:51:53.505 [org.springframework.kafka.KafkaListenerEndpointContainer#4-4-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:51:53.505 [org.springframework.kafka.KafkaListenerEndpointContainer#6-3-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:51:53.505 [org.springframework.kafka.KafkaListenerEndpointContainer#4-4-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:51:53.505 [org.springframework.kafka.KafkaListenerEndpointContainer#5-1-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:51:53.505 [org.springframework.kafka.KafkaListenerEndpointContainer#3-7-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:51:53.505 [org.springframework.kafka.KafkaListenerEndpointContainer#4-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:51:53.505 [org.springframework.kafka.KafkaListenerEndpointContainer#5-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:51:53.505 [org.springframework.kafka.KafkaListenerEndpointContainer#6-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:51:53.505 [org.springframework.kafka.KafkaListenerEndpointContainer#1-6-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:51:53.505 [org.springframework.kafka.KafkaListenerEndpointContainer#6-4-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:51:53.505 [org.springframework.kafka.KafkaListenerEndpointContainer#1-6-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:51:53.505 [org.springframework.kafka.KafkaListenerEndpointContainer#6-4-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:51:53.505 [org.springframework.kafka.KafkaListenerEndpointContainer#1-6-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:51:53.505 [org.springframework.kafka.KafkaListenerEndpointContainer#6-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:51:53.505 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:51:53.505 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:51:53.505 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:51:53.505 [org.springframework.kafka.KafkaListenerEndpointContainer#1-1-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:51:53.505 [org.springframework.kafka.KafkaListenerEndpointContainer#1-1-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:51:53.505 [org.springframework.kafka.KafkaListenerEndpointContainer#1-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:51:53.505 [org.springframework.kafka.KafkaListenerEndpointContainer#4-3-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:51:53.505 [org.springframework.kafka.KafkaListenerEndpointContainer#4-3-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:51:53.505 [org.springframework.kafka.KafkaListenerEndpointContainer#4-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:51:53.505 [org.springframework.kafka.KafkaListenerEndpointContainer#3-1-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:51:53.505 [org.springframework.kafka.KafkaListenerEndpointContainer#3-1-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:51:53.505 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:51:53.505 [org.springframework.kafka.KafkaListenerEndpointContainer#3-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:51:53.505 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:51:53.505 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:51:53.505 [org.springframework.kafka.KafkaListenerEndpointContainer#7-6-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:51:53.505 [org.springframework.kafka.KafkaListenerEndpointContainer#7-6-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:51:53.505 [org.springframework.kafka.KafkaListenerEndpointContainer#7-6-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:51:53.505 [org.springframework.kafka.KafkaListenerEndpointContainer#3-6-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:51:53.505 [org.springframework.kafka.KafkaListenerEndpointContainer#3-6-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:51:53.505 [org.springframework.kafka.KafkaListenerEndpointContainer#3-6-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:51:53.505 [org.springframework.kafka.KafkaListenerEndpointContainer#1-7-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:51:53.505 [org.springframework.kafka.KafkaListenerEndpointContainer#1-7-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:51:53.505 [org.springframework.kafka.KafkaListenerEndpointContainer#1-7-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:51:53.574 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [exchange-order-cancel-success-0] for group default-group
13:51:53.574 [org.springframework.kafka.KafkaListenerEndpointContainer#7-0-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [exchange-waiting-order-0] for group default-group
13:51:53.574 [org.springframework.kafka.KafkaListenerEndpointContainer#5-0-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [exchange-trade-0] for group default-group
13:51:53.605 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [exchange-trade-mocker-0] for group default-group
13:51:53.605 [org.springframework.kafka.KafkaListenerEndpointContainer#4-0-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [exchange-trade-plate-0] for group default-group
13:51:53.605 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [exchange-order-completed-0] for group default-group
13:51:53.737 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [exchange-market-symbol-0] for group default-group
13:51:53.737 [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [exchange-waiting-order-cancel-0] for group default-group
13:51:53.876 [org.springframework.kafka.KafkaListenerEndpointContainer#7-0-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[exchange-waiting-order-0]
13:51:53.876 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[exchange-market-symbol-0]
13:51:53.876 [org.springframework.kafka.KafkaListenerEndpointContainer#7-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:51:53.876 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:51:54.178 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[exchange-order-completed-0]
13:51:54.178 [org.springframework.kafka.KafkaListenerEndpointContainer#4-0-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[exchange-trade-plate-0]
13:51:54.178 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:51:54.178 [org.springframework.kafka.KafkaListenerEndpointContainer#4-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:51:54.178 [org.springframework.kafka.KafkaListenerEndpointContainer#5-0-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[exchange-trade-0]
13:51:54.178 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[exchange-order-cancel-success-0]
13:51:54.178 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[exchange-trade-mocker-0]
13:51:54.178 [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[exchange-waiting-order-cancel-0]
13:51:54.178 [org.springframework.kafka.KafkaListenerEndpointContainer#5-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:51:54.178 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:51:54.178 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:51:54.178 [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:51:55.048 [org.springframework.kafka.KafkaListenerEndpointContainer#1-6-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 45
13:51:55.048 [org.springframework.kafka.KafkaListenerEndpointContainer#5-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 45
13:51:55.048 [org.springframework.kafka.KafkaListenerEndpointContainer#1-6-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:51:55.048 [org.springframework.kafka.KafkaListenerEndpointContainer#5-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 45
13:51:55.048 [org.springframework.kafka.KafkaListenerEndpointContainer#5-4-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:51:55.048 [org.springframework.kafka.KafkaListenerEndpointContainer#5-1-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:51:55.048 [org.springframework.kafka.KafkaListenerEndpointContainer#1-6-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:51:55.048 [org.springframework.kafka.KafkaListenerEndpointContainer#5-4-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:51:55.048 [org.springframework.kafka.KafkaListenerEndpointContainer#5-1-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:51:55.048 [org.springframework.kafka.KafkaListenerEndpointContainer#4-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 45
13:51:55.048 [org.springframework.kafka.KafkaListenerEndpointContainer#4-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 45
13:51:55.048 [org.springframework.kafka.KafkaListenerEndpointContainer#2-2-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 45
13:51:55.048 [org.springframework.kafka.KafkaListenerEndpointContainer#4-4-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:51:55.048 [org.springframework.kafka.KafkaListenerEndpointContainer#6-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 45
13:51:55.048 [org.springframework.kafka.KafkaListenerEndpointContainer#2-2-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:51:55.048 [org.springframework.kafka.KafkaListenerEndpointContainer#6-1-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:51:55.048 [org.springframework.kafka.KafkaListenerEndpointContainer#7-8-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 45
13:51:55.048 [org.springframework.kafka.KafkaListenerEndpointContainer#2-2-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:51:55.048 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 45
13:51:55.048 [org.springframework.kafka.KafkaListenerEndpointContainer#4-1-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:51:55.048 [org.springframework.kafka.KafkaListenerEndpointContainer#4-4-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:51:55.048 [org.springframework.kafka.KafkaListenerEndpointContainer#7-8-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:51:55.048 [org.springframework.kafka.KafkaListenerEndpointContainer#0-6-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 45
13:51:55.048 [org.springframework.kafka.KafkaListenerEndpointContainer#6-1-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:51:55.048 [org.springframework.kafka.KafkaListenerEndpointContainer#0-7-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 45
13:51:55.048 [org.springframework.kafka.KafkaListenerEndpointContainer#3-7-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 45
13:51:55.048 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 45
13:51:55.048 [org.springframework.kafka.KafkaListenerEndpointContainer#2-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 45
13:51:55.048 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:51:55.048 [org.springframework.kafka.KafkaListenerEndpointContainer#3-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 45
13:51:55.048 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:51:55.048 [org.springframework.kafka.KafkaListenerEndpointContainer#1-2-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 45
13:51:55.048 [org.springframework.kafka.KafkaListenerEndpointContainer#0-5-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 45
13:51:55.048 [org.springframework.kafka.KafkaListenerEndpointContainer#1-2-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:51:55.048 [org.springframework.kafka.KafkaListenerEndpointContainer#6-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 45
13:51:55.048 [org.springframework.kafka.KafkaListenerEndpointContainer#7-7-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 45
13:51:55.048 [org.springframework.kafka.KafkaListenerEndpointContainer#6-3-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:51:55.048 [org.springframework.kafka.KafkaListenerEndpointContainer#7-8-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:51:55.048 [org.springframework.kafka.KafkaListenerEndpointContainer#7-7-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:51:55.048 [org.springframework.kafka.KafkaListenerEndpointContainer#2-7-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 45
13:51:55.048 [org.springframework.kafka.KafkaListenerEndpointContainer#5-5-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 45
13:51:55.048 [org.springframework.kafka.KafkaListenerEndpointContainer#7-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 45
13:51:55.048 [org.springframework.kafka.KafkaListenerEndpointContainer#5-5-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:51:55.048 [org.springframework.kafka.KafkaListenerEndpointContainer#3-5-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 45
13:51:55.048 [org.springframework.kafka.KafkaListenerEndpointContainer#7-0-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [exchange-waiting-order-0] for group default-group
13:51:55.048 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [exchange-market-symbol-0] for group default-group
13:51:55.048 [org.springframework.kafka.KafkaListenerEndpointContainer#3-5-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:51:55.048 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 45
13:51:55.048 [org.springframework.kafka.KafkaListenerEndpointContainer#2-3-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:51:55.048 [org.springframework.kafka.KafkaListenerEndpointContainer#1-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 45
13:51:55.048 [org.springframework.kafka.KafkaListenerEndpointContainer#4-2-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 45
13:51:55.048 [org.springframework.kafka.KafkaListenerEndpointContainer#3-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 45
13:51:55.048 [org.springframework.kafka.KafkaListenerEndpointContainer#1-2-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:51:55.048 [org.springframework.kafka.KafkaListenerEndpointContainer#4-1-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:51:55.048 [org.springframework.kafka.KafkaListenerEndpointContainer#4-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 45
13:51:55.048 [org.springframework.kafka.KafkaListenerEndpointContainer#6-6-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 45
13:51:55.048 [org.springframework.kafka.KafkaListenerEndpointContainer#2-7-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:51:55.048 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 45
13:51:55.048 [org.springframework.kafka.KafkaListenerEndpointContainer#5-5-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:51:55.048 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 45
13:51:55.048 [org.springframework.kafka.KafkaListenerEndpointContainer#3-5-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:51:55.048 [org.springframework.kafka.KafkaListenerEndpointContainer#2-3-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:51:55.048 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [exchange-order-cancel-success-0] for group default-group
13:51:55.048 [org.springframework.kafka.KafkaListenerEndpointContainer#7-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 45
13:51:55.048 [org.springframework.kafka.KafkaListenerEndpointContainer#1-8-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 45
13:51:55.048 [org.springframework.kafka.KafkaListenerEndpointContainer#4-6-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 45
13:51:55.048 [org.springframework.kafka.KafkaListenerEndpointContainer#1-4-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:51:55.048 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 45
13:51:55.048 [org.springframework.kafka.KafkaListenerEndpointContainer#5-8-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 45
13:51:55.048 [org.springframework.kafka.KafkaListenerEndpointContainer#0-5-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:51:55.048 [org.springframework.kafka.KafkaListenerEndpointContainer#5-8-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:51:55.048 [org.springframework.kafka.KafkaListenerEndpointContainer#2-6-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 45
13:51:55.048 [org.springframework.kafka.KafkaListenerEndpointContainer#7-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 45
13:51:55.048 [org.springframework.kafka.KafkaListenerEndpointContainer#2-6-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:51:55.048 [org.springframework.kafka.KafkaListenerEndpointContainer#4-2-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:51:55.048 [org.springframework.kafka.KafkaListenerEndpointContainer#0-6-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:51:55.048 [org.springframework.kafka.KafkaListenerEndpointContainer#4-3-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:51:55.048 [org.springframework.kafka.KafkaListenerEndpointContainer#0-7-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:51:55.048 [org.springframework.kafka.KafkaListenerEndpointContainer#6-6-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:51:55.048 [org.springframework.kafka.KafkaListenerEndpointContainer#3-7-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:51:55.048 [org.springframework.kafka.KafkaListenerEndpointContainer#2-7-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:51:55.048 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:51:55.048 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [exchange-trade-mocker-0] for group default-group
13:51:55.048 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:51:55.048 [org.springframework.kafka.KafkaListenerEndpointContainer#5-6-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 45
13:51:55.048 [org.springframework.kafka.KafkaListenerEndpointContainer#1-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 45
13:51:55.048 [org.springframework.kafka.KafkaListenerEndpointContainer#3-2-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 45
13:51:55.048 [org.springframework.kafka.KafkaListenerEndpointContainer#1-1-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:51:55.048 [org.springframework.kafka.KafkaListenerEndpointContainer#2-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 45
13:51:55.048 [org.springframework.kafka.KafkaListenerEndpointContainer#1-1-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:51:55.048 [org.springframework.kafka.KafkaListenerEndpointContainer#2-8-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 45
13:51:55.048 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 45
13:51:55.048 [org.springframework.kafka.KafkaListenerEndpointContainer#5-2-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 45
13:51:55.048 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:51:55.048 [org.springframework.kafka.KafkaListenerEndpointContainer#1-8-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:51:55.048 [org.springframework.kafka.KafkaListenerEndpointContainer#5-7-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 45
13:51:55.048 [org.springframework.kafka.KafkaListenerEndpointContainer#3-4-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:51:55.048 [org.springframework.kafka.KafkaListenerEndpointContainer#1-5-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 45
13:51:55.048 [org.springframework.kafka.KafkaListenerEndpointContainer#3-4-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:51:55.048 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:51:55.048 [org.springframework.kafka.KafkaListenerEndpointContainer#7-6-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 45
13:51:55.048 [org.springframework.kafka.KafkaListenerEndpointContainer#6-3-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:51:55.048 [org.springframework.kafka.KafkaListenerEndpointContainer#7-6-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:51:55.048 [org.springframework.kafka.KafkaListenerEndpointContainer#5-8-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:51:55.048 [org.springframework.kafka.KafkaListenerEndpointContainer#4-6-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:51:55.048 [org.springframework.kafka.KafkaListenerEndpointContainer#7-7-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:51:55.048 [org.springframework.kafka.KafkaListenerEndpointContainer#4-6-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:51:55.048 [org.springframework.kafka.KafkaListenerEndpointContainer#6-7-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 45
13:51:55.048 [org.springframework.kafka.KafkaListenerEndpointContainer#7-5-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 45
13:51:55.048 [org.springframework.kafka.KafkaListenerEndpointContainer#3-3-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:51:55.048 [org.springframework.kafka.KafkaListenerEndpointContainer#0-6-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:51:55.048 [org.springframework.kafka.KafkaListenerEndpointContainer#3-8-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 45
13:51:55.048 [org.springframework.kafka.KafkaListenerEndpointContainer#6-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 45
13:51:55.048 [org.springframework.kafka.KafkaListenerEndpointContainer#0-7-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:51:55.048 [org.springframework.kafka.KafkaListenerEndpointContainer#6-4-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:51:55.048 [org.springframework.kafka.KafkaListenerEndpointContainer#4-5-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 45
13:51:55.048 [org.springframework.kafka.KafkaListenerEndpointContainer#3-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 45
13:51:55.048 [org.springframework.kafka.KafkaListenerEndpointContainer#4-5-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:51:55.048 [org.springframework.kafka.KafkaListenerEndpointContainer#5-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 45
13:51:55.048 [org.springframework.kafka.KafkaListenerEndpointContainer#4-3-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:51:55.048 [org.springframework.kafka.KafkaListenerEndpointContainer#5-0-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [exchange-trade-0] for group default-group
13:51:55.048 [org.springframework.kafka.KafkaListenerEndpointContainer#6-6-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:51:55.048 [org.springframework.kafka.KafkaListenerEndpointContainer#3-7-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:51:55.048 [org.springframework.kafka.KafkaListenerEndpointContainer#3-6-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 45
13:51:55.048 [org.springframework.kafka.KafkaListenerEndpointContainer#7-2-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 45
13:51:55.048 [org.springframework.kafka.KafkaListenerEndpointContainer#1-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 45
13:51:55.048 [org.springframework.kafka.KafkaListenerEndpointContainer#4-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 45
13:51:55.048 [org.springframework.kafka.KafkaListenerEndpointContainer#5-6-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:51:55.048 [org.springframework.kafka.KafkaListenerEndpointContainer#5-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 45
13:51:55.048 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 45
13:51:55.048 [org.springframework.kafka.KafkaListenerEndpointContainer#6-8-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 45
13:51:55.048 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [exchange-order-completed-0] for group default-group
13:51:55.048 [org.springframework.kafka.KafkaListenerEndpointContainer#7-4-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:51:55.048 [org.springframework.kafka.KafkaListenerEndpointContainer#2-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 45
13:51:55.048 [org.springframework.kafka.KafkaListenerEndpointContainer#1-7-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 45
13:51:55.048 [org.springframework.kafka.KafkaListenerEndpointContainer#2-8-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:51:55.048 [org.springframework.kafka.KafkaListenerEndpointContainer#1-7-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:51:55.048 [org.springframework.kafka.KafkaListenerEndpointContainer#1-8-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:51:55.048 [org.springframework.kafka.KafkaListenerEndpointContainer#2-8-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:51:55.048 [org.springframework.kafka.KafkaListenerEndpointContainer#0-8-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 45
13:51:55.048 [org.springframework.kafka.KafkaListenerEndpointContainer#1-5-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:51:55.048 [org.springframework.kafka.KafkaListenerEndpointContainer#5-7-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:51:55.048 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:51:55.048 [org.springframework.kafka.KafkaListenerEndpointContainer#7-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 45
13:51:55.048 [org.springframework.kafka.KafkaListenerEndpointContainer#1-4-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:51:55.048 [org.springframework.kafka.KafkaListenerEndpointContainer#6-7-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:51:55.048 [org.springframework.kafka.KafkaListenerEndpointContainer#0-5-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:51:55.048 [org.springframework.kafka.KafkaListenerEndpointContainer#7-5-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:51:55.048 [org.springframework.kafka.KafkaListenerEndpointContainer#6-2-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 45
13:51:55.048 [org.springframework.kafka.KafkaListenerEndpointContainer#4-7-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 45
13:51:55.048 [org.springframework.kafka.KafkaListenerEndpointContainer#3-8-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:51:55.061 [org.springframework.kafka.KafkaListenerEndpointContainer#4-7-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:51:55.048 [org.springframework.kafka.KafkaListenerEndpointContainer#7-2-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:51:55.048 [org.springframework.kafka.KafkaListenerEndpointContainer#1-3-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:51:55.048 [org.springframework.kafka.KafkaListenerEndpointContainer#7-3-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:51:55.061 [org.springframework.kafka.KafkaListenerEndpointContainer#1-3-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:51:55.061 [org.springframework.kafka.KafkaListenerEndpointContainer#7-3-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:51:55.048 [org.springframework.kafka.KafkaListenerEndpointContainer#6-4-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:51:55.048 [org.springframework.kafka.KafkaListenerEndpointContainer#2-6-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:51:55.048 [org.springframework.kafka.KafkaListenerEndpointContainer#6-8-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:51:55.048 [org.springframework.kafka.KafkaListenerEndpointContainer#4-2-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:51:55.061 [org.springframework.kafka.KafkaListenerEndpointContainer#6-8-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:51:55.048 [org.springframework.kafka.KafkaListenerEndpointContainer#0-8-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:51:55.048 [org.springframework.kafka.KafkaListenerEndpointContainer#5-7-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:51:55.061 [org.springframework.kafka.KafkaListenerEndpointContainer#0-8-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:51:55.048 [org.springframework.kafka.KafkaListenerEndpointContainer#7-1-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:51:55.048 [org.springframework.kafka.KafkaListenerEndpointContainer#6-7-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:51:55.048 [org.springframework.kafka.KafkaListenerEndpointContainer#4-5-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:51:55.048 [org.springframework.kafka.KafkaListenerEndpointContainer#6-5-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 45
13:51:55.061 [org.springframework.kafka.KafkaListenerEndpointContainer#3-8-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:51:55.061 [org.springframework.kafka.KafkaListenerEndpointContainer#6-5-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:51:55.048 [org.springframework.kafka.KafkaListenerEndpointContainer#4-8-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 45
13:51:55.048 [org.springframework.kafka.KafkaListenerEndpointContainer#3-2-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:51:55.061 [org.springframework.kafka.KafkaListenerEndpointContainer#4-8-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:51:55.061 [org.springframework.kafka.KafkaListenerEndpointContainer#3-2-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:51:55.048 [org.springframework.kafka.KafkaListenerEndpointContainer#2-4-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:51:55.048 [org.springframework.kafka.KafkaListenerEndpointContainer#2-5-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 45
13:51:55.048 [org.springframework.kafka.KafkaListenerEndpointContainer#7-4-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:51:55.048 [org.springframework.kafka.KafkaListenerEndpointContainer#2-1-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:51:55.048 [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 45
13:51:55.048 [org.springframework.kafka.KafkaListenerEndpointContainer#5-2-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:51:55.061 [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [exchange-waiting-order-cancel-0] for group default-group
13:51:55.048 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:51:55.048 [org.springframework.kafka.KafkaListenerEndpointContainer#1-5-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:51:55.048 [org.springframework.kafka.KafkaListenerEndpointContainer#7-6-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:51:55.048 [org.springframework.kafka.KafkaListenerEndpointContainer#3-3-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:51:55.061 [org.springframework.kafka.KafkaListenerEndpointContainer#7-5-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:51:55.048 [org.springframework.kafka.KafkaListenerEndpointContainer#3-1-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:51:55.048 [org.springframework.kafka.KafkaListenerEndpointContainer#3-6-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:51:55.061 [org.springframework.kafka.KafkaListenerEndpointContainer#3-6-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:51:55.061 [org.springframework.kafka.KafkaListenerEndpointContainer#4-7-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:51:55.061 [org.springframework.kafka.KafkaListenerEndpointContainer#7-2-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:51:55.048 [org.springframework.kafka.KafkaListenerEndpointContainer#5-6-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:51:55.048 [org.springframework.kafka.KafkaListenerEndpointContainer#4-0-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [exchange-trade-plate-0] for group default-group
13:51:55.048 [org.springframework.kafka.KafkaListenerEndpointContainer#5-3-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:51:55.048 [org.springframework.kafka.KafkaListenerEndpointContainer#1-7-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:51:55.061 [org.springframework.kafka.KafkaListenerEndpointContainer#7-1-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:51:55.061 [org.springframework.kafka.KafkaListenerEndpointContainer#6-2-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:51:55.061 [org.springframework.kafka.KafkaListenerEndpointContainer#6-5-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:51:55.061 [org.springframework.kafka.KafkaListenerEndpointContainer#4-8-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:51:55.061 [org.springframework.kafka.KafkaListenerEndpointContainer#2-4-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:51:55.061 [org.springframework.kafka.KafkaListenerEndpointContainer#2-5-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:51:55.061 [org.springframework.kafka.KafkaListenerEndpointContainer#2-1-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:51:55.061 [org.springframework.kafka.KafkaListenerEndpointContainer#5-2-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:51:55.061 [org.springframework.kafka.KafkaListenerEndpointContainer#3-1-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:51:55.061 [org.springframework.kafka.KafkaListenerEndpointContainer#5-3-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:51:55.061 [org.springframework.kafka.KafkaListenerEndpointContainer#6-2-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:51:55.061 [org.springframework.kafka.KafkaListenerEndpointContainer#2-5-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:51:55.119 [org.springframework.kafka.KafkaListenerEndpointContainer#7-0-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[exchange-waiting-order-0]
13:51:55.119 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[exchange-order-cancel-success-0]
13:51:55.119 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[exchange-market-symbol-0]
13:51:55.119 [org.springframework.kafka.KafkaListenerEndpointContainer#5-0-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[exchange-trade-0]
13:51:55.119 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[exchange-trade-mocker-0]
13:51:55.148 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[exchange-order-completed-0]
13:51:55.148 [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[exchange-waiting-order-cancel-0]
13:51:55.148 [org.springframework.kafka.KafkaListenerEndpointContainer#4-0-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[exchange-trade-plate-0]
13:52:00.022 [MessageBroker-6] INFO  cn.ztuo.bitrade.job.KLineGeneratorJob - 分钟K线:Tue Sep 10 13:52:00 CST 2019
13:52:00.022 [MessageBroker-6] INFO  cn.ztuo.bitrade.job.KLineGeneratorJob - 生成BTC/USDT分钟k线:{}
13:52:00.022 [MessageBroker-6] INFO  cn.ztuo.bitrade.processor.DefaultCoinProcessor - auto generate 1min kline in 13:52:00,data={"closePrice":0,"count":0,"highestPrice":0,"lowestPrice":0,"openPrice":0,"period":"1min","time":1568094720000,"turnover":0,"volume":0}
13:53:00.015 [MessageBroker-7] INFO  cn.ztuo.bitrade.job.KLineGeneratorJob - 分钟K线:Tue Sep 10 13:53:00 CST 2019
13:53:00.015 [MessageBroker-7] INFO  cn.ztuo.bitrade.job.KLineGeneratorJob - 生成BTC/USDT分钟k线:{}
13:53:00.015 [MessageBroker-7] INFO  cn.ztuo.bitrade.processor.DefaultCoinProcessor - auto generate 1min kline in 13:53:00,data={"closePrice":0,"count":0,"highestPrice":0,"lowestPrice":0,"openPrice":0,"period":"1min","time":1568094780000,"turnover":0,"volume":0}
13:54:00.020 [MessageBroker-1] INFO  cn.ztuo.bitrade.job.KLineGeneratorJob - 分钟K线:Tue Sep 10 13:54:00 CST 2019
13:54:00.020 [MessageBroker-1] INFO  cn.ztuo.bitrade.job.KLineGeneratorJob - 生成BTC/USDT分钟k线:{}
13:54:00.020 [MessageBroker-1] INFO  cn.ztuo.bitrade.processor.DefaultCoinProcessor - auto generate 1min kline in 13:54:00,data={"closePrice":0,"count":0,"highestPrice":0,"lowestPrice":0,"openPrice":0,"period":"1min","time":1568094840000,"turnover":0,"volume":0}
13:55:00.037 [MessageBroker-2] INFO  cn.ztuo.bitrade.job.KLineGeneratorJob - 分钟K线:Tue Sep 10 13:55:00 CST 2019
13:55:00.037 [MessageBroker-2] INFO  cn.ztuo.bitrade.job.KLineGeneratorJob - 生成BTC/USDT分钟k线:{}
13:55:00.039 [MessageBroker-2] INFO  cn.ztuo.bitrade.processor.DefaultCoinProcessor - auto generate 1min kline in 13:55:00,data={"closePrice":0,"count":0,"highestPrice":0,"lowestPrice":0,"openPrice":0,"period":"1min","time":1568094900000,"turnover":0,"volume":0}
13:55:00.039 [MessageBroker-2] INFO  cn.ztuo.bitrade.processor.DefaultCoinProcessor - time range from 2019-09-10 13:50:00 to 2019-09-10 13:55:00
13:56:00.020 [MessageBroker-1] INFO  cn.ztuo.bitrade.job.KLineGeneratorJob - 分钟K线:Tue Sep 10 13:56:00 CST 2019
13:56:00.020 [MessageBroker-1] INFO  cn.ztuo.bitrade.job.KLineGeneratorJob - 生成BTC/USDT分钟k线:{}
13:56:00.020 [MessageBroker-1] INFO  cn.ztuo.bitrade.processor.DefaultCoinProcessor - auto generate 1min kline in 13:56:00,data={"closePrice":0,"count":0,"highestPrice":0,"lowestPrice":0,"openPrice":0,"period":"1min","time":1568094960000,"turnover":0,"volume":0}
13:56:49.670 [AsyncResolver-bootstrap-executor-0] INFO  c.n.d.shared.resolver.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
13:56:53.197 [org.springframework.kafka.KafkaListenerEndpointContainer#7-3-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:56:53.197 [org.springframework.kafka.KafkaListenerEndpointContainer#0-5-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:56:53.197 [org.springframework.kafka.KafkaListenerEndpointContainer#6-6-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:56:53.197 [org.springframework.kafka.KafkaListenerEndpointContainer#0-5-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:56:53.197 [org.springframework.kafka.KafkaListenerEndpointContainer#1-2-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:56:53.197 [org.springframework.kafka.KafkaListenerEndpointContainer#0-5-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:56:53.197 [org.springframework.kafka.KafkaListenerEndpointContainer#1-2-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:56:53.197 [org.springframework.kafka.KafkaListenerEndpointContainer#7-3-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:56:53.197 [org.springframework.kafka.KafkaListenerEndpointContainer#6-6-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:56:53.197 [org.springframework.kafka.KafkaListenerEndpointContainer#7-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:56:53.197 [org.springframework.kafka.KafkaListenerEndpointContainer#6-6-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:56:53.197 [org.springframework.kafka.KafkaListenerEndpointContainer#1-2-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:56:53.197 [org.springframework.kafka.KafkaListenerEndpointContainer#1-8-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:56:53.197 [org.springframework.kafka.KafkaListenerEndpointContainer#1-8-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:56:53.197 [org.springframework.kafka.KafkaListenerEndpointContainer#1-8-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:56:53.197 [org.springframework.kafka.KafkaListenerEndpointContainer#1-3-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:56:53.197 [org.springframework.kafka.KafkaListenerEndpointContainer#1-3-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:56:53.197 [org.springframework.kafka.KafkaListenerEndpointContainer#5-2-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:56:53.197 [org.springframework.kafka.KafkaListenerEndpointContainer#1-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:56:53.197 [org.springframework.kafka.KafkaListenerEndpointContainer#5-2-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:56:53.197 [org.springframework.kafka.KafkaListenerEndpointContainer#5-2-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:56:53.197 [org.springframework.kafka.KafkaListenerEndpointContainer#4-6-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:56:53.197 [org.springframework.kafka.KafkaListenerEndpointContainer#4-6-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:56:53.197 [org.springframework.kafka.KafkaListenerEndpointContainer#4-6-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:56:53.197 [org.springframework.kafka.KafkaListenerEndpointContainer#3-3-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:56:53.197 [org.springframework.kafka.KafkaListenerEndpointContainer#3-3-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:56:53.197 [org.springframework.kafka.KafkaListenerEndpointContainer#3-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:56:53.229 [org.springframework.kafka.KafkaListenerEndpointContainer#2-6-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:56:53.229 [org.springframework.kafka.KafkaListenerEndpointContainer#4-5-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:56:53.229 [org.springframework.kafka.KafkaListenerEndpointContainer#4-5-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:56:53.229 [org.springframework.kafka.KafkaListenerEndpointContainer#4-5-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:56:53.229 [org.springframework.kafka.KafkaListenerEndpointContainer#7-8-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:56:53.229 [org.springframework.kafka.KafkaListenerEndpointContainer#7-8-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:56:53.229 [org.springframework.kafka.KafkaListenerEndpointContainer#7-8-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:56:53.229 [org.springframework.kafka.KafkaListenerEndpointContainer#5-3-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:56:53.229 [org.springframework.kafka.KafkaListenerEndpointContainer#5-3-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:56:53.229 [org.springframework.kafka.KafkaListenerEndpointContainer#5-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:56:53.229 [org.springframework.kafka.KafkaListenerEndpointContainer#2-5-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:56:53.229 [org.springframework.kafka.KafkaListenerEndpointContainer#2-5-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:56:53.229 [org.springframework.kafka.KafkaListenerEndpointContainer#2-5-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:56:53.229 [org.springframework.kafka.KafkaListenerEndpointContainer#6-5-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:56:53.229 [org.springframework.kafka.KafkaListenerEndpointContainer#6-5-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:56:53.229 [org.springframework.kafka.KafkaListenerEndpointContainer#6-5-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:56:53.229 [org.springframework.kafka.KafkaListenerEndpointContainer#5-8-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:56:53.229 [org.springframework.kafka.KafkaListenerEndpointContainer#5-8-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:56:53.229 [org.springframework.kafka.KafkaListenerEndpointContainer#5-8-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:56:53.229 [org.springframework.kafka.KafkaListenerEndpointContainer#2-6-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:56:53.229 [org.springframework.kafka.KafkaListenerEndpointContainer#2-6-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:56:53.229 [org.springframework.kafka.KafkaListenerEndpointContainer#3-2-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:56:53.229 [org.springframework.kafka.KafkaListenerEndpointContainer#3-2-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:56:53.229 [org.springframework.kafka.KafkaListenerEndpointContainer#3-2-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:56:53.229 [org.springframework.kafka.KafkaListenerEndpointContainer#0-6-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:56:53.229 [org.springframework.kafka.KafkaListenerEndpointContainer#7-2-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:56:53.229 [org.springframework.kafka.KafkaListenerEndpointContainer#0-6-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:56:53.229 [org.springframework.kafka.KafkaListenerEndpointContainer#7-2-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:56:53.229 [org.springframework.kafka.KafkaListenerEndpointContainer#0-6-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:56:53.229 [org.springframework.kafka.KafkaListenerEndpointContainer#7-2-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:56:53.229 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [exchange-trade-mocker-0] for group default-group
13:56:53.244 [org.springframework.kafka.KafkaListenerEndpointContainer#1-4-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:56:53.244 [org.springframework.kafka.KafkaListenerEndpointContainer#1-4-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:56:53.244 [org.springframework.kafka.KafkaListenerEndpointContainer#1-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:56:53.244 [org.springframework.kafka.KafkaListenerEndpointContainer#3-5-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:56:53.244 [org.springframework.kafka.KafkaListenerEndpointContainer#3-5-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:56:53.244 [org.springframework.kafka.KafkaListenerEndpointContainer#3-5-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:56:53.244 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:56:53.244 [org.springframework.kafka.KafkaListenerEndpointContainer#6-1-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:56:53.244 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:56:53.244 [org.springframework.kafka.KafkaListenerEndpointContainer#6-1-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:56:53.244 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:56:53.244 [org.springframework.kafka.KafkaListenerEndpointContainer#6-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:56:53.244 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [exchange-market-symbol-0] for group default-group
13:56:53.244 [org.springframework.kafka.KafkaListenerEndpointContainer#2-7-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:56:53.244 [org.springframework.kafka.KafkaListenerEndpointContainer#2-7-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:56:53.244 [org.springframework.kafka.KafkaListenerEndpointContainer#7-5-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:56:53.244 [org.springframework.kafka.KafkaListenerEndpointContainer#2-7-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:56:53.244 [org.springframework.kafka.KafkaListenerEndpointContainer#6-7-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:56:53.244 [org.springframework.kafka.KafkaListenerEndpointContainer#7-5-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:56:53.244 [org.springframework.kafka.KafkaListenerEndpointContainer#6-7-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:56:53.244 [org.springframework.kafka.KafkaListenerEndpointContainer#7-5-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:56:53.244 [org.springframework.kafka.KafkaListenerEndpointContainer#6-7-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:56:53.244 [org.springframework.kafka.KafkaListenerEndpointContainer#0-7-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:56:53.244 [org.springframework.kafka.KafkaListenerEndpointContainer#5-4-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:56:53.244 [org.springframework.kafka.KafkaListenerEndpointContainer#0-7-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:56:53.244 [org.springframework.kafka.KafkaListenerEndpointContainer#5-4-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:56:53.244 [org.springframework.kafka.KafkaListenerEndpointContainer#0-7-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:56:53.244 [org.springframework.kafka.KafkaListenerEndpointContainer#5-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:56:53.260 [org.springframework.kafka.KafkaListenerEndpointContainer#2-8-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:56:53.260 [org.springframework.kafka.KafkaListenerEndpointContainer#2-8-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:56:53.260 [org.springframework.kafka.KafkaListenerEndpointContainer#2-8-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:56:53.260 [org.springframework.kafka.KafkaListenerEndpointContainer#6-2-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:56:53.260 [org.springframework.kafka.KafkaListenerEndpointContainer#6-2-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:56:53.260 [org.springframework.kafka.KafkaListenerEndpointContainer#6-2-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:56:53.260 [org.springframework.kafka.KafkaListenerEndpointContainer#7-4-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:56:53.260 [org.springframework.kafka.KafkaListenerEndpointContainer#7-4-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:56:53.260 [org.springframework.kafka.KafkaListenerEndpointContainer#7-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:56:53.260 [org.springframework.kafka.KafkaListenerEndpointContainer#1-5-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:56:53.260 [org.springframework.kafka.KafkaListenerEndpointContainer#1-5-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:56:53.260 [org.springframework.kafka.KafkaListenerEndpointContainer#1-5-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:56:53.260 [org.springframework.kafka.KafkaListenerEndpointContainer#4-7-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:56:53.260 [org.springframework.kafka.KafkaListenerEndpointContainer#4-7-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:56:53.260 [org.springframework.kafka.KafkaListenerEndpointContainer#4-7-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:56:53.260 [org.springframework.kafka.KafkaListenerEndpointContainer#4-0-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [exchange-trade-plate-0] for group default-group
13:56:53.260 [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [exchange-waiting-order-cancel-0] for group default-group
13:56:53.260 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:56:53.260 [org.springframework.kafka.KafkaListenerEndpointContainer#4-2-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:56:53.260 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:56:53.260 [org.springframework.kafka.KafkaListenerEndpointContainer#2-2-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:56:53.260 [org.springframework.kafka.KafkaListenerEndpointContainer#5-5-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:56:53.260 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:56:53.260 [org.springframework.kafka.KafkaListenerEndpointContainer#4-1-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:56:53.260 [org.springframework.kafka.KafkaListenerEndpointContainer#3-4-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:56:53.260 [org.springframework.kafka.KafkaListenerEndpointContainer#5-5-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:56:53.260 [org.springframework.kafka.KafkaListenerEndpointContainer#4-2-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:56:53.260 [org.springframework.kafka.KafkaListenerEndpointContainer#2-2-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:56:53.260 [org.springframework.kafka.KafkaListenerEndpointContainer#2-2-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:56:53.260 [org.springframework.kafka.KafkaListenerEndpointContainer#4-2-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:56:53.260 [org.springframework.kafka.KafkaListenerEndpointContainer#4-1-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:56:53.260 [org.springframework.kafka.KafkaListenerEndpointContainer#4-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:56:53.260 [org.springframework.kafka.KafkaListenerEndpointContainer#3-4-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:56:53.260 [org.springframework.kafka.KafkaListenerEndpointContainer#3-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:56:53.260 [org.springframework.kafka.KafkaListenerEndpointContainer#5-5-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:56:53.275 [org.springframework.kafka.KafkaListenerEndpointContainer#1-1-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:56:53.275 [org.springframework.kafka.KafkaListenerEndpointContainer#3-6-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:56:53.275 [org.springframework.kafka.KafkaListenerEndpointContainer#6-8-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:56:53.275 [org.springframework.kafka.KafkaListenerEndpointContainer#0-8-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:56:53.275 [org.springframework.kafka.KafkaListenerEndpointContainer#6-8-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:56:53.275 [org.springframework.kafka.KafkaListenerEndpointContainer#3-1-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:56:53.275 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:56:53.275 [org.springframework.kafka.KafkaListenerEndpointContainer#3-1-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:56:53.275 [org.springframework.kafka.KafkaListenerEndpointContainer#7-6-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:56:53.275 [org.springframework.kafka.KafkaListenerEndpointContainer#3-6-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:56:53.275 [org.springframework.kafka.KafkaListenerEndpointContainer#4-3-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:56:53.275 [org.springframework.kafka.KafkaListenerEndpointContainer#3-6-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:56:53.275 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:56:53.275 [org.springframework.kafka.KafkaListenerEndpointContainer#2-1-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:56:53.275 [org.springframework.kafka.KafkaListenerEndpointContainer#0-8-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:56:53.275 [org.springframework.kafka.KafkaListenerEndpointContainer#0-8-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:56:53.275 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:56:53.275 [org.springframework.kafka.KafkaListenerEndpointContainer#7-6-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:56:53.275 [org.springframework.kafka.KafkaListenerEndpointContainer#7-6-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:56:53.275 [org.springframework.kafka.KafkaListenerEndpointContainer#3-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:56:53.275 [org.springframework.kafka.KafkaListenerEndpointContainer#1-7-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:56:53.275 [org.springframework.kafka.KafkaListenerEndpointContainer#1-1-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:56:53.275 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:56:53.275 [org.springframework.kafka.KafkaListenerEndpointContainer#1-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:56:53.275 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:56:53.275 [org.springframework.kafka.KafkaListenerEndpointContainer#6-8-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:56:53.275 [org.springframework.kafka.KafkaListenerEndpointContainer#4-3-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:56:53.275 [org.springframework.kafka.KafkaListenerEndpointContainer#1-7-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:56:53.275 [org.springframework.kafka.KafkaListenerEndpointContainer#2-1-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:56:53.275 [org.springframework.kafka.KafkaListenerEndpointContainer#1-7-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:56:53.275 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:56:53.275 [org.springframework.kafka.KafkaListenerEndpointContainer#4-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:56:53.275 [org.springframework.kafka.KafkaListenerEndpointContainer#2-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:56:53.298 [org.springframework.kafka.KafkaListenerEndpointContainer#6-3-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:56:53.298 [org.springframework.kafka.KafkaListenerEndpointContainer#6-3-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:56:53.298 [org.springframework.kafka.KafkaListenerEndpointContainer#7-7-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:56:53.298 [org.springframework.kafka.KafkaListenerEndpointContainer#7-7-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:56:53.298 [org.springframework.kafka.KafkaListenerEndpointContainer#2-4-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:56:53.298 [org.springframework.kafka.KafkaListenerEndpointContainer#2-4-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:56:53.298 [org.springframework.kafka.KafkaListenerEndpointContainer#2-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:56:53.298 [org.springframework.kafka.KafkaListenerEndpointContainer#5-6-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:56:53.298 [org.springframework.kafka.KafkaListenerEndpointContainer#5-6-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:56:53.298 [org.springframework.kafka.KafkaListenerEndpointContainer#5-6-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:56:53.298 [org.springframework.kafka.KafkaListenerEndpointContainer#5-7-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:56:53.298 [org.springframework.kafka.KafkaListenerEndpointContainer#4-4-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:56:53.298 [org.springframework.kafka.KafkaListenerEndpointContainer#5-7-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:56:53.298 [org.springframework.kafka.KafkaListenerEndpointContainer#4-4-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:56:53.298 [org.springframework.kafka.KafkaListenerEndpointContainer#5-7-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:56:53.298 [org.springframework.kafka.KafkaListenerEndpointContainer#4-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:56:53.298 [org.springframework.kafka.KafkaListenerEndpointContainer#3-7-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:56:53.298 [org.springframework.kafka.KafkaListenerEndpointContainer#3-7-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:56:53.298 [org.springframework.kafka.KafkaListenerEndpointContainer#5-1-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:56:53.298 [org.springframework.kafka.KafkaListenerEndpointContainer#6-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:56:53.298 [org.springframework.kafka.KafkaListenerEndpointContainer#7-7-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:56:53.298 [org.springframework.kafka.KafkaListenerEndpointContainer#5-1-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:56:53.298 [org.springframework.kafka.KafkaListenerEndpointContainer#5-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:56:53.298 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [exchange-order-cancel-success-0] for group default-group
13:56:53.298 [org.springframework.kafka.KafkaListenerEndpointContainer#7-0-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [exchange-waiting-order-0] for group default-group
13:56:53.298 [org.springframework.kafka.KafkaListenerEndpointContainer#5-0-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [exchange-trade-0] for group default-group
13:56:53.298 [org.springframework.kafka.KafkaListenerEndpointContainer#3-7-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:56:53.298 [org.springframework.kafka.KafkaListenerEndpointContainer#7-1-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:56:53.298 [org.springframework.kafka.KafkaListenerEndpointContainer#6-4-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:56:53.298 [org.springframework.kafka.KafkaListenerEndpointContainer#2-3-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:56:53.298 [org.springframework.kafka.KafkaListenerEndpointContainer#7-1-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:56:53.298 [org.springframework.kafka.KafkaListenerEndpointContainer#2-3-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:56:53.298 [org.springframework.kafka.KafkaListenerEndpointContainer#6-4-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:56:53.298 [org.springframework.kafka.KafkaListenerEndpointContainer#2-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:56:53.298 [org.springframework.kafka.KafkaListenerEndpointContainer#6-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:56:53.298 [org.springframework.kafka.KafkaListenerEndpointContainer#1-6-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:56:53.298 [org.springframework.kafka.KafkaListenerEndpointContainer#7-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:56:53.298 [org.springframework.kafka.KafkaListenerEndpointContainer#1-6-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:56:53.298 [org.springframework.kafka.KafkaListenerEndpointContainer#1-6-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:56:53.298 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [exchange-order-completed-0] for group default-group
13:56:53.460 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[exchange-trade-mocker-0]
13:56:53.460 [org.springframework.kafka.KafkaListenerEndpointContainer#5-0-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[exchange-trade-0]
13:56:53.460 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:56:53.460 [org.springframework.kafka.KafkaListenerEndpointContainer#5-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:56:53.476 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[exchange-order-completed-0]
13:56:53.476 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[exchange-market-symbol-0]
13:56:53.476 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:56:53.476 [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[exchange-waiting-order-cancel-0]
13:56:53.476 [org.springframework.kafka.KafkaListenerEndpointContainer#7-0-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[exchange-waiting-order-0]
13:56:53.476 [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:56:53.476 [org.springframework.kafka.KafkaListenerEndpointContainer#4-0-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[exchange-trade-plate-0]
13:56:53.476 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[exchange-order-cancel-success-0]
13:56:53.476 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:56:53.476 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:56:53.476 [org.springframework.kafka.KafkaListenerEndpointContainer#7-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:56:53.476 [org.springframework.kafka.KafkaListenerEndpointContainer#4-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:56:55.164 [org.springframework.kafka.KafkaListenerEndpointContainer#3-8-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:56:55.164 [org.springframework.kafka.KafkaListenerEndpointContainer#3-8-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:56:55.164 [org.springframework.kafka.KafkaListenerEndpointContainer#3-8-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:56:55.254 [org.springframework.kafka.KafkaListenerEndpointContainer#4-8-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:56:55.254 [org.springframework.kafka.KafkaListenerEndpointContainer#4-8-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:56:55.254 [org.springframework.kafka.KafkaListenerEndpointContainer#4-8-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#1-6-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 46
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#3-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 46
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#2-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 46
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#6-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 46
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#3-7-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 46
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#4-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 46
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#5-5-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 46
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#5-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 46
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#3-5-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 46
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#5-5-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#2-7-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 46
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#0-5-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 46
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#2-7-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#5-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 46
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#6-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 46
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#5-1-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#4-2-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 46
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#3-7-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#4-2-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 46
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#1-2-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 46
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#2-2-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 46
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#2-6-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 46
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#7-8-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 46
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#2-6-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#5-4-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#2-7-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#7-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 46
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#5-1-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#6-3-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#5-8-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 46
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#7-7-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 46
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#2-2-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 46
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#6-6-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 46
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#7-8-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#6-6-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#7-8-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#6-6-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 46
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#7-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 46
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#7-3-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#7-0-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [exchange-waiting-order-0] for group default-group
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#5-8-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#4-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 46
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#5-8-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#2-2-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#0-7-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 46
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#0-7-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#1-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 46
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 46
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#1-4-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#1-4-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [exchange-market-symbol-0] for group default-group
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#3-4-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 46
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#3-2-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 46
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#2-3-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#3-2-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#2-3-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#1-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 46
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#4-1-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#0-7-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#4-1-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#1-6-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#2-8-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 46
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#1-6-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#2-8-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#3-4-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#0-6-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 46
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#6-1-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#2-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 46
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#3-5-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#3-2-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#5-5-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#4-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 46
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#4-4-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#4-3-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 46
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#0-5-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#0-5-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#3-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 46
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#3-7-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#3-3-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#4-2-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#0-6-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [exchange-order-cancel-success-0] for group default-group
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#2-4-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#3-5-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#2-4-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#2-6-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#7-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 46
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#4-3-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#3-3-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#1-2-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [exchange-trade-mocker-0] for group default-group
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#7-6-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 46
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#1-1-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#2-8-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#5-6-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 46
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#5-4-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#5-6-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#6-3-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#7-7-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#7-3-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#0-6-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#4-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 46
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#7-6-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#4-0-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [exchange-trade-plate-0] for group default-group
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#7-6-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#6-1-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#5-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 46
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#5-3-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#5-2-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 46
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#4-4-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#1-5-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 46
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#1-5-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#1-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 46
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 46
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#0-8-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 46
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#1-8-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 46
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#1-2-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#3-6-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 46
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#1-1-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#7-4-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#5-6-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#5-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 46
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#5-7-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 46
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#1-3-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#5-7-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#4-6-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 46
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#5-7-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#4-6-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#3-6-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#7-7-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#3-6-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#5-3-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#1-8-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#6-5-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 46
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#5-2-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#5-0-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [exchange-trade-0] for group default-group
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#1-5-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#3-8-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 46
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#0-8-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#4-8-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 46
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#0-8-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#7-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 46
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#6-2-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 46
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#6-7-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 46
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#6-2-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#2-5-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 46
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#6-2-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#7-2-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 46
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 46
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#4-7-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 46
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#1-8-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#3-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 46
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#7-4-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#3-1-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#7-1-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#6-7-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#7-1-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#6-7-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#6-5-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#5-2-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#1-3-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#7-5-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 46
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#4-6-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#7-5-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#6-8-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 46
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#3-8-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#3-1-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#3-8-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#4-8-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#2-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 46
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#4-8-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#7-2-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#1-7-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 46
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#4-7-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#7-5-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#4-7-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#7-2-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#6-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 46
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#1-7-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#6-4-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#2-5-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#2-5-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#6-5-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [exchange-order-completed-0] for group default-group
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 46
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#4-5-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 46
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#6-8-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#4-5-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#6-8-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#4-5-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#2-1-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#1-7-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#2-1-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#6-4-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:56:56.202 [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [exchange-waiting-order-cancel-0] for group default-group
13:56:56.272 [org.springframework.kafka.KafkaListenerEndpointContainer#7-0-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[exchange-waiting-order-0]
13:56:56.272 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[exchange-order-cancel-success-0]
13:56:56.287 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[exchange-trade-mocker-0]
13:56:56.287 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[exchange-market-symbol-0]
13:56:56.287 [org.springframework.kafka.KafkaListenerEndpointContainer#5-0-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[exchange-trade-0]
13:56:56.287 [org.springframework.kafka.KafkaListenerEndpointContainer#4-0-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[exchange-trade-plate-0]
13:56:56.304 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[exchange-order-completed-0]
13:56:56.304 [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[exchange-waiting-order-cancel-0]
13:57:00.013 [MessageBroker-9] INFO  cn.ztuo.bitrade.job.KLineGeneratorJob - 分钟K线:Tue Sep 10 13:57:00 CST 2019
13:57:00.013 [MessageBroker-9] INFO  cn.ztuo.bitrade.job.KLineGeneratorJob - 生成BTC/USDT分钟k线:{}
13:57:00.013 [MessageBroker-9] INFO  cn.ztuo.bitrade.processor.DefaultCoinProcessor - auto generate 1min kline in 13:57:00,data={"closePrice":0,"count":0,"highestPrice":0,"lowestPrice":0,"openPrice":0,"period":"1min","time":1568095020000,"turnover":0,"volume":0}
13:57:41.350 [Thread-36] INFO  o.s.b.c.e.AnnotationConfigEmbeddedWebApplicationContext - Closing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@7ad54c55: startup date [Tue Sep 10 13:46:37 CST 2019]; parent: org.springframework.context.annotation.AnnotationConfigApplicationContext@6bbe2511
13:57:41.351 [Thread-36] INFO  o.s.c.n.e.serviceregistry.EurekaServiceRegistry - Unregistering application bitrade-market with eureka with status DOWN
13:57:41.351 [Thread-36] WARN  com.netflix.discovery.DiscoveryClient - Saw local status change event StatusChangeEvent [timestamp=1568095061351, current=DOWN, previous=UP]
13:57:41.351 [DiscoveryClient-InstanceInfoReplicator-0] INFO  com.netflix.discovery.DiscoveryClient - DiscoveryClient_BITRADE-MARKET/wxpker-computer:bitrade-market:6004: registering service...
13:57:41.353 [Thread-36] INFO  o.s.context.support.DefaultLifecycleProcessor - Stopping beans in phase 2147483647
13:57:41.353 [Thread-36] INFO  o.s.m.simp.broker.SimpleBrokerMessageHandler - Stopping...
13:57:41.353 [Thread-36] INFO  o.s.m.simp.broker.SimpleBrokerMessageHandler - BrokerAvailabilityEvent[available=false, SimpleBrokerMessageHandler [DefaultSubscriptionRegistry[cache[0 destination(s)], registry[0 sessions]]]]
13:57:41.353 [Thread-36] INFO  o.s.m.simp.broker.SimpleBrokerMessageHandler - Stopped.
13:57:41.353 [Thread-36] INFO  o.s.context.support.DefaultLifecycleProcessor - Stopping beans in phase 0
13:57:41.366 [DiscoveryClient-InstanceInfoReplicator-0] INFO  com.netflix.discovery.DiscoveryClient - DiscoveryClient_BITRADE-MARKET/wxpker-computer:bitrade-market:6004 - registration status: 204
13:57:41.376 [org.springframework.kafka.KafkaListenerEndpointContainer#2-8-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
13:57:41.376 [org.springframework.kafka.KafkaListenerEndpointContainer#2-6-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
13:57:41.376 [org.springframework.kafka.KafkaListenerEndpointContainer#6-2-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
13:57:41.376 [org.springframework.kafka.KafkaListenerEndpointContainer#6-4-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
13:57:41.376 [org.springframework.kafka.KafkaListenerEndpointContainer#4-1-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
13:57:41.376 [org.springframework.kafka.KafkaListenerEndpointContainer#4-8-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
13:57:41.376 [org.springframework.kafka.KafkaListenerEndpointContainer#7-3-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
13:57:41.376 [org.springframework.kafka.KafkaListenerEndpointContainer#2-4-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
13:57:41.376 [org.springframework.kafka.KafkaListenerEndpointContainer#5-1-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
13:57:41.376 [org.springframework.kafka.KafkaListenerEndpointContainer#7-7-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
13:57:41.376 [org.springframework.kafka.KafkaListenerEndpointContainer#4-4-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
13:57:41.376 [org.springframework.kafka.KafkaListenerEndpointContainer#3-1-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
13:57:41.376 [org.springframework.kafka.KafkaListenerEndpointContainer#4-2-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
13:57:41.376 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
13:57:41.376 [org.springframework.kafka.KafkaListenerEndpointContainer#2-2-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
13:57:41.376 [org.springframework.kafka.KafkaListenerEndpointContainer#7-6-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
13:57:41.376 [org.springframework.kafka.KafkaListenerEndpointContainer#7-2-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
13:57:41.376 [org.springframework.kafka.KafkaListenerEndpointContainer#7-8-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
13:57:41.391 [org.springframework.kafka.KafkaListenerEndpointContainer#4-3-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
13:57:41.391 [org.springframework.kafka.KafkaListenerEndpointContainer#7-4-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
13:57:41.391 [org.springframework.kafka.KafkaListenerEndpointContainer#6-5-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
13:57:41.391 [org.springframework.kafka.KafkaListenerEndpointContainer#0-6-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
13:57:41.391 [org.springframework.kafka.KafkaListenerEndpointContainer#1-3-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
13:57:41.391 [org.springframework.kafka.KafkaListenerEndpointContainer#4-7-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
13:57:41.391 [org.springframework.kafka.KafkaListenerEndpointContainer#6-3-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
13:57:41.391 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
13:57:41.391 [org.springframework.kafka.KafkaListenerEndpointContainer#5-2-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
13:57:41.391 [org.springframework.kafka.KafkaListenerEndpointContainer#6-7-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
13:57:41.391 [org.springframework.kafka.KafkaListenerEndpointContainer#1-6-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
13:57:41.391 [org.springframework.kafka.KafkaListenerEndpointContainer#5-8-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
13:57:41.391 [org.springframework.kafka.KafkaListenerEndpointContainer#1-5-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
13:57:41.391 [org.springframework.kafka.KafkaListenerEndpointContainer#5-6-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
13:57:41.391 [org.springframework.kafka.KafkaListenerEndpointContainer#5-7-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
13:57:41.391 [org.springframework.kafka.KafkaListenerEndpointContainer#3-6-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
13:57:41.391 [org.springframework.kafka.KafkaListenerEndpointContainer#1-2-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
13:57:41.391 [org.springframework.kafka.KafkaListenerEndpointContainer#4-5-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
13:57:41.391 [org.springframework.kafka.KafkaListenerEndpointContainer#0-8-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
13:57:41.396 [org.springframework.kafka.KafkaListenerEndpointContainer#0-5-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
13:57:41.396 [org.springframework.kafka.KafkaListenerEndpointContainer#6-8-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
13:57:41.396 [org.springframework.kafka.KafkaListenerEndpointContainer#2-7-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
13:57:41.396 [org.springframework.kafka.KafkaListenerEndpointContainer#3-5-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
13:57:41.396 [org.springframework.kafka.KafkaListenerEndpointContainer#7-1-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
13:57:41.396 [org.springframework.kafka.KafkaListenerEndpointContainer#5-3-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
13:57:41.396 [org.springframework.kafka.KafkaListenerEndpointContainer#5-5-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
13:57:41.396 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
13:57:41.396 [org.springframework.kafka.KafkaListenerEndpointContainer#3-2-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
13:57:41.396 [org.springframework.kafka.KafkaListenerEndpointContainer#2-5-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
13:57:41.396 [org.springframework.kafka.KafkaListenerEndpointContainer#5-4-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
13:57:41.396 [org.springframework.kafka.KafkaListenerEndpointContainer#1-1-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
13:57:41.396 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
13:57:41.396 [org.springframework.kafka.KafkaListenerEndpointContainer#1-7-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
13:57:41.396 [org.springframework.kafka.KafkaListenerEndpointContainer#0-7-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
13:57:41.396 [org.springframework.kafka.KafkaListenerEndpointContainer#6-1-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
13:57:41.396 [org.springframework.kafka.KafkaListenerEndpointContainer#3-7-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
13:57:41.396 [org.springframework.kafka.KafkaListenerEndpointContainer#7-5-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
13:57:41.396 [org.springframework.kafka.KafkaListenerEndpointContainer#2-3-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
13:57:41.396 [org.springframework.kafka.KafkaListenerEndpointContainer#3-8-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
13:57:41.396 [org.springframework.kafka.KafkaListenerEndpointContainer#6-6-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
13:57:41.396 [org.springframework.kafka.KafkaListenerEndpointContainer#3-3-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
13:57:41.396 [org.springframework.kafka.KafkaListenerEndpointContainer#2-1-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
13:57:41.396 [org.springframework.kafka.KafkaListenerEndpointContainer#3-4-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
13:57:41.396 [org.springframework.kafka.KafkaListenerEndpointContainer#1-8-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
13:57:41.396 [org.springframework.kafka.KafkaListenerEndpointContainer#4-6-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
13:57:41.396 [org.springframework.kafka.KafkaListenerEndpointContainer#1-4-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
13:57:41.647 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
13:57:41.647 [org.springframework.kafka.KafkaListenerEndpointContainer#7-0-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
13:57:41.647 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
13:57:41.647 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
13:57:41.665 [org.springframework.kafka.KafkaListenerEndpointContainer#5-0-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
13:57:41.732 [org.springframework.kafka.KafkaListenerEndpointContainer#4-0-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
13:57:41.732 [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
13:57:41.732 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] INFO  o.s.k.l.KafkaMessageListenerContainer$ListenerConsumer - Consumer stopped
13:57:41.732 [Thread-36] INFO  o.s.jmx.export.annotation.AnnotationMBeanExporter - Unregistering JMX-exposed beans on shutdown
13:57:41.732 [Thread-36] INFO  o.s.jmx.export.annotation.AnnotationMBeanExporter - Unregistering JMX-exposed beans
13:57:41.732 [Thread-36] INFO  com.netflix.discovery.DiscoveryClient - Shutting down DiscoveryClient ...
13:57:41.732 [Thread-36] INFO  com.netflix.discovery.DiscoveryClient - Unregistering ...
13:57:41.750 [Thread-36] INFO  com.netflix.discovery.DiscoveryClient - DiscoveryClient_BITRADE-MARKET/wxpker-computer:bitrade-market:6004 - deregister  status: 200
13:57:41.756 [Thread-36] INFO  com.netflix.discovery.DiscoveryClient - Completed shut down of DiscoveryClient
13:57:41.756 [Thread-36] INFO  o.s.scheduling.concurrent.ThreadPoolTaskExecutor - Shutting down ExecutorService 'brokerChannelExecutor'
13:57:41.756 [Thread-36] INFO  o.s.scheduling.concurrent.ThreadPoolTaskScheduler - Shutting down ExecutorService 'messageBrokerTaskScheduler'
13:57:41.781 [Thread-36] INFO  o.s.scheduling.concurrent.ThreadPoolTaskExecutor - Shutting down ExecutorService 'clientOutboundChannelExecutor'
13:57:41.781 [Thread-36] INFO  o.s.scheduling.concurrent.ThreadPoolTaskExecutor - Shutting down ExecutorService 'clientInboundChannelExecutor'
13:57:41.781 [Thread-36] INFO  o.s.orm.jpa.LocalContainerEntityManagerFactoryBean - Closing JPA EntityManagerFactory for persistence unit 'default'
13:57:41.781 [Thread-36] INFO  com.alibaba.druid.pool.DruidDataSource - {dataSource-1} closed
13:57:50.990 [main] INFO  o.s.c.a.AnnotationConfigApplicationContext - Refreshing org.springframework.context.annotation.AnnotationConfigApplicationContext@5b068087: startup date [Tue Sep 10 13:57:50 CST 2019]; root of context hierarchy
13:57:51.153 [background-preinit] INFO  org.hibernate.validator.internal.util.Version - HV000001: Hibernate Validator 5.3.6.Final
13:57:51.270 [main] INFO  o.s.b.f.a.AutowiredAnnotationBeanPostProcessor - JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
13:57:51.348 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'configurationPropertiesRebinderAutoConfiguration' of type [org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration$$EnhancerBySpringCGLIB$$6964a03e] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
13:57:52.113 [main] INFO  cn.ztuo.bitrade.MarketApplication - No active profile set, falling back to default profiles: default
13:57:52.130 [main] INFO  o.s.b.c.e.AnnotationConfigEmbeddedWebApplicationContext - Refreshing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@3c904f1e: startup date [Tue Sep 10 13:57:52 CST 2019]; parent: org.springframework.context.annotation.AnnotationConfigApplicationContext@5b068087
13:57:53.005 [main] INFO  o.s.b.factory.support.DefaultListableBeanFactory - Overriding bean definition for bean 'redisUtil' with a different definition: replacing [Generic bean: class [cn.ztuo.bitrade.util.RedisUtil]; scope=singleton; abstract=false; lazyInit=false; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=null; destroyMethodName=null; defined in file [F:\ztuo_v2\ztuo_framework\core\target\classes\cn\ztuo\bitrade\util\RedisUtil.class]] with [Root bean: class [null]; scope=; abstract=false; lazyInit=false; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=redisConfig; factoryMethodName=redisUtil; initMethodName=null; destroyMethodName=(inferred); defined in class path resource [cn/ztuo/bitrade/config/RedisConfig.class]]
13:57:53.221 [main] INFO  o.s.d.r.config.RepositoryConfigurationDelegate - Multiple Spring Data modules found, entering strict repository configuration mode!
13:57:53.610 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data JPA - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.OrderDetailAggregationRepository.
13:57:53.615 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data JPA - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.ExchangeOrderDetailRepository.
13:57:53.624 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data JPA - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.MemberLogDao.
13:57:53.675 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data JPA - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.TradeRepository.
13:57:53.687 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data JPA - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.ExchangeTradeRepository.
13:57:53.868 [main] INFO  o.s.d.r.config.RepositoryConfigurationDelegate - Multiple Spring Data modules found, entering strict repository configuration mode!
13:57:54.228 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.AdvertiseDao.
13:57:54.229 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.MemberPromotionDao.
13:57:54.229 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.ReleaseBalanceDao.
13:57:54.230 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.AdminDao.
13:57:54.230 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.MemberLevelDao.
13:57:54.231 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.OrderDao.
13:57:54.231 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.MemberSignRecordDao.
13:57:54.231 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.AppRevisionDao.
13:57:54.232 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.IntegrationRecordDao.
13:57:54.232 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.MemberApplicationConfigDao.
13:57:54.232 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.SysPermissionDao.
13:57:54.233 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.DataDictionaryDao.
13:57:54.233 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.HotTransferRecordDao.
13:57:54.233 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.MemberDepositDao.
13:57:54.234 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.CountryDao.
13:57:54.234 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.DividendStartRecordDao.
13:57:54.235 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.MemberBonusDao.
13:57:54.235 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.EmptionRecordDao.
13:57:54.236 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.SysHelpDao.
13:57:54.236 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.LossThresholdRepository.
13:57:54.236 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.PaymentHistoryRepository.
13:57:54.236 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.FeedbackDao.
13:57:54.236 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.RewardActivitySettingDao.
13:57:54.237 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.AnnouncementDao.
13:57:54.237 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.AdminAccessLogDao.
13:57:54.237 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.BusinessCancelApplyDao.
13:57:54.238 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.IeoEmptionDao.
13:57:54.238 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.AppealDao.
13:57:54.238 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.GiftConfigDao.
13:57:54.239 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.LockPositionRecordDao.
13:57:54.239 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.RiskRecordRepository.
13:57:54.239 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.RewardWalletDao.
13:57:54.239 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.RewardPromotionSettingDao.
13:57:54.240 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.LeverWalletTransferRecordRepository.
13:57:54.240 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.CoinDao.
13:57:54.240 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.MemberApiKeyDao.
13:57:54.240 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.MemberTransactionDao.
13:57:54.241 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.SignDao.
13:57:54.241 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.SmsDao.
13:57:54.241 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.PlatformTransactionDao.
13:57:54.241 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.LegalWalletWithdrawDao.
13:57:54.242 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.ExchangeOrderRepository.
13:57:54.242 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.LeverCoinRepository.
13:57:54.242 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.MemberDao.
13:57:54.243 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.InitPlateDao.
13:57:54.243 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.MemberAddressDao.
13:57:54.243 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.RobotTransactionDao.
13:57:54.243 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.MemberApplicationDao.
13:57:54.243 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.FavorSymbolRepository.
13:57:54.244 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.LoanRecordRepository.
13:57:54.244 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.MemberWalletDao.
13:57:54.244 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.OtcWalletDao.
13:57:54.244 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.DepositRecordDao.
13:57:54.245 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.PoundageConvertEthDao.
13:57:54.245 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.SysAdvertiseDao.
13:57:54.245 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.TransferAddressDao.
13:57:54.245 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.ExchangeCoinRepository.
13:57:54.245 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.SysRoleDao.
13:57:54.246 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.WebsiteInformationDao.
13:57:54.246 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.OtcCoinDao.
13:57:54.246 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.TransferRecordDao.
13:57:54.247 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.GiftRecordDao.
13:57:54.247 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.DepartmentDao.
13:57:54.247 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.BusinessAuthDepositDao.
13:57:54.247 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.AirdropDao.
13:57:54.248 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.LeverWalletRepository.
13:57:54.248 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.MemberGradeDao.
13:57:54.248 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.RewardRecordDao.
13:57:54.248 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.WithdrawRecordDao.
13:57:54.248 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.LegalWalletRechargeDao.
13:57:54.248 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.BusinessAuthApplyDao.
13:57:54.268 [main] INFO  o.s.d.r.config.RepositoryConfigurationDelegate - Multiple Spring Data modules found, entering strict repository configuration mode!
13:57:54.575 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.AdvertiseDao.
13:57:54.576 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.MemberPromotionDao.
13:57:54.576 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.ReleaseBalanceDao.
13:57:54.576 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.AdminDao.
13:57:54.576 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.MemberLevelDao.
13:57:54.576 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.OrderDao.
13:57:54.577 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.MemberSignRecordDao.
13:57:54.577 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.AppRevisionDao.
13:57:54.577 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.OrderDetailAggregationRepository.
13:57:54.577 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.IntegrationRecordDao.
13:57:54.577 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.MemberApplicationConfigDao.
13:57:54.578 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.SysPermissionDao.
13:57:54.578 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.ExchangeOrderDetailRepository.
13:57:54.578 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.DataDictionaryDao.
13:57:54.578 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.HotTransferRecordDao.
13:57:54.579 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.MemberDepositDao.
13:57:54.579 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.CountryDao.
13:57:54.579 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.DividendStartRecordDao.
13:57:54.579 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.MemberBonusDao.
13:57:54.580 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.MemberLogDao.
13:57:54.580 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.EmptionRecordDao.
13:57:54.580 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.SysHelpDao.
13:57:54.580 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.LossThresholdRepository.
13:57:54.580 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.PaymentHistoryRepository.
13:57:54.580 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.FeedbackDao.
13:57:54.581 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.RewardActivitySettingDao.
13:57:54.581 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.AnnouncementDao.
13:57:54.581 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.AdminAccessLogDao.
13:57:54.581 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.BusinessCancelApplyDao.
13:57:54.581 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.IeoEmptionDao.
13:57:54.581 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.AppealDao.
13:57:54.582 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.GiftConfigDao.
13:57:54.582 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.LockPositionRecordDao.
13:57:54.582 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.RiskRecordRepository.
13:57:54.582 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.RewardWalletDao.
13:57:54.582 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.RewardPromotionSettingDao.
13:57:54.582 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.LeverWalletTransferRecordRepository.
13:57:54.583 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.CoinDao.
13:57:54.583 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.MemberApiKeyDao.
13:57:54.583 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.MemberTransactionDao.
13:57:54.583 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.SignDao.
13:57:54.583 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.SmsDao.
13:57:54.583 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.PlatformTransactionDao.
13:57:54.584 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.LegalWalletWithdrawDao.
13:57:54.584 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.ExchangeOrderRepository.
13:57:54.584 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.LeverCoinRepository.
13:57:54.584 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.MemberDao.
13:57:54.584 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.InitPlateDao.
13:57:54.584 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.MemberAddressDao.
13:57:54.585 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.RobotTransactionDao.
13:57:54.585 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.MemberApplicationDao.
13:57:54.585 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.FavorSymbolRepository.
13:57:54.585 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.LoanRecordRepository.
13:57:54.585 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.MemberWalletDao.
13:57:54.586 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.OtcWalletDao.
13:57:54.586 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.DepositRecordDao.
13:57:54.586 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.PoundageConvertEthDao.
13:57:54.586 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.SysAdvertiseDao.
13:57:54.586 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.TransferAddressDao.
13:57:54.586 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.ExchangeCoinRepository.
13:57:54.586 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.SysRoleDao.
13:57:54.586 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.WebsiteInformationDao.
13:57:54.586 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.TradeRepository.
13:57:54.586 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.OtcCoinDao.
13:57:54.586 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.TransferRecordDao.
13:57:54.586 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.GiftRecordDao.
13:57:54.586 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.DepartmentDao.
13:57:54.586 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.BusinessAuthDepositDao.
13:57:54.586 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.AirdropDao.
13:57:54.588 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.LeverWalletRepository.
13:57:54.588 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.MemberGradeDao.
13:57:54.588 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.RewardRecordDao.
13:57:54.588 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.WithdrawRecordDao.
13:57:54.588 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.ExchangeTradeRepository.
13:57:54.588 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.LegalWalletRechargeDao.
13:57:54.588 [main] INFO  o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface cn.ztuo.bitrade.dao.BusinessAuthApplyDao.
13:57:54.766 [main] INFO  o.springframework.cloud.context.scope.GenericScope - BeanFactory id=30c01683-e1c5-3dbf-93ce-833db208f136
13:57:54.814 [main] INFO  o.s.b.f.a.AutowiredAnnotationBeanPostProcessor - JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
13:57:54.841 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'cn.ztuo.aqmd.HawkNettyConfiguration' of type [cn.ztuo.aqmd.HawkNettyConfiguration$$EnhancerBySpringCGLIB$$b97a6f17] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
13:57:54.856 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.kafka.annotation.KafkaBootstrapConfiguration' of type [org.springframework.kafka.annotation.KafkaBootstrapConfiguration$$EnhancerBySpringCGLIB$$20fcaec4] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
13:57:54.899 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'loginUserService' of type [cn.ztuo.aqmd.service.DefaultLoginUserService] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
13:57:54.899 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'hawkServerRealm' of type [cn.ztuo.aqmd.netty.shiro.realm.HawkServerRealm] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
13:57:54.914 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'sessionIdGenerator' of type [cn.ztuo.aqmd.netty.shiro.SequenceSessionIdGenerator] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
13:57:54.921 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'sessionDAO' of type [org.apache.shiro.session.mgt.eis.EnterpriseCacheSessionDAO] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
13:57:54.941 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'sessionManager' of type [cn.ztuo.aqmd.netty.shiro.session.DefaultHawkSessionManager] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
13:57:54.957 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'spring.cache-org.springframework.boot.autoconfigure.cache.CacheProperties' of type [org.springframework.boot.autoconfigure.cache.CacheProperties] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
13:57:54.957 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.boot.autoconfigure.cache.CacheAutoConfiguration' of type [org.springframework.boot.autoconfigure.cache.CacheAutoConfiguration$$EnhancerBySpringCGLIB$$8ad09803] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
13:57:54.957 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'cacheManagerCustomizers' of type [org.springframework.boot.autoconfigure.cache.CacheManagerCustomizers] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
13:57:54.957 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.boot.autoconfigure.cache.EhCacheCacheConfiguration' of type [org.springframework.boot.autoconfigure.cache.EhCacheCacheConfiguration$$EnhancerBySpringCGLIB$$256f6501] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
13:57:55.057 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'ehCacheCacheManager' of type [net.sf.ehcache.CacheManager] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
13:57:55.057 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'cacheManager' of type [org.springframework.cache.ehcache.EhCacheCacheManager] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
13:57:55.057 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'springCacheManagerWrapper' of type [cn.ztuo.aqmd.netty.shiro.cache.SpringCacheManagerWrapper] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
13:57:55.073 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'hawkSubjectFactory' of type [cn.ztuo.aqmd.netty.shiro.mgt.DefaultHawkSubjectFactory] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
13:57:55.088 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'securityManager' of type [cn.ztuo.aqmd.netty.shiro.mgt.DefaultHawkSecurityManager] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
13:57:55.099 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'methodInvokingFactoryBean' of type [org.springframework.beans.factory.config.MethodInvokingFactoryBean] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
13:57:55.204 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration' of type [org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration$$EnhancerBySpringCGLIB$$4d4a9d41] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
13:57:55.243 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.cache.annotation.ProxyCachingConfiguration' of type [org.springframework.cache.annotation.ProxyCachingConfiguration$$EnhancerBySpringCGLIB$$965cd35f] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
13:57:55.260 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'cacheAutoConfigurationValidator' of type [org.springframework.boot.autoconfigure.cache.CacheAutoConfiguration$CacheManagerValidator] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
13:57:55.299 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration' of type [org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration$$EnhancerBySpringCGLIB$$6964a03e] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
13:57:55.576 [main] INFO  o.s.b.c.e.tomcat.TomcatEmbeddedServletContainer - Tomcat initialized with port(s): 6004 (http)
13:57:55.592 [main] INFO  org.apache.catalina.core.StandardService - Starting service [Tomcat]
13:57:55.601 [main] INFO  org.apache.catalina.core.StandardEngine - Starting Servlet Engine: Apache Tomcat/8.5.23
13:57:55.725 [localhost-startStop-1] INFO  o.a.c.c.C.[Tomcat].[localhost].[/market] - Initializing Spring embedded WebApplicationContext
13:57:55.725 [localhost-startStop-1] INFO  org.springframework.web.context.ContextLoader - Root WebApplicationContext: initialization completed in 3595 ms
13:57:55.946 [localhost-startStop-1] INFO  o.s.boot.web.servlet.FilterRegistrationBean - Mapping filter: 'characterEncodingFilter' to: [/*]
13:57:55.946 [localhost-startStop-1] INFO  o.s.boot.web.servlet.FilterRegistrationBean - Mapping filter: 'hiddenHttpMethodFilter' to: [/*]
13:57:55.946 [localhost-startStop-1] INFO  o.s.boot.web.servlet.FilterRegistrationBean - Mapping filter: 'httpPutFormContentFilter' to: [/*]
13:57:55.946 [localhost-startStop-1] INFO  o.s.boot.web.servlet.FilterRegistrationBean - Mapping filter: 'requestContextFilter' to: [/*]
13:57:55.946 [localhost-startStop-1] INFO  o.s.boot.web.servlet.FilterRegistrationBean - Mapping filter: 'corsFilter' to: [/*]
13:57:55.946 [localhost-startStop-1] INFO  o.s.boot.web.servlet.ServletRegistrationBean - Mapping servlet: 'dispatcherServlet' to [/]
13:57:56.302 [main] INFO  com.alibaba.druid.pool.DruidDataSource - {dataSource-1} inited
13:57:56.564 [main] INFO  o.s.orm.jpa.LocalContainerEntityManagerFactoryBean - Building JPA container EntityManagerFactory for persistence unit 'default'
13:57:56.579 [main] INFO  org.hibernate.jpa.internal.util.LogHelper - HHH000204: Processing PersistenceUnitInfo [
	name: default
	...]
13:57:56.627 [main] INFO  org.hibernate.Version - HHH000412: Hibernate Core {5.0.12.Final}
13:57:56.644 [main] INFO  org.hibernate.cfg.Environment - HHH000206: hibernate.properties not found
13:57:56.644 [main] INFO  org.hibernate.cfg.Environment - HHH000021: Bytecode provider name : javassist
13:57:56.680 [main] INFO  org.hibernate.annotations.common.Version - HCANN000001: Hibernate Commons Annotations {5.0.1.Final}
13:57:56.803 [main] INFO  org.hibernate.dialect.Dialect - HHH000400: Using dialect: org.hibernate.dialect.MySQL5Dialect
13:57:57.499 [main] INFO  org.hibernate.tuple.PojoInstantiator - HHH000182: No default (no-argument) constructor for class: cn.ztuo.bitrade.entity.RiskRecord (class must be instantiated by Interceptor)
13:57:57.831 [main] INFO  o.s.orm.jpa.LocalContainerEntityManagerFactoryBean - Initialized JPA EntityManagerFactory for persistence unit 'default'
13:57:58.403 [main] INFO  org.mongodb.driver.cluster - Cluster created with settings {hosts=[localhost:27017], mode=SINGLE, requiredClusterType=UNKNOWN, serverSelectionTimeout='30000 ms', maxWaitQueueSize=500}
13:57:58.535 [cluster-ClusterId{value='5d773b6631d7591c0cebd421', description='null'}-localhost:27017] INFO  org.mongodb.driver.connection - Opened connection [connectionId{localValue:1, serverValue:4}] to localhost:27017
13:57:58.535 [cluster-ClusterId{value='5d773b6631d7591c0cebd421', description='null'}-localhost:27017] INFO  org.mongodb.driver.cluster - Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, version=ServerVersion{versionList=[3, 6, 3]}, minWireVersion=0, maxWireVersion=6, maxDocumentSize=16777216, roundTripTimeNanos=665600}
13:57:58.543 [main] WARN  o.s.data.mongodb.core.convert.CustomConversions - Registering converter from class java.math.BigDecimal to class org.bson.types.Decimal128 as reading converter although it doesn't convert from a Mongo supported type! You might wanna check you annotation setup at the converter implementation.
13:57:58.543 [main] WARN  o.s.data.mongodb.core.convert.CustomConversions - Registering converter from class org.bson.types.Decimal128 to class java.math.BigDecimal as writing converter although it doesn't convert to a Mongo supported type! You might wanna check you annotation setup at the converter implementation.
13:57:58.835 [main] INFO  o.s.scheduling.concurrent.ThreadPoolTaskExecutor - Initializing ExecutorService  'clientInboundChannelExecutor'
13:57:58.854 [main] INFO  o.s.scheduling.concurrent.ThreadPoolTaskExecutor - Initializing ExecutorService  'clientOutboundChannelExecutor'
13:57:58.906 [main] INFO  cn.ztuo.aqmd.core.context.HawkContext - 注册指令20001#1
13:57:58.906 [main] INFO  cn.ztuo.aqmd.core.context.HawkContext - 注册指令20021#1
13:57:58.906 [main] INFO  cn.ztuo.aqmd.core.context.HawkContext - 注册指令20002#1
13:57:58.906 [main] INFO  cn.ztuo.aqmd.core.context.HawkContext - 注册指令20022#1
13:57:59.511 [main] INFO  o.h.hql.internal.QueryTranslatorFactoryInitiator - HHH000397: Using ASTQueryTranslatorFactory
13:57:59.862 [main] INFO  cn.ztuo.bitrade.config.ProcessorConfig - ====initialized CoinProcessorFactory start==================================
13:58:00.210 [main] INFO  cn.ztuo.bitrade.config.ProcessorConfig - exchange-coin result:[ExchangeCoin(symbol=BTC/USDT, coinSymbol=BTC, baseSymbol=USDT, enable=1, fee=0.0010, baseFee=null, sort=0, coinScale=8, baseCoinScale=8, minSellPrice=0E-8, enableMarketSell=IS_TRUE, enableMarketBuy=IS_TRUE, maxTradingTime=0, maxTradingOrder=0, flag=0, minTurnover=0E-8, zone=0, minVolume=0E-8, maxVolume=0E-8, defaultSymbol=0)]
13:58:00.210 [main] INFO  cn.ztuo.bitrade.processor.CoinProcessorFactory - CoinProcessorFactory addProcessor = BTC/USDT
13:58:00.210 [main] INFO  cn.ztuo.bitrade.config.ProcessorConfig - ====initialized CoinProcessorFactory completed====
13:58:00.210 [main] INFO  cn.ztuo.bitrade.config.ProcessorConfig - CoinProcessorFactory = 
13:58:00.800 [main] INFO  cn.ztuo.bitrade.config.WaitingOrderConfig - init waiting order factory,symbol=BTC/USDT
13:58:00.800 [main] INFO  cn.ztuo.bitrade.waiting.WaitingOrder - init waiting for symbol BTC/USDT
13:58:00.800 [main] INFO  cn.ztuo.bitrade.config.WaitingOrderConfig - 初始化结束=WaitingOrder(symbol=BTC/USDT, buyTriggerPriceQueue={}, sellTriggerPriceQueue={}, ready=false)
13:58:02.125 [main] INFO  o.s.scheduling.concurrent.ThreadPoolTaskScheduler - Initializing ExecutorService  'messageBrokerTaskScheduler'
13:58:02.180 [main] INFO  o.s.w.s.server.support.WebSocketHandlerMapping - Mapped URL path [/market-ws/**] onto handler of type [class org.springframework.web.socket.sockjs.support.SockJsHttpRequestHandler]
13:58:02.202 [main] INFO  o.s.scheduling.concurrent.ThreadPoolTaskExecutor - Initializing ExecutorService  'brokerChannelExecutor'
13:58:02.400 [main] INFO  org.mongodb.driver.cluster - Cluster created with settings {hosts=[localhost:27017], mode=SINGLE, requiredClusterType=UNKNOWN, serverSelectionTimeout='30000 ms', maxWaitQueueSize=500}
13:58:02.427 [cluster-ClusterId{value='5d773b6a31d7591c0cebd422', description='null'}-localhost:27017] INFO  org.mongodb.driver.connection - Opened connection [connectionId{localValue:2, serverValue:5}] to localhost:27017
13:58:02.429 [cluster-ClusterId{value='5d773b6a31d7591c0cebd422', description='null'}-localhost:27017] INFO  org.mongodb.driver.cluster - Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, version=ServerVersion{versionList=[3, 6, 3]}, minWireVersion=0, maxWireVersion=6, maxDocumentSize=16777216, roundTripTimeNanos=427499}
13:58:02.465 [main] WARN  com.netflix.config.sources.URLConfigurationSource - No URLs will be polled as dynamic configuration sources.
13:58:02.465 [main] INFO  com.netflix.config.sources.URLConfigurationSource - To enable URLs as dynamic configuration sources, define System property archaius.configurationSource.additionalUrls or make config.properties available on classpath.
13:58:02.465 [main] WARN  com.netflix.config.sources.URLConfigurationSource - No URLs will be polled as dynamic configuration sources.
13:58:02.465 [main] INFO  com.netflix.config.sources.URLConfigurationSource - To enable URLs as dynamic configuration sources, define System property archaius.configurationSource.additionalUrls or make config.properties available on classpath.
13:58:02.673 [main] INFO  o.s.w.s.m.m.a.RequestMappingHandlerAdapter - Looking for @ControllerAdvice: org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@3c904f1e: startup date [Tue Sep 10 13:57:52 CST 2019]; parent: org.springframework.context.annotation.AnnotationConfigApplicationContext@5b068087
13:58:02.730 [main] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/exchange-rate/{fromUnit}-{toUnit}]}" onto public cn.ztuo.bitrade.util.MessageResult cn.ztuo.bitrade.controller.ExchangeRateController.getUsdCnyRate(java.lang.String,java.lang.String)
13:58:02.730 [main] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/exchange-rate/{legalCoin}/{coin}]}" onto public cn.ztuo.bitrade.util.MessageResult cn.ztuo.bitrade.controller.ExchangeRateController.getUsdExchangeRate(java.lang.String,java.lang.String)
13:58:02.730 [main] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/symbol-info]}" onto public cn.ztuo.bitrade.entity.ExchangeCoin cn.ztuo.bitrade.controller.MarketController.findSymbol(java.lang.String)
13:58:02.730 [main] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/symbol-thumb]}" onto public java.util.List<cn.ztuo.bitrade.entity.CoinThumb> cn.ztuo.bitrade.controller.MarketController.findSymbolThumb(java.lang.Boolean)
13:58:02.730 [main] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/overview]}" onto public java.util.Map<java.lang.String, java.util.List<cn.ztuo.bitrade.entity.CoinThumb>> cn.ztuo.bitrade.controller.MarketController.overview()
13:58:02.730 [main] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/history]}" onto public com.alibaba.fastjson.JSONArray cn.ztuo.bitrade.controller.MarketController.findKHistory(java.lang.String,long,long,java.lang.String)
13:58:02.730 [main] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/symbol]}" onto public java.util.List<cn.ztuo.bitrade.entity.ExchangeCoin> cn.ztuo.bitrade.controller.MarketController.findAllSymbol()
13:58:02.730 [main] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/latest-trade]}" onto public java.util.List<cn.ztuo.bitrade.entity.ExchangeTrade> cn.ztuo.bitrade.controller.MarketController.latestTrade(java.lang.String,int)
13:58:02.730 [main] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/exchange-plate]}" onto public java.util.Map<java.lang.String, java.util.List<cn.ztuo.bitrade.entity.TradePlateItem>> cn.ztuo.bitrade.controller.MarketController.findTradePlate(java.lang.String)
13:58:02.730 [main] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/find/waiting]}" onto public cn.ztuo.bitrade.entity.ExchangeOrder cn.ztuo.bitrade.controller.MarketController.findWaitingOrder(java.lang.String,java.lang.String,cn.ztuo.bitrade.entity.ExchangeOrderDirection)
13:58:02.730 [main] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/default/symbol],methods=[GET]}" onto public cn.ztuo.bitrade.util.MessageResult cn.ztuo.bitrade.controller.MarketController.findDefaultSymbol()
13:58:02.730 [main] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/symbol-thumb-trend]}" onto public com.alibaba.fastjson.JSONArray cn.ztuo.bitrade.controller.MarketController.findSymbolThumbWithTrend()
13:58:02.745 [main] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/exchange-plate-full]}" onto public java.util.Map<java.lang.String, com.alibaba.fastjson.JSONObject> cn.ztuo.bitrade.controller.MarketController.findTradePlateFull(java.lang.String)
13:58:02.745 [main] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/exchange-plate-mini]}" onto public java.util.Map<java.lang.String, com.alibaba.fastjson.JSONObject> cn.ztuo.bitrade.controller.MarketController.findTradePlateMini(java.lang.String)
13:58:02.745 [main] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/captcha]}" onto public void cn.ztuo.bitrade.controller.CaptchaController.genCaptcha(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse) throws java.io.IOException
13:58:02.750 [main] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
13:58:02.750 [main] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
13:58:02.805 [main] INFO  o.s.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/webjars/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
13:58:02.805 [main] INFO  o.s.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
13:58:02.831 [main] INFO  o.s.w.s.m.m.a.ExceptionHandlerExceptionResolver - Detected @ExceptionHandler methods in exceptionControllerAdvice
13:58:02.889 [main] INFO  o.s.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/**/favicon.ico] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
13:58:03.475 [main] INFO  cn.ztuo.aqmd.core.context.HawkContext - 注册指令11002#1
13:58:03.491 [main] INFO  cn.ztuo.aqmd.core.context.HawkContext - 注册指令11004#1
13:58:03.491 [main] INFO  cn.ztuo.aqmd.core.context.HawkContext - 增加过滤器class cn.ztuo.aqmd.netty.filter.AccessAuthFilter
13:58:03.491 [main] INFO  cn.ztuo.aqmd.core.context.HawkContext - 增加过滤器class cn.ztuo.aqmd.netty.filter.DelegatingHawkFilterProxy
13:58:04.241 [main] WARN  o.s.c.s.e.EurekaStarterDeprecationWarningAutoConfiguration - spring-cloud-starter-eureka is deprecated as of Spring Cloud Netflix 1.4.0, please migrate to spring-cloud-starter-netflix-eureka
13:58:04.494 [main] INFO  o.s.jmx.export.annotation.AnnotationMBeanExporter - Registering beans for JMX exposure on startup
13:58:04.494 [main] INFO  o.s.jmx.export.annotation.AnnotationMBeanExporter - Bean with name 'dataSource' has been autodetected for JMX exposure
13:58:04.504 [main] INFO  o.s.jmx.export.annotation.AnnotationMBeanExporter - Bean with name 'environmentManager' has been autodetected for JMX exposure
13:58:04.504 [main] INFO  o.s.jmx.export.annotation.AnnotationMBeanExporter - Bean with name 'configurationPropertiesRebinder' has been autodetected for JMX exposure
13:58:04.504 [main] INFO  o.s.jmx.export.annotation.AnnotationMBeanExporter - Bean with name 'refreshScope' has been autodetected for JMX exposure
13:58:04.504 [main] INFO  o.s.jmx.export.annotation.AnnotationMBeanExporter - Located managed bean 'environmentManager': registering with JMX server as MBean [org.springframework.cloud.context.environment:name=environmentManager,type=EnvironmentManager]
13:58:04.522 [main] INFO  o.s.jmx.export.annotation.AnnotationMBeanExporter - Located managed bean 'refreshScope': registering with JMX server as MBean [org.springframework.cloud.context.scope.refresh:name=refreshScope,type=RefreshScope]
13:58:04.534 [main] INFO  o.s.jmx.export.annotation.AnnotationMBeanExporter - Located managed bean 'configurationPropertiesRebinder': registering with JMX server as MBean [org.springframework.cloud.context.properties:name=configurationPropertiesRebinder,context=3c904f1e,type=ConfigurationPropertiesRebinder]
13:58:04.534 [main] INFO  o.s.jmx.export.annotation.AnnotationMBeanExporter - Located MBean 'dataSource': registering with JMX server as MBean [com.alibaba.druid.pool:name=dataSource,type=DruidDataSource]
13:58:04.737 [main] INFO  o.s.context.support.DefaultLifecycleProcessor - Starting beans in phase 0
13:58:04.747 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:58:04.777 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-1
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:58:04.787 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.0.0
13:58:04.787 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : b8642491e78c5a13
13:58:04.787 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:58:04.787 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-2
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:58:04.787 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.0.0
13:58:04.787 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : b8642491e78c5a13
13:58:04.787 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:58:04.796 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-3
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:58:04.798 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.0.0
13:58:04.798 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : b8642491e78c5a13
13:58:04.798 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:58:04.798 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-4
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:58:04.798 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.0.0
13:58:04.798 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : b8642491e78c5a13
13:58:04.798 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:58:04.798 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-5
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:58:04.798 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.0.0
13:58:04.798 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : b8642491e78c5a13
13:58:04.798 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:58:04.806 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-6
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:58:04.806 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.0.0
13:58:04.806 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : b8642491e78c5a13
13:58:04.808 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:58:04.808 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-7
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:58:04.808 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.0.0
13:58:04.808 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : b8642491e78c5a13
13:58:04.808 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:58:04.808 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-8
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:58:04.808 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.0.0
13:58:04.808 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : b8642491e78c5a13
13:58:04.808 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:58:04.816 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-9
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:58:04.816 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.0.0
13:58:04.816 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : b8642491e78c5a13
13:58:04.816 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:58:04.816 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-10
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:58:04.816 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.0.0
13:58:04.816 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : b8642491e78c5a13
13:58:04.816 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:58:04.816 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-11
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:58:04.816 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.0.0
13:58:04.816 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : b8642491e78c5a13
13:58:04.816 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:58:04.816 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-12
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:58:04.816 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.0.0
13:58:04.816 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : b8642491e78c5a13
13:58:04.816 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:58:04.816 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-13
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:58:04.826 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.0.0
13:58:04.826 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : b8642491e78c5a13
13:58:04.826 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:58:04.826 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-14
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:58:04.828 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.0.0
13:58:04.828 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : b8642491e78c5a13
13:58:04.828 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:58:04.828 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-15
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:58:04.828 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.0.0
13:58:04.828 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : b8642491e78c5a13
13:58:04.828 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:58:04.828 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-16
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:58:04.832 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.0.0
13:58:04.832 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : b8642491e78c5a13
13:58:04.832 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:58:04.832 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-17
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:58:04.832 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.0.0
13:58:04.832 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : b8642491e78c5a13
13:58:04.832 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:58:04.832 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-18
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:58:04.837 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.0.0
13:58:04.837 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : b8642491e78c5a13
13:58:04.837 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:58:04.837 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-19
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:58:04.837 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.0.0
13:58:04.837 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : b8642491e78c5a13
13:58:04.837 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:58:04.837 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-20
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:58:04.837 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.0.0
13:58:04.837 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : b8642491e78c5a13
13:58:04.837 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:58:04.837 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-21
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:58:04.837 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.0.0
13:58:04.837 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : b8642491e78c5a13
13:58:04.837 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:58:04.837 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-22
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:58:04.837 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.0.0
13:58:04.837 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : b8642491e78c5a13
13:58:04.837 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:58:04.837 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-23
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:58:04.837 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.0.0
13:58:04.837 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : b8642491e78c5a13
13:58:04.837 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:58:04.837 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-24
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:58:04.837 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.0.0
13:58:04.837 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : b8642491e78c5a13
13:58:04.837 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:58:04.847 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-25
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:58:04.847 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.0.0
13:58:04.847 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : b8642491e78c5a13
13:58:04.847 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:58:04.849 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-26
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:58:04.849 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.0.0
13:58:04.849 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : b8642491e78c5a13
13:58:04.849 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:58:04.849 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-27
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:58:04.849 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.0.0
13:58:04.849 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : b8642491e78c5a13
13:58:04.849 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:58:04.849 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-28
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:58:04.849 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.0.0
13:58:04.849 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : b8642491e78c5a13
13:58:04.849 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:58:04.849 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-29
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:58:04.849 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.0.0
13:58:04.849 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : b8642491e78c5a13
13:58:04.849 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:58:04.849 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-30
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:58:04.849 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.0.0
13:58:04.849 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : b8642491e78c5a13
13:58:04.849 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:58:04.857 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-31
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:58:04.857 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.0.0
13:58:04.857 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : b8642491e78c5a13
13:58:04.857 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:58:04.857 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-32
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:58:04.857 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.0.0
13:58:04.857 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : b8642491e78c5a13
13:58:04.857 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:58:04.857 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-33
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:58:04.857 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.0.0
13:58:04.857 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : b8642491e78c5a13
13:58:04.857 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:58:04.857 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-34
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:58:04.857 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.0.0
13:58:04.857 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : b8642491e78c5a13
13:58:04.857 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:58:04.857 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-35
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:58:04.857 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.0.0
13:58:04.857 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : b8642491e78c5a13
13:58:04.857 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:58:04.857 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-36
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:58:04.857 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.0.0
13:58:04.857 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : b8642491e78c5a13
13:58:04.857 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:58:04.857 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-37
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:58:04.857 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.0.0
13:58:04.857 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : b8642491e78c5a13
13:58:04.857 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:58:04.857 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-38
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:58:04.857 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.0.0
13:58:04.857 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : b8642491e78c5a13
13:58:04.867 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:58:04.867 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-39
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:58:04.867 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.0.0
13:58:04.867 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : b8642491e78c5a13
13:58:04.867 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:58:04.869 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-40
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:58:04.869 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.0.0
13:58:04.869 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : b8642491e78c5a13
13:58:04.869 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:58:04.869 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-41
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:58:04.869 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.0.0
13:58:04.869 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : b8642491e78c5a13
13:58:04.869 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:58:04.869 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-42
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:58:04.869 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.0.0
13:58:04.869 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : b8642491e78c5a13
13:58:04.869 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:58:04.869 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-43
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:58:04.869 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.0.0
13:58:04.869 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : b8642491e78c5a13
13:58:04.869 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:58:04.869 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-44
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:58:04.869 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.0.0
13:58:04.869 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : b8642491e78c5a13
13:58:04.869 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:58:04.877 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-45
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:58:04.877 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.0.0
13:58:04.877 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : b8642491e78c5a13
13:58:04.877 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:58:04.877 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-46
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:58:04.877 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.0.0
13:58:04.877 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : b8642491e78c5a13
13:58:04.881 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:58:04.881 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-47
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:58:04.881 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.0.0
13:58:04.881 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : b8642491e78c5a13
13:58:04.881 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:58:04.881 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-48
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:58:04.881 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.0.0
13:58:04.881 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : b8642491e78c5a13
13:58:04.881 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:58:04.881 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-49
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:58:04.881 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.0.0
13:58:04.881 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : b8642491e78c5a13
13:58:04.881 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:58:04.881 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-50
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:58:04.881 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.0.0
13:58:04.881 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : b8642491e78c5a13
13:58:04.881 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:58:04.887 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-51
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:58:04.887 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.0.0
13:58:04.887 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : b8642491e78c5a13
13:58:04.887 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:58:04.887 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-52
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:58:04.887 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.0.0
13:58:04.887 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : b8642491e78c5a13
13:58:04.889 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:58:04.889 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-53
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:58:04.889 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.0.0
13:58:04.889 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : b8642491e78c5a13
13:58:04.889 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:58:04.889 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-54
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:58:04.889 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.0.0
13:58:04.889 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : b8642491e78c5a13
13:58:04.889 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:58:04.889 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-55
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:58:04.889 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.0.0
13:58:04.889 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : b8642491e78c5a13
13:58:04.889 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:58:04.889 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-56
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:58:04.889 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.0.0
13:58:04.889 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : b8642491e78c5a13
13:58:04.889 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:58:04.897 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-57
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:58:04.897 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.0.0
13:58:04.897 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : b8642491e78c5a13
13:58:04.897 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:58:04.897 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-58
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:58:04.897 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.0.0
13:58:04.897 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : b8642491e78c5a13
13:58:04.897 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:58:04.897 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-59
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:58:04.897 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.0.0
13:58:04.897 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : b8642491e78c5a13
13:58:04.897 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:58:04.897 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-60
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:58:04.897 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.0.0
13:58:04.897 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : b8642491e78c5a13
13:58:04.897 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:58:04.897 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-61
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:58:04.897 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.0.0
13:58:04.897 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : b8642491e78c5a13
13:58:04.897 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:58:04.897 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-62
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:58:04.897 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.0.0
13:58:04.897 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : b8642491e78c5a13
13:58:04.897 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:58:04.897 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-63
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:58:04.897 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.0.0
13:58:04.897 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : b8642491e78c5a13
13:58:04.897 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:58:04.897 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-64
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:58:04.897 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.0.0
13:58:04.897 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : b8642491e78c5a13
13:58:04.897 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:58:04.907 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-65
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:58:04.907 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.0.0
13:58:04.907 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : b8642491e78c5a13
13:58:04.907 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:58:04.909 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-66
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:58:04.909 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.0.0
13:58:04.909 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : b8642491e78c5a13
13:58:04.909 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:58:04.909 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-67
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:58:04.909 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.0.0
13:58:04.909 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : b8642491e78c5a13
13:58:04.909 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:58:04.909 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-68
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:58:04.909 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.0.0
13:58:04.909 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : b8642491e78c5a13
13:58:04.909 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:58:04.909 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-69
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:58:04.909 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.0.0
13:58:04.909 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : b8642491e78c5a13
13:58:04.909 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:58:04.909 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-70
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:58:04.909 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.0.0
13:58:04.909 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : b8642491e78c5a13
13:58:04.909 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:58:04.909 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-71
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:58:04.909 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.0.0
13:58:04.909 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : b8642491e78c5a13
13:58:04.909 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:58:04.909 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [112.74.59.207:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-72
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 100
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = default-group
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 15000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest

13:58:04.909 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.0.0
13:58:04.909 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : b8642491e78c5a13
13:58:04.919 [main] INFO  o.s.cloud.netflix.eureka.InstanceInfoFactory - Setting initial instance status as: STARTING
13:58:04.950 [main] INFO  com.netflix.discovery.DiscoveryClient - Initializing Eureka in region us-east-1
13:58:05.060 [main] INFO  c.n.discovery.provider.DiscoveryJerseyProvider - Using JSON encoding codec LegacyJacksonJson
13:58:05.060 [main] INFO  c.n.discovery.provider.DiscoveryJerseyProvider - Using JSON decoding codec LegacyJacksonJson
13:58:05.159 [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Discovered coordinator 112.74.59.207:9092 (id: 2147483647 rack: null) for group default-group.
13:58:05.159 [org.springframework.kafka.KafkaListenerEndpointContainer#6-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Discovered coordinator 112.74.59.207:9092 (id: 2147483647 rack: null) for group default-group.
13:58:05.159 [org.springframework.kafka.KafkaListenerEndpointContainer#6-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Discovered coordinator 112.74.59.207:9092 (id: 2147483647 rack: null) for group default-group.
13:58:05.159 [org.springframework.kafka.KafkaListenerEndpointContainer#6-8-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Discovered coordinator 112.74.59.207:9092 (id: 2147483647 rack: null) for group default-group.
13:58:05.159 [org.springframework.kafka.KafkaListenerEndpointContainer#6-7-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Discovered coordinator 112.74.59.207:9092 (id: 2147483647 rack: null) for group default-group.
13:58:05.159 [org.springframework.kafka.KafkaListenerEndpointContainer#6-5-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Discovered coordinator 112.74.59.207:9092 (id: 2147483647 rack: null) for group default-group.
13:58:05.159 [org.springframework.kafka.KafkaListenerEndpointContainer#6-6-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Discovered coordinator 112.74.59.207:9092 (id: 2147483647 rack: null) for group default-group.
13:58:05.159 [org.springframework.kafka.KafkaListenerEndpointContainer#7-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Discovered coordinator 112.74.59.207:9092 (id: 2147483647 rack: null) for group default-group.
13:58:05.159 [org.springframework.kafka.KafkaListenerEndpointContainer#6-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Discovered coordinator 112.74.59.207:9092 (id: 2147483647 rack: null) for group default-group.
13:58:05.159 [org.springframework.kafka.KafkaListenerEndpointContainer#7-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Discovered coordinator 112.74.59.207:9092 (id: 2147483647 rack: null) for group default-group.
13:58:05.159 [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:05.159 [org.springframework.kafka.KafkaListenerEndpointContainer#6-7-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:05.159 [org.springframework.kafka.KafkaListenerEndpointContainer#6-5-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:05.159 [org.springframework.kafka.KafkaListenerEndpointContainer#6-8-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:05.159 [org.springframework.kafka.KafkaListenerEndpointContainer#7-1-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:05.159 [org.springframework.kafka.KafkaListenerEndpointContainer#6-1-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:05.159 [org.springframework.kafka.KafkaListenerEndpointContainer#6-3-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:05.159 [org.springframework.kafka.KafkaListenerEndpointContainer#6-5-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:05.159 [org.springframework.kafka.KafkaListenerEndpointContainer#6-6-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:05.159 [org.springframework.kafka.KafkaListenerEndpointContainer#6-3-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:05.159 [org.springframework.kafka.KafkaListenerEndpointContainer#6-4-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:05.159 [org.springframework.kafka.KafkaListenerEndpointContainer#6-7-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:05.159 [org.springframework.kafka.KafkaListenerEndpointContainer#6-8-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:05.159 [org.springframework.kafka.KafkaListenerEndpointContainer#6-7-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:05.159 [org.springframework.kafka.KafkaListenerEndpointContainer#7-1-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:05.159 [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:05.159 [org.springframework.kafka.KafkaListenerEndpointContainer#6-6-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:05.159 [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:05.159 [org.springframework.kafka.KafkaListenerEndpointContainer#6-6-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:05.159 [org.springframework.kafka.KafkaListenerEndpointContainer#6-1-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:05.159 [org.springframework.kafka.KafkaListenerEndpointContainer#6-5-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:05.159 [org.springframework.kafka.KafkaListenerEndpointContainer#6-4-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:05.159 [org.springframework.kafka.KafkaListenerEndpointContainer#6-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:05.159 [org.springframework.kafka.KafkaListenerEndpointContainer#7-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:05.159 [org.springframework.kafka.KafkaListenerEndpointContainer#6-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:05.159 [org.springframework.kafka.KafkaListenerEndpointContainer#7-0-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:05.159 [org.springframework.kafka.KafkaListenerEndpointContainer#6-8-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:05.159 [org.springframework.kafka.KafkaListenerEndpointContainer#6-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:05.159 [org.springframework.kafka.KafkaListenerEndpointContainer#7-0-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:05.159 [org.springframework.kafka.KafkaListenerEndpointContainer#7-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:05.175 [org.springframework.kafka.KafkaListenerEndpointContainer#7-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Discovered coordinator 112.74.59.207:9092 (id: 2147483647 rack: null) for group default-group.
13:58:05.175 [org.springframework.kafka.KafkaListenerEndpointContainer#7-3-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:05.175 [org.springframework.kafka.KafkaListenerEndpointContainer#7-3-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:05.175 [org.springframework.kafka.KafkaListenerEndpointContainer#7-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:05.175 [main] INFO  c.n.discovery.provider.DiscoveryJerseyProvider - Using XML encoding codec XStreamXml
13:58:05.175 [main] INFO  c.n.discovery.provider.DiscoveryJerseyProvider - Using XML decoding codec XStreamXml
13:58:05.214 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Discovered coordinator 112.74.59.207:9092 (id: 2147483647 rack: null) for group default-group.
13:58:05.214 [org.springframework.kafka.KafkaListenerEndpointContainer#7-8-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Discovered coordinator 112.74.59.207:9092 (id: 2147483647 rack: null) for group default-group.
13:58:05.214 [org.springframework.kafka.KafkaListenerEndpointContainer#2-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Discovered coordinator 112.74.59.207:9092 (id: 2147483647 rack: null) for group default-group.
13:58:05.214 [org.springframework.kafka.KafkaListenerEndpointContainer#7-7-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Discovered coordinator 112.74.59.207:9092 (id: 2147483647 rack: null) for group default-group.
13:58:05.214 [org.springframework.kafka.KafkaListenerEndpointContainer#2-5-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Discovered coordinator 112.74.59.207:9092 (id: 2147483647 rack: null) for group default-group.
13:58:05.214 [org.springframework.kafka.KafkaListenerEndpointContainer#7-2-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Discovered coordinator 112.74.59.207:9092 (id: 2147483647 rack: null) for group default-group.
13:58:05.214 [org.springframework.kafka.KafkaListenerEndpointContainer#2-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Discovered coordinator 112.74.59.207:9092 (id: 2147483647 rack: null) for group default-group.
13:58:05.214 [org.springframework.kafka.KafkaListenerEndpointContainer#7-6-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Discovered coordinator 112.74.59.207:9092 (id: 2147483647 rack: null) for group default-group.
13:58:05.214 [org.springframework.kafka.KafkaListenerEndpointContainer#2-2-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Discovered coordinator 112.74.59.207:9092 (id: 2147483647 rack: null) for group default-group.
13:58:05.214 [org.springframework.kafka.KafkaListenerEndpointContainer#7-7-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:05.214 [org.springframework.kafka.KafkaListenerEndpointContainer#2-5-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:05.214 [org.springframework.kafka.KafkaListenerEndpointContainer#7-2-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:05.214 [org.springframework.kafka.KafkaListenerEndpointContainer#2-1-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:05.214 [org.springframework.kafka.KafkaListenerEndpointContainer#7-2-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:05.214 [org.springframework.kafka.KafkaListenerEndpointContainer#7-7-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:05.214 [org.springframework.kafka.KafkaListenerEndpointContainer#7-8-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:05.214 [org.springframework.kafka.KafkaListenerEndpointContainer#7-6-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:05.214 [org.springframework.kafka.KafkaListenerEndpointContainer#2-4-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:05.214 [org.springframework.kafka.KafkaListenerEndpointContainer#2-5-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:05.214 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:05.214 [org.springframework.kafka.KafkaListenerEndpointContainer#2-5-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:05.214 [org.springframework.kafka.KafkaListenerEndpointContainer#2-1-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:05.214 [org.springframework.kafka.KafkaListenerEndpointContainer#7-6-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:05.214 [org.springframework.kafka.KafkaListenerEndpointContainer#7-2-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:05.214 [org.springframework.kafka.KafkaListenerEndpointContainer#2-4-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:05.214 [org.springframework.kafka.KafkaListenerEndpointContainer#7-7-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:05.214 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:05.214 [org.springframework.kafka.KafkaListenerEndpointContainer#2-2-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:05.214 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:05.214 [org.springframework.kafka.KafkaListenerEndpointContainer#2-2-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:05.214 [org.springframework.kafka.KafkaListenerEndpointContainer#2-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:05.214 [org.springframework.kafka.KafkaListenerEndpointContainer#2-2-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:05.214 [org.springframework.kafka.KafkaListenerEndpointContainer#7-8-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:05.214 [org.springframework.kafka.KafkaListenerEndpointContainer#7-6-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:05.214 [org.springframework.kafka.KafkaListenerEndpointContainer#7-8-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:05.214 [org.springframework.kafka.KafkaListenerEndpointContainer#2-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:05.259 [org.springframework.kafka.KafkaListenerEndpointContainer#3-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Discovered coordinator 112.74.59.207:9092 (id: 2147483647 rack: null) for group default-group.
13:58:05.259 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Discovered coordinator 112.74.59.207:9092 (id: 2147483647 rack: null) for group default-group.
13:58:05.259 [org.springframework.kafka.KafkaListenerEndpointContainer#5-5-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Discovered coordinator 112.74.59.207:9092 (id: 2147483647 rack: null) for group default-group.
13:58:05.259 [org.springframework.kafka.KafkaListenerEndpointContainer#5-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Discovered coordinator 112.74.59.207:9092 (id: 2147483647 rack: null) for group default-group.
13:58:05.259 [org.springframework.kafka.KafkaListenerEndpointContainer#5-2-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Discovered coordinator 112.74.59.207:9092 (id: 2147483647 rack: null) for group default-group.
13:58:05.259 [org.springframework.kafka.KafkaListenerEndpointContainer#4-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Discovered coordinator 112.74.59.207:9092 (id: 2147483647 rack: null) for group default-group.
13:58:05.259 [org.springframework.kafka.KafkaListenerEndpointContainer#3-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Discovered coordinator 112.74.59.207:9092 (id: 2147483647 rack: null) for group default-group.
13:58:05.259 [org.springframework.kafka.KafkaListenerEndpointContainer#2-8-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Discovered coordinator 112.74.59.207:9092 (id: 2147483647 rack: null) for group default-group.
13:58:05.259 [org.springframework.kafka.KafkaListenerEndpointContainer#3-6-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Discovered coordinator 112.74.59.207:9092 (id: 2147483647 rack: null) for group default-group.
13:58:05.259 [org.springframework.kafka.KafkaListenerEndpointContainer#4-6-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Discovered coordinator 112.74.59.207:9092 (id: 2147483647 rack: null) for group default-group.
13:58:05.259 [org.springframework.kafka.KafkaListenerEndpointContainer#5-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Discovered coordinator 112.74.59.207:9092 (id: 2147483647 rack: null) for group default-group.
13:58:05.259 [org.springframework.kafka.KafkaListenerEndpointContainer#4-2-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Discovered coordinator 112.74.59.207:9092 (id: 2147483647 rack: null) for group default-group.
13:58:05.259 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:05.259 [org.springframework.kafka.KafkaListenerEndpointContainer#3-1-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:05.259 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:05.259 [org.springframework.kafka.KafkaListenerEndpointContainer#4-8-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Discovered coordinator 112.74.59.207:9092 (id: 2147483647 rack: null) for group default-group.
13:58:05.259 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:05.259 [org.springframework.kafka.KafkaListenerEndpointContainer#3-3-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:05.259 [org.springframework.kafka.KafkaListenerEndpointContainer#4-0-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:05.259 [org.springframework.kafka.KafkaListenerEndpointContainer#3-3-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:05.259 [org.springframework.kafka.KafkaListenerEndpointContainer#4-0-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:05.259 [org.springframework.kafka.KafkaListenerEndpointContainer#3-5-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Discovered coordinator 112.74.59.207:9092 (id: 2147483647 rack: null) for group default-group.
13:58:05.259 [org.springframework.kafka.KafkaListenerEndpointContainer#4-6-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:05.259 [org.springframework.kafka.KafkaListenerEndpointContainer#3-6-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:05.259 [org.springframework.kafka.KafkaListenerEndpointContainer#5-5-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:05.259 [org.springframework.kafka.KafkaListenerEndpointContainer#5-0-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:05.259 [org.springframework.kafka.KafkaListenerEndpointContainer#4-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:05.259 [org.springframework.kafka.KafkaListenerEndpointContainer#3-1-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:05.259 [org.springframework.kafka.KafkaListenerEndpointContainer#3-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:05.259 [org.springframework.kafka.KafkaListenerEndpointContainer#4-5-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Discovered coordinator 112.74.59.207:9092 (id: 2147483647 rack: null) for group default-group.
13:58:05.259 [org.springframework.kafka.KafkaListenerEndpointContainer#4-6-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:05.259 [org.springframework.kafka.KafkaListenerEndpointContainer#5-4-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:05.259 [org.springframework.kafka.KafkaListenerEndpointContainer#4-6-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:05.259 [org.springframework.kafka.KafkaListenerEndpointContainer#5-2-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:05.259 [org.springframework.kafka.KafkaListenerEndpointContainer#5-5-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:05.259 [org.springframework.kafka.KafkaListenerEndpointContainer#2-8-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:05.259 [org.springframework.kafka.KafkaListenerEndpointContainer#4-8-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:05.259 [org.springframework.kafka.KafkaListenerEndpointContainer#4-2-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:05.259 [org.springframework.kafka.KafkaListenerEndpointContainer#3-6-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:05.259 [org.springframework.kafka.KafkaListenerEndpointContainer#5-0-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:05.259 [org.springframework.kafka.KafkaListenerEndpointContainer#3-6-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:05.259 [org.springframework.kafka.KafkaListenerEndpointContainer#3-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:05.259 [org.springframework.kafka.KafkaListenerEndpointContainer#5-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:05.259 [org.springframework.kafka.KafkaListenerEndpointContainer#4-5-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:05.259 [org.springframework.kafka.KafkaListenerEndpointContainer#3-5-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:05.259 [org.springframework.kafka.KafkaListenerEndpointContainer#5-2-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:05.259 [org.springframework.kafka.KafkaListenerEndpointContainer#3-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Discovered coordinator 112.74.59.207:9092 (id: 2147483647 rack: null) for group default-group.
13:58:05.259 [org.springframework.kafka.KafkaListenerEndpointContainer#5-2-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:05.259 [org.springframework.kafka.KafkaListenerEndpointContainer#5-5-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:05.259 [org.springframework.kafka.KafkaListenerEndpointContainer#4-8-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:05.259 [org.springframework.kafka.KafkaListenerEndpointContainer#4-8-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:05.259 [org.springframework.kafka.KafkaListenerEndpointContainer#5-4-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:05.259 [org.springframework.kafka.KafkaListenerEndpointContainer#2-8-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:05.259 [org.springframework.kafka.KafkaListenerEndpointContainer#4-2-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:05.259 [org.springframework.kafka.KafkaListenerEndpointContainer#3-4-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:05.259 [org.springframework.kafka.KafkaListenerEndpointContainer#4-5-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:05.259 [org.springframework.kafka.KafkaListenerEndpointContainer#3-4-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:05.259 [org.springframework.kafka.KafkaListenerEndpointContainer#3-5-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:05.259 [org.springframework.kafka.KafkaListenerEndpointContainer#5-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:05.259 [org.springframework.kafka.KafkaListenerEndpointContainer#3-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:05.259 [org.springframework.kafka.KafkaListenerEndpointContainer#3-5-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:05.259 [org.springframework.kafka.KafkaListenerEndpointContainer#2-8-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:05.259 [org.springframework.kafka.KafkaListenerEndpointContainer#4-5-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:05.259 [org.springframework.kafka.KafkaListenerEndpointContainer#4-2-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:05.259 [org.springframework.kafka.KafkaListenerEndpointContainer#4-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Discovered coordinator 112.74.59.207:9092 (id: 2147483647 rack: null) for group default-group.
13:58:05.259 [org.springframework.kafka.KafkaListenerEndpointContainer#3-7-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Discovered coordinator 112.74.59.207:9092 (id: 2147483647 rack: null) for group default-group.
13:58:05.259 [org.springframework.kafka.KafkaListenerEndpointContainer#3-8-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Discovered coordinator 112.74.59.207:9092 (id: 2147483647 rack: null) for group default-group.
13:58:05.259 [org.springframework.kafka.KafkaListenerEndpointContainer#3-7-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:05.259 [org.springframework.kafka.KafkaListenerEndpointContainer#4-3-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:05.259 [org.springframework.kafka.KafkaListenerEndpointContainer#3-7-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:05.259 [org.springframework.kafka.KafkaListenerEndpointContainer#3-8-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:05.259 [org.springframework.kafka.KafkaListenerEndpointContainer#3-7-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:05.259 [org.springframework.kafka.KafkaListenerEndpointContainer#4-3-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:05.259 [org.springframework.kafka.KafkaListenerEndpointContainer#3-8-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:05.259 [org.springframework.kafka.KafkaListenerEndpointContainer#4-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:05.259 [org.springframework.kafka.KafkaListenerEndpointContainer#3-8-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:05.259 [org.springframework.kafka.KafkaListenerEndpointContainer#3-2-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Discovered coordinator 112.74.59.207:9092 (id: 2147483647 rack: null) for group default-group.
13:58:05.259 [org.springframework.kafka.KafkaListenerEndpointContainer#5-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Discovered coordinator 112.74.59.207:9092 (id: 2147483647 rack: null) for group default-group.
13:58:05.259 [org.springframework.kafka.KafkaListenerEndpointContainer#1-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Discovered coordinator 112.74.59.207:9092 (id: 2147483647 rack: null) for group default-group.
13:58:05.259 [org.springframework.kafka.KafkaListenerEndpointContainer#5-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Discovered coordinator 112.74.59.207:9092 (id: 2147483647 rack: null) for group default-group.
13:58:05.259 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Discovered coordinator 112.74.59.207:9092 (id: 2147483647 rack: null) for group default-group.
13:58:05.259 [org.springframework.kafka.KafkaListenerEndpointContainer#1-1-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:05.259 [org.springframework.kafka.KafkaListenerEndpointContainer#5-1-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:05.259 [org.springframework.kafka.KafkaListenerEndpointContainer#3-2-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:05.259 [org.springframework.kafka.KafkaListenerEndpointContainer#5-1-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:05.259 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:05.259 [org.springframework.kafka.KafkaListenerEndpointContainer#1-1-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:05.259 [org.springframework.kafka.KafkaListenerEndpointContainer#5-3-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:05.259 [org.springframework.kafka.KafkaListenerEndpointContainer#1-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:05.259 [org.springframework.kafka.KafkaListenerEndpointContainer#5-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:05.259 [org.springframework.kafka.KafkaListenerEndpointContainer#5-3-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:05.259 [org.springframework.kafka.KafkaListenerEndpointContainer#3-2-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:05.259 [org.springframework.kafka.KafkaListenerEndpointContainer#5-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:05.259 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:05.259 [org.springframework.kafka.KafkaListenerEndpointContainer#3-2-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:05.259 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:05.259 [org.springframework.kafka.KafkaListenerEndpointContainer#0-6-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Discovered coordinator 112.74.59.207:9092 (id: 2147483647 rack: null) for group default-group.
13:58:05.259 [org.springframework.kafka.KafkaListenerEndpointContainer#0-6-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:05.259 [org.springframework.kafka.KafkaListenerEndpointContainer#0-6-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:05.259 [org.springframework.kafka.KafkaListenerEndpointContainer#0-6-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:05.259 [org.springframework.kafka.KafkaListenerEndpointContainer#5-8-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Discovered coordinator 112.74.59.207:9092 (id: 2147483647 rack: null) for group default-group.
13:58:05.259 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Discovered coordinator 112.74.59.207:9092 (id: 2147483647 rack: null) for group default-group.
13:58:05.259 [org.springframework.kafka.KafkaListenerEndpointContainer#5-6-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Discovered coordinator 112.74.59.207:9092 (id: 2147483647 rack: null) for group default-group.
13:58:05.259 [org.springframework.kafka.KafkaListenerEndpointContainer#5-8-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:05.259 [org.springframework.kafka.KafkaListenerEndpointContainer#5-8-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:05.259 [org.springframework.kafka.KafkaListenerEndpointContainer#5-8-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:05.259 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:05.259 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:05.259 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:05.259 [org.springframework.kafka.KafkaListenerEndpointContainer#5-6-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:05.259 [org.springframework.kafka.KafkaListenerEndpointContainer#5-6-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:05.259 [org.springframework.kafka.KafkaListenerEndpointContainer#5-6-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:05.259 [org.springframework.kafka.KafkaListenerEndpointContainer#0-5-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Discovered coordinator 112.74.59.207:9092 (id: 2147483647 rack: null) for group default-group.
13:58:05.259 [org.springframework.kafka.KafkaListenerEndpointContainer#0-5-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:05.259 [org.springframework.kafka.KafkaListenerEndpointContainer#0-5-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:05.259 [org.springframework.kafka.KafkaListenerEndpointContainer#0-5-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:05.259 [org.springframework.kafka.KafkaListenerEndpointContainer#5-7-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Discovered coordinator 112.74.59.207:9092 (id: 2147483647 rack: null) for group default-group.
13:58:05.259 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Discovered coordinator 112.74.59.207:9092 (id: 2147483647 rack: null) for group default-group.
13:58:05.259 [org.springframework.kafka.KafkaListenerEndpointContainer#5-7-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:05.259 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:05.259 [org.springframework.kafka.KafkaListenerEndpointContainer#5-7-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:05.259 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:05.259 [org.springframework.kafka.KafkaListenerEndpointContainer#5-7-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:05.259 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:05.259 [org.springframework.kafka.KafkaListenerEndpointContainer#0-8-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Discovered coordinator 112.74.59.207:9092 (id: 2147483647 rack: null) for group default-group.
13:58:05.259 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Discovered coordinator 112.74.59.207:9092 (id: 2147483647 rack: null) for group default-group.
13:58:05.259 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:05.259 [org.springframework.kafka.KafkaListenerEndpointContainer#0-8-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:05.259 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:05.259 [org.springframework.kafka.KafkaListenerEndpointContainer#0-8-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:05.259 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:05.259 [org.springframework.kafka.KafkaListenerEndpointContainer#0-8-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:05.259 [org.springframework.kafka.KafkaListenerEndpointContainer#1-6-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Discovered coordinator 112.74.59.207:9092 (id: 2147483647 rack: null) for group default-group.
13:58:05.259 [org.springframework.kafka.KafkaListenerEndpointContainer#1-6-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:05.259 [org.springframework.kafka.KafkaListenerEndpointContainer#1-6-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:05.259 [org.springframework.kafka.KafkaListenerEndpointContainer#1-6-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:05.259 [org.springframework.kafka.KafkaListenerEndpointContainer#1-2-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Discovered coordinator 112.74.59.207:9092 (id: 2147483647 rack: null) for group default-group.
13:58:05.259 [org.springframework.kafka.KafkaListenerEndpointContainer#1-2-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:05.259 [org.springframework.kafka.KafkaListenerEndpointContainer#1-2-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:05.259 [org.springframework.kafka.KafkaListenerEndpointContainer#1-2-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:05.276 [org.springframework.kafka.KafkaListenerEndpointContainer#1-7-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Discovered coordinator 112.74.59.207:9092 (id: 2147483647 rack: null) for group default-group.
13:58:05.276 [org.springframework.kafka.KafkaListenerEndpointContainer#1-7-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:05.276 [org.springframework.kafka.KafkaListenerEndpointContainer#1-7-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:05.276 [org.springframework.kafka.KafkaListenerEndpointContainer#1-7-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:05.346 [org.springframework.kafka.KafkaListenerEndpointContainer#1-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Discovered coordinator 112.74.59.207:9092 (id: 2147483647 rack: null) for group default-group.
13:58:05.346 [org.springframework.kafka.KafkaListenerEndpointContainer#1-3-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:05.346 [org.springframework.kafka.KafkaListenerEndpointContainer#1-3-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:05.346 [org.springframework.kafka.KafkaListenerEndpointContainer#1-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:05.346 [org.springframework.kafka.KafkaListenerEndpointContainer#1-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Discovered coordinator 112.74.59.207:9092 (id: 2147483647 rack: null) for group default-group.
13:58:05.346 [org.springframework.kafka.KafkaListenerEndpointContainer#1-8-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Discovered coordinator 112.74.59.207:9092 (id: 2147483647 rack: null) for group default-group.
13:58:05.346 [org.springframework.kafka.KafkaListenerEndpointContainer#1-4-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:05.346 [org.springframework.kafka.KafkaListenerEndpointContainer#1-8-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:05.346 [org.springframework.kafka.KafkaListenerEndpointContainer#1-4-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:05.346 [org.springframework.kafka.KafkaListenerEndpointContainer#1-8-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:05.346 [org.springframework.kafka.KafkaListenerEndpointContainer#1-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:05.346 [org.springframework.kafka.KafkaListenerEndpointContainer#1-8-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:05.415 [org.springframework.kafka.KafkaListenerEndpointContainer#1-5-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Discovered coordinator 112.74.59.207:9092 (id: 2147483647 rack: null) for group default-group.
13:58:05.415 [org.springframework.kafka.KafkaListenerEndpointContainer#1-5-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:05.415 [org.springframework.kafka.KafkaListenerEndpointContainer#1-5-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:05.415 [org.springframework.kafka.KafkaListenerEndpointContainer#1-5-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:05.459 [main] INFO  c.n.d.shared.resolver.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
13:58:05.624 [main] INFO  com.netflix.discovery.DiscoveryClient - Disable delta property : false
13:58:05.624 [main] INFO  com.netflix.discovery.DiscoveryClient - Single vip registry refresh property : null
13:58:05.624 [main] INFO  com.netflix.discovery.DiscoveryClient - Force full registry fetch : false
13:58:05.624 [main] INFO  com.netflix.discovery.DiscoveryClient - Application is null : false
13:58:05.624 [main] INFO  com.netflix.discovery.DiscoveryClient - Registered Applications size is zero : true
13:58:05.624 [main] INFO  com.netflix.discovery.DiscoveryClient - Application version is -1: true
13:58:05.624 [main] INFO  com.netflix.discovery.DiscoveryClient - Getting all instance registry info from the eureka server
13:58:05.733 [main] INFO  com.netflix.discovery.DiscoveryClient - The response status is 200
13:58:05.735 [main] INFO  com.netflix.discovery.DiscoveryClient - Starting heartbeat executor: renew interval is: 30
13:58:05.737 [main] INFO  com.netflix.discovery.InstanceInfoReplicator - InstanceInfoReplicator onDemand update allowed rate per min is 4
13:58:05.740 [main] INFO  com.netflix.discovery.DiscoveryClient - Discovery Client initialized at timestamp 1568095085739 with initial instances count: 0
13:58:05.752 [main] INFO  o.s.c.n.e.serviceregistry.EurekaServiceRegistry - Registering application bitrade-market with eureka with status UP
13:58:05.753 [main] INFO  com.netflix.discovery.DiscoveryClient - Saw local status change event StatusChangeEvent [timestamp=1568095085753, current=UP, previous=STARTING]
13:58:05.755 [DiscoveryClient-InstanceInfoReplicator-0] INFO  com.netflix.discovery.DiscoveryClient - DiscoveryClient_BITRADE-MARKET/wxpker-computer:bitrade-market:6004: registering service...
13:58:05.755 [main] INFO  o.s.context.support.DefaultLifecycleProcessor - Starting beans in phase 2147483647
13:58:05.756 [main] INFO  o.s.m.simp.broker.SimpleBrokerMessageHandler - Starting...
13:58:05.757 [main] INFO  o.s.m.simp.broker.SimpleBrokerMessageHandler - BrokerAvailabilityEvent[available=true, SimpleBrokerMessageHandler [DefaultSubscriptionRegistry[cache[0 destination(s)], registry[0 sessions]]]]
13:58:05.759 [main] INFO  o.s.m.simp.broker.SimpleBrokerMessageHandler - Started.
13:58:05.778 [main] INFO  cn.ztuo.bitrade.ApplicationEvent - ====初始化CoinExchangeRate====
13:58:05.778 [main] INFO  cn.ztuo.bitrade.component.CoinExchangeRate - rate map:{CNHUSD=0.14925, USDCNH=6.7}
13:58:05.778 [main] INFO  cn.ztuo.bitrade.ApplicationEvent - legalAnchoredCoins:{USDT=USD}
13:58:05.778 [main] INFO  cn.ztuo.bitrade.ApplicationEvent - ====初始化CoinProcessor====
13:58:05.785 [main] INFO  cn.ztuo.bitrade.processor.DefaultCoinProcessor - initializeThumb from 1568044800000 to 1568095080000
13:58:05.795 [org.springframework.kafka.KafkaListenerEndpointContainer#7-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Discovered coordinator 112.74.59.207:9092 (id: 2147483647 rack: null) for group default-group.
13:58:05.795 [org.springframework.kafka.KafkaListenerEndpointContainer#7-4-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:05.795 [org.springframework.kafka.KafkaListenerEndpointContainer#7-4-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:05.795 [org.springframework.kafka.KafkaListenerEndpointContainer#7-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:05.798 [org.springframework.kafka.KafkaListenerEndpointContainer#7-5-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Discovered coordinator 112.74.59.207:9092 (id: 2147483647 rack: null) for group default-group.
13:58:05.799 [org.springframework.kafka.KafkaListenerEndpointContainer#7-5-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:05.799 [org.springframework.kafka.KafkaListenerEndpointContainer#7-5-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:05.799 [org.springframework.kafka.KafkaListenerEndpointContainer#7-5-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:05.829 [DiscoveryClient-InstanceInfoReplicator-0] INFO  com.netflix.discovery.DiscoveryClient - DiscoveryClient_BITRADE-MARKET/wxpker-computer:bitrade-market:6004 - registration status: 204
13:58:05.845 [main] INFO  org.mongodb.driver.connection - Opened connection [connectionId{localValue:3, serverValue:6}] to localhost:27017
13:58:05.901 [main] INFO  cn.ztuo.bitrade.processor.DefaultCoinProcessor - symbol = BTC/USDT ,baseCoin = USDT
13:58:05.902 [main] INFO  cn.ztuo.bitrade.processor.DefaultCoinProcessor - setBaseUsdRate = 
13:58:05.902 [main] INFO  cn.ztuo.bitrade.processor.DefaultCoinProcessor - setUsdRate = 
13:58:05.902 [main] INFO  cn.ztuo.bitrade.config.WaitingOrderEvent - ======initialize waitingOrder======
13:58:05.927 [main] INFO  cn.ztuo.bitrade.config.WaitingOrderEvent - 待挂单数量=0
13:58:05.927 [main] INFO  cn.ztuo.bitrade.config.WaitingOrderEvent - 初始化完毕waitingOrder=WaitingOrder(symbol=BTC/USDT, buyTriggerPriceQueue={}, sellTriggerPriceQueue={}, ready=false)
13:58:05.936 [main] INFO  org.apache.coyote.http11.Http11NioProtocol - Initializing ProtocolHandler ["http-nio-6004"]
13:58:05.937 [org.springframework.kafka.KafkaListenerEndpointContainer#2-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Discovered coordinator 112.74.59.207:9092 (id: 2147483647 rack: null) for group default-group.
13:58:05.937 [org.springframework.kafka.KafkaListenerEndpointContainer#2-3-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:05.937 [org.springframework.kafka.KafkaListenerEndpointContainer#2-3-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:05.937 [org.springframework.kafka.KafkaListenerEndpointContainer#2-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:05.937 [org.springframework.kafka.KafkaListenerEndpointContainer#2-6-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Discovered coordinator 112.74.59.207:9092 (id: 2147483647 rack: null) for group default-group.
13:58:05.937 [org.springframework.kafka.KafkaListenerEndpointContainer#2-6-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:05.937 [org.springframework.kafka.KafkaListenerEndpointContainer#2-6-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:05.937 [org.springframework.kafka.KafkaListenerEndpointContainer#2-6-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:05.937 [org.springframework.kafka.KafkaListenerEndpointContainer#2-7-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Discovered coordinator 112.74.59.207:9092 (id: 2147483647 rack: null) for group default-group.
13:58:05.937 [org.springframework.kafka.KafkaListenerEndpointContainer#2-7-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:05.937 [org.springframework.kafka.KafkaListenerEndpointContainer#2-7-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:05.937 [org.springframework.kafka.KafkaListenerEndpointContainer#2-7-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:05.953 [main] INFO  org.apache.coyote.http11.Http11NioProtocol - Starting ProtocolHandler ["http-nio-6004"]
13:58:05.953 [main] INFO  org.apache.tomcat.util.net.NioSelectorPool - Using a shared selector for servlet write/read
13:58:05.962 [org.springframework.kafka.KafkaListenerEndpointContainer#6-2-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Discovered coordinator 112.74.59.207:9092 (id: 2147483647 rack: null) for group default-group.
13:58:05.962 [org.springframework.kafka.KafkaListenerEndpointContainer#6-2-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:05.962 [org.springframework.kafka.KafkaListenerEndpointContainer#6-2-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:05.962 [org.springframework.kafka.KafkaListenerEndpointContainer#6-2-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:05.977 [main] INFO  o.s.b.c.e.tomcat.TomcatEmbeddedServletContainer - Tomcat started on port(s): 6004 (http)
13:58:05.977 [main] INFO  o.s.c.n.e.s.EurekaAutoServiceRegistration - Updating port to 6004
13:58:05.986 [main] INFO  cn.ztuo.bitrade.MarketApplication - Started MarketApplication in 16.102 seconds (JVM running for 17.893)
13:58:06.037 [org.springframework.kafka.KafkaListenerEndpointContainer#4-7-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Discovered coordinator 112.74.59.207:9092 (id: 2147483647 rack: null) for group default-group.
13:58:06.037 [org.springframework.kafka.KafkaListenerEndpointContainer#4-7-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:06.037 [org.springframework.kafka.KafkaListenerEndpointContainer#4-7-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:06.037 [org.springframework.kafka.KafkaListenerEndpointContainer#4-7-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:06.053 [org.springframework.kafka.KafkaListenerEndpointContainer#4-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Discovered coordinator 112.74.59.207:9092 (id: 2147483647 rack: null) for group default-group.
13:58:06.053 [org.springframework.kafka.KafkaListenerEndpointContainer#4-4-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:06.053 [org.springframework.kafka.KafkaListenerEndpointContainer#4-4-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:06.053 [org.springframework.kafka.KafkaListenerEndpointContainer#4-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:06.053 [org.springframework.kafka.KafkaListenerEndpointContainer#4-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Discovered coordinator 112.74.59.207:9092 (id: 2147483647 rack: null) for group default-group.
13:58:06.053 [org.springframework.kafka.KafkaListenerEndpointContainer#4-1-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:06.053 [org.springframework.kafka.KafkaListenerEndpointContainer#4-1-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:06.053 [org.springframework.kafka.KafkaListenerEndpointContainer#4-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:06.062 [org.springframework.kafka.KafkaListenerEndpointContainer#0-7-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Discovered coordinator 112.74.59.207:9092 (id: 2147483647 rack: null) for group default-group.
13:58:06.062 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Discovered coordinator 112.74.59.207:9092 (id: 2147483647 rack: null) for group default-group.
13:58:06.062 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:06.062 [org.springframework.kafka.KafkaListenerEndpointContainer#0-7-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:06.062 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:06.062 [org.springframework.kafka.KafkaListenerEndpointContainer#0-7-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:06.062 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:06.062 [org.springframework.kafka.KafkaListenerEndpointContainer#0-7-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:06.062 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Discovered coordinator 112.74.59.207:9092 (id: 2147483647 rack: null) for group default-group.
13:58:06.062 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:06.062 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:06.062 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:06.338 [Thread-36] INFO  cn.ztuo.aqmd.netty.server.NettyServer - Server started at port 28901
13:58:07.400 [org.springframework.kafka.KafkaListenerEndpointContainer#0-6-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 48
13:58:07.400 [org.springframework.kafka.KafkaListenerEndpointContainer#4-2-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 48
13:58:07.400 [org.springframework.kafka.KafkaListenerEndpointContainer#6-6-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 48
13:58:07.400 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 48
13:58:07.400 [org.springframework.kafka.KafkaListenerEndpointContainer#4-7-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 48
13:58:07.400 [org.springframework.kafka.KafkaListenerEndpointContainer#4-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 48
13:58:07.400 [org.springframework.kafka.KafkaListenerEndpointContainer#6-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 48
13:58:07.400 [org.springframework.kafka.KafkaListenerEndpointContainer#4-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 48
13:58:07.401 [org.springframework.kafka.KafkaListenerEndpointContainer#2-2-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 48
13:58:07.400 [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 48
13:58:07.401 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 48
13:58:07.400 [org.springframework.kafka.KafkaListenerEndpointContainer#5-5-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 48
13:58:07.400 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 48
13:58:07.400 [org.springframework.kafka.KafkaListenerEndpointContainer#5-8-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 48
13:58:07.400 [org.springframework.kafka.KafkaListenerEndpointContainer#5-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 48
13:58:07.400 [org.springframework.kafka.KafkaListenerEndpointContainer#5-6-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 48
13:58:07.400 [org.springframework.kafka.KafkaListenerEndpointContainer#7-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 48
13:58:07.400 [org.springframework.kafka.KafkaListenerEndpointContainer#5-7-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 48
13:58:07.401 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 48
13:58:07.401 [org.springframework.kafka.KafkaListenerEndpointContainer#3-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 48
13:58:07.401 [org.springframework.kafka.KafkaListenerEndpointContainer#3-7-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 48
13:58:07.400 [org.springframework.kafka.KafkaListenerEndpointContainer#1-8-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 48
13:58:07.401 [org.springframework.kafka.KafkaListenerEndpointContainer#0-7-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 48
13:58:07.401 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 48
13:58:07.401 [org.springframework.kafka.KafkaListenerEndpointContainer#2-7-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 48
13:58:07.401 [org.springframework.kafka.KafkaListenerEndpointContainer#6-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 48
13:58:07.403 [org.springframework.kafka.KafkaListenerEndpointContainer#2-7-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:07.404 [org.springframework.kafka.KafkaListenerEndpointContainer#2-7-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:07.401 [org.springframework.kafka.KafkaListenerEndpointContainer#7-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 48
13:58:07.406 [org.springframework.kafka.KafkaListenerEndpointContainer#7-3-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:07.406 [org.springframework.kafka.KafkaListenerEndpointContainer#7-3-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:07.401 [org.springframework.kafka.KafkaListenerEndpointContainer#0-6-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:07.407 [org.springframework.kafka.KafkaListenerEndpointContainer#0-6-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:07.401 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:07.411 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:07.401 [org.springframework.kafka.KafkaListenerEndpointContainer#6-2-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 48
13:58:07.411 [org.springframework.kafka.KafkaListenerEndpointContainer#6-2-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:07.411 [org.springframework.kafka.KafkaListenerEndpointContainer#6-2-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:07.401 [org.springframework.kafka.KafkaListenerEndpointContainer#5-5-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:07.411 [org.springframework.kafka.KafkaListenerEndpointContainer#5-5-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:07.401 [org.springframework.kafka.KafkaListenerEndpointContainer#5-6-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:07.411 [org.springframework.kafka.KafkaListenerEndpointContainer#5-6-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:07.401 [org.springframework.kafka.KafkaListenerEndpointContainer#1-6-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 48
13:58:07.411 [org.springframework.kafka.KafkaListenerEndpointContainer#1-6-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:07.411 [org.springframework.kafka.KafkaListenerEndpointContainer#1-6-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:07.401 [org.springframework.kafka.KafkaListenerEndpointContainer#7-1-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:07.401 [org.springframework.kafka.KafkaListenerEndpointContainer#6-6-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:07.411 [org.springframework.kafka.KafkaListenerEndpointContainer#7-1-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:07.411 [org.springframework.kafka.KafkaListenerEndpointContainer#6-6-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:07.401 [org.springframework.kafka.KafkaListenerEndpointContainer#5-7-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:07.401 [org.springframework.kafka.KafkaListenerEndpointContainer#2-2-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:07.411 [org.springframework.kafka.KafkaListenerEndpointContainer#5-7-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:07.411 [org.springframework.kafka.KafkaListenerEndpointContainer#2-2-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:07.401 [org.springframework.kafka.KafkaListenerEndpointContainer#4-4-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:07.401 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:07.411 [org.springframework.kafka.KafkaListenerEndpointContainer#4-4-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:07.411 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:07.401 [org.springframework.kafka.KafkaListenerEndpointContainer#7-7-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 48
13:58:07.411 [org.springframework.kafka.KafkaListenerEndpointContainer#7-7-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:07.411 [org.springframework.kafka.KafkaListenerEndpointContainer#7-7-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:07.401 [org.springframework.kafka.KafkaListenerEndpointContainer#0-5-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 48
13:58:07.411 [org.springframework.kafka.KafkaListenerEndpointContainer#0-5-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:07.411 [org.springframework.kafka.KafkaListenerEndpointContainer#0-5-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:07.401 [org.springframework.kafka.KafkaListenerEndpointContainer#7-2-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 48
13:58:07.401 [org.springframework.kafka.KafkaListenerEndpointContainer#4-2-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:07.401 [org.springframework.kafka.KafkaListenerEndpointContainer#2-6-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 48
13:58:07.411 [org.springframework.kafka.KafkaListenerEndpointContainer#4-2-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:07.411 [org.springframework.kafka.KafkaListenerEndpointContainer#2-6-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:07.411 [org.springframework.kafka.KafkaListenerEndpointContainer#2-6-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:07.401 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 48
13:58:07.401 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 48
13:58:07.411 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:07.411 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:07.401 [org.springframework.kafka.KafkaListenerEndpointContainer#3-2-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 48
13:58:07.411 [org.springframework.kafka.KafkaListenerEndpointContainer#3-2-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:07.411 [org.springframework.kafka.KafkaListenerEndpointContainer#3-2-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:07.402 [org.springframework.kafka.KafkaListenerEndpointContainer#3-1-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:07.402 [org.springframework.kafka.KafkaListenerEndpointContainer#6-3-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:07.402 [org.springframework.kafka.KafkaListenerEndpointContainer#3-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 48
13:58:07.411 [org.springframework.kafka.KafkaListenerEndpointContainer#3-1-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:07.411 [org.springframework.kafka.KafkaListenerEndpointContainer#3-4-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:07.411 [org.springframework.kafka.KafkaListenerEndpointContainer#3-4-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:07.402 [org.springframework.kafka.KafkaListenerEndpointContainer#5-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 48
13:58:07.411 [org.springframework.kafka.KafkaListenerEndpointContainer#5-1-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:07.411 [org.springframework.kafka.KafkaListenerEndpointContainer#5-1-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:07.402 [org.springframework.kafka.KafkaListenerEndpointContainer#2-5-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 48
13:58:07.411 [org.springframework.kafka.KafkaListenerEndpointContainer#2-5-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:07.411 [org.springframework.kafka.KafkaListenerEndpointContainer#2-5-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:07.402 [org.springframework.kafka.KafkaListenerEndpointContainer#1-2-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 48
13:58:07.402 [org.springframework.kafka.KafkaListenerEndpointContainer#1-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 48
13:58:07.411 [org.springframework.kafka.KafkaListenerEndpointContainer#1-2-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:07.411 [org.springframework.kafka.KafkaListenerEndpointContainer#1-3-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:07.411 [org.springframework.kafka.KafkaListenerEndpointContainer#1-2-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:07.402 [org.springframework.kafka.KafkaListenerEndpointContainer#6-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 48
13:58:07.411 [org.springframework.kafka.KafkaListenerEndpointContainer#6-4-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:07.411 [org.springframework.kafka.KafkaListenerEndpointContainer#6-4-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:07.402 [org.springframework.kafka.KafkaListenerEndpointContainer#1-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 48
13:58:07.402 [org.springframework.kafka.KafkaListenerEndpointContainer#3-8-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 48
13:58:07.411 [org.springframework.kafka.KafkaListenerEndpointContainer#3-8-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:07.402 [org.springframework.kafka.KafkaListenerEndpointContainer#6-8-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 48
13:58:07.411 [org.springframework.kafka.KafkaListenerEndpointContainer#3-8-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:07.411 [org.springframework.kafka.KafkaListenerEndpointContainer#6-8-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:07.411 [org.springframework.kafka.KafkaListenerEndpointContainer#6-8-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:07.402 [org.springframework.kafka.KafkaListenerEndpointContainer#3-7-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:07.411 [org.springframework.kafka.KafkaListenerEndpointContainer#3-7-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:07.402 [org.springframework.kafka.KafkaListenerEndpointContainer#7-8-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 48
13:58:07.402 [org.springframework.kafka.KafkaListenerEndpointContainer#5-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 48
13:58:07.402 [org.springframework.kafka.KafkaListenerEndpointContainer#4-6-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 48
13:58:07.402 [org.springframework.kafka.KafkaListenerEndpointContainer#4-5-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 48
13:58:07.411 [org.springframework.kafka.KafkaListenerEndpointContainer#4-5-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:07.411 [org.springframework.kafka.KafkaListenerEndpointContainer#4-5-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:07.411 [org.springframework.kafka.KafkaListenerEndpointContainer#7-8-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:07.418 [org.springframework.kafka.KafkaListenerEndpointContainer#7-8-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:07.402 [org.springframework.kafka.KafkaListenerEndpointContainer#2-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 48
13:58:07.402 [org.springframework.kafka.KafkaListenerEndpointContainer#3-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 48
13:58:07.402 [org.springframework.kafka.KafkaListenerEndpointContainer#3-5-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 48
13:58:07.418 [org.springframework.kafka.KafkaListenerEndpointContainer#2-4-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:07.418 [org.springframework.kafka.KafkaListenerEndpointContainer#3-5-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:07.418 [org.springframework.kafka.KafkaListenerEndpointContainer#2-4-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:07.418 [org.springframework.kafka.KafkaListenerEndpointContainer#3-5-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:07.402 [org.springframework.kafka.KafkaListenerEndpointContainer#1-8-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:07.402 [org.springframework.kafka.KafkaListenerEndpointContainer#1-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 48
13:58:07.418 [org.springframework.kafka.KafkaListenerEndpointContainer#1-8-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:07.418 [org.springframework.kafka.KafkaListenerEndpointContainer#1-4-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:07.402 [org.springframework.kafka.KafkaListenerEndpointContainer#7-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 48
13:58:07.402 [org.springframework.kafka.KafkaListenerEndpointContainer#4-0-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [exchange-market-symbol-0] for group default-group
13:58:07.418 [org.springframework.kafka.KafkaListenerEndpointContainer#7-0-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [exchange-waiting-order-cancel-0] for group default-group
13:58:07.401 [org.springframework.kafka.KafkaListenerEndpointContainer#7-5-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 48
13:58:07.418 [org.springframework.kafka.KafkaListenerEndpointContainer#7-5-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:07.418 [org.springframework.kafka.KafkaListenerEndpointContainer#7-5-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:07.402 [org.springframework.kafka.KafkaListenerEndpointContainer#3-6-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 48
13:58:07.418 [org.springframework.kafka.KafkaListenerEndpointContainer#3-6-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:07.420 [org.springframework.kafka.KafkaListenerEndpointContainer#3-6-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:07.402 [org.springframework.kafka.KafkaListenerEndpointContainer#2-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 48
13:58:07.420 [org.springframework.kafka.KafkaListenerEndpointContainer#2-3-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:07.420 [org.springframework.kafka.KafkaListenerEndpointContainer#2-3-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:07.402 [org.springframework.kafka.KafkaListenerEndpointContainer#4-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 48
13:58:07.420 [org.springframework.kafka.KafkaListenerEndpointContainer#4-1-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:07.420 [org.springframework.kafka.KafkaListenerEndpointContainer#4-1-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:07.402 [org.springframework.kafka.KafkaListenerEndpointContainer#5-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 48
13:58:07.420 [org.springframework.kafka.KafkaListenerEndpointContainer#5-4-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:07.420 [org.springframework.kafka.KafkaListenerEndpointContainer#5-4-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:07.402 [org.springframework.kafka.KafkaListenerEndpointContainer#0-7-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:07.402 [org.springframework.kafka.KafkaListenerEndpointContainer#1-7-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 48
13:58:07.420 [org.springframework.kafka.KafkaListenerEndpointContainer#1-7-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:07.420 [org.springframework.kafka.KafkaListenerEndpointContainer#1-7-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:07.402 [org.springframework.kafka.KafkaListenerEndpointContainer#1-5-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 48
13:58:07.420 [org.springframework.kafka.KafkaListenerEndpointContainer#1-5-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:07.420 [org.springframework.kafka.KafkaListenerEndpointContainer#1-5-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:07.402 [org.springframework.kafka.KafkaListenerEndpointContainer#4-8-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 48
13:58:07.420 [org.springframework.kafka.KafkaListenerEndpointContainer#4-8-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:07.420 [org.springframework.kafka.KafkaListenerEndpointContainer#4-8-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:07.402 [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [exchange-waiting-order-0] for group default-group
13:58:07.402 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [exchange-trade-plate-0] for group default-group
13:58:07.402 [org.springframework.kafka.KafkaListenerEndpointContainer#7-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 48
13:58:07.402 [org.springframework.kafka.KafkaListenerEndpointContainer#6-7-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 48
13:58:07.402 [org.springframework.kafka.KafkaListenerEndpointContainer#5-0-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [exchange-order-cancel-success-0] for group default-group
13:58:07.402 [org.springframework.kafka.KafkaListenerEndpointContainer#4-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 48
13:58:07.402 [org.springframework.kafka.KafkaListenerEndpointContainer#5-8-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:07.402 [org.springframework.kafka.KafkaListenerEndpointContainer#5-2-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 48
13:58:07.402 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [exchange-trade-0] for group default-group
13:58:07.402 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [exchange-order-completed-0] for group default-group
13:58:07.402 [org.springframework.kafka.KafkaListenerEndpointContainer#4-7-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:07.420 [org.springframework.kafka.KafkaListenerEndpointContainer#4-7-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:07.402 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 48
13:58:07.420 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:07.420 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:07.402 [org.springframework.kafka.KafkaListenerEndpointContainer#6-5-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 48
13:58:07.402 [org.springframework.kafka.KafkaListenerEndpointContainer#0-8-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 48
13:58:07.420 [org.springframework.kafka.KafkaListenerEndpointContainer#6-5-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:07.420 [org.springframework.kafka.KafkaListenerEndpointContainer#6-5-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:07.420 [org.springframework.kafka.KafkaListenerEndpointContainer#0-8-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:07.403 [org.springframework.kafka.KafkaListenerEndpointContainer#6-1-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:07.402 [org.springframework.kafka.KafkaListenerEndpointContainer#2-8-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 48
13:58:07.420 [org.springframework.kafka.KafkaListenerEndpointContainer#2-8-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:07.420 [org.springframework.kafka.KafkaListenerEndpointContainer#0-8-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:07.420 [org.springframework.kafka.KafkaListenerEndpointContainer#2-8-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:07.420 [org.springframework.kafka.KafkaListenerEndpointContainer#6-1-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:07.411 [org.springframework.kafka.KafkaListenerEndpointContainer#7-2-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:07.411 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [exchange-trade-mocker-0] for group default-group
13:58:07.420 [org.springframework.kafka.KafkaListenerEndpointContainer#7-2-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:07.411 [org.springframework.kafka.KafkaListenerEndpointContainer#6-3-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:07.411 [org.springframework.kafka.KafkaListenerEndpointContainer#1-3-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:07.411 [org.springframework.kafka.KafkaListenerEndpointContainer#1-1-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:07.411 [org.springframework.kafka.KafkaListenerEndpointContainer#5-3-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:07.428 [org.springframework.kafka.KafkaListenerEndpointContainer#5-3-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:07.411 [org.springframework.kafka.KafkaListenerEndpointContainer#4-6-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:07.418 [org.springframework.kafka.KafkaListenerEndpointContainer#3-3-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:07.418 [org.springframework.kafka.KafkaListenerEndpointContainer#1-4-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:07.428 [org.springframework.kafka.KafkaListenerEndpointContainer#3-3-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:07.420 [org.springframework.kafka.KafkaListenerEndpointContainer#7-4-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:07.420 [org.springframework.kafka.KafkaListenerEndpointContainer#6-7-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:07.428 [org.springframework.kafka.KafkaListenerEndpointContainer#7-4-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:07.428 [org.springframework.kafka.KafkaListenerEndpointContainer#6-7-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:07.420 [org.springframework.kafka.KafkaListenerEndpointContainer#0-7-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:07.420 [org.springframework.kafka.KafkaListenerEndpointContainer#4-3-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:07.420 [org.springframework.kafka.KafkaListenerEndpointContainer#5-8-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:07.428 [org.springframework.kafka.KafkaListenerEndpointContainer#4-3-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:07.420 [org.springframework.kafka.KafkaListenerEndpointContainer#1-1-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:07.428 [org.springframework.kafka.KafkaListenerEndpointContainer#4-6-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:07.420 [org.springframework.kafka.KafkaListenerEndpointContainer#5-2-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:07.428 [org.springframework.kafka.KafkaListenerEndpointContainer#5-2-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:07.511 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[exchange-order-completed-0]
13:58:07.511 [org.springframework.kafka.KafkaListenerEndpointContainer#4-0-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[exchange-market-symbol-0]
13:58:07.511 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[exchange-trade-0]
13:58:07.511 [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[exchange-waiting-order-0]
13:58:07.511 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[exchange-trade-mocker-0]
13:58:07.511 [org.springframework.kafka.KafkaListenerEndpointContainer#5-0-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[exchange-order-cancel-success-0]
13:58:07.511 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[exchange-trade-plate-0]
13:58:07.519 [org.springframework.kafka.KafkaListenerEndpointContainer#7-0-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[exchange-waiting-order-cancel-0]
13:58:10.446 [org.springframework.kafka.KafkaListenerEndpointContainer#0-6-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:10.446 [org.springframework.kafka.KafkaListenerEndpointContainer#0-6-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:10.446 [org.springframework.kafka.KafkaListenerEndpointContainer#2-7-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:10.446 [org.springframework.kafka.KafkaListenerEndpointContainer#0-6-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:10.446 [org.springframework.kafka.KafkaListenerEndpointContainer#2-7-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:10.446 [org.springframework.kafka.KafkaListenerEndpointContainer#7-3-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:10.446 [org.springframework.kafka.KafkaListenerEndpointContainer#2-7-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:10.446 [org.springframework.kafka.KafkaListenerEndpointContainer#7-3-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:10.446 [org.springframework.kafka.KafkaListenerEndpointContainer#7-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:10.462 [org.springframework.kafka.KafkaListenerEndpointContainer#2-3-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:10.462 [org.springframework.kafka.KafkaListenerEndpointContainer#6-6-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:10.462 [org.springframework.kafka.KafkaListenerEndpointContainer#2-3-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:10.462 [org.springframework.kafka.KafkaListenerEndpointContainer#1-7-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:10.462 [org.springframework.kafka.KafkaListenerEndpointContainer#6-6-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:10.462 [org.springframework.kafka.KafkaListenerEndpointContainer#1-7-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:10.462 [org.springframework.kafka.KafkaListenerEndpointContainer#6-1-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:10.462 [org.springframework.kafka.KafkaListenerEndpointContainer#2-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:10.462 [org.springframework.kafka.KafkaListenerEndpointContainer#7-5-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:10.462 [org.springframework.kafka.KafkaListenerEndpointContainer#6-6-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:10.462 [org.springframework.kafka.KafkaListenerEndpointContainer#1-8-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:10.462 [org.springframework.kafka.KafkaListenerEndpointContainer#6-1-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:10.462 [org.springframework.kafka.KafkaListenerEndpointContainer#3-1-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:10.462 [org.springframework.kafka.KafkaListenerEndpointContainer#1-7-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:10.462 [org.springframework.kafka.KafkaListenerEndpointContainer#7-5-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:10.462 [org.springframework.kafka.KafkaListenerEndpointContainer#1-8-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:10.462 [org.springframework.kafka.KafkaListenerEndpointContainer#7-5-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:10.462 [org.springframework.kafka.KafkaListenerEndpointContainer#6-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:10.462 [org.springframework.kafka.KafkaListenerEndpointContainer#0-7-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:10.462 [org.springframework.kafka.KafkaListenerEndpointContainer#1-8-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:10.462 [org.springframework.kafka.KafkaListenerEndpointContainer#0-7-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:10.462 [org.springframework.kafka.KafkaListenerEndpointContainer#1-6-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:10.462 [org.springframework.kafka.KafkaListenerEndpointContainer#1-6-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:10.462 [org.springframework.kafka.KafkaListenerEndpointContainer#3-1-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:10.462 [org.springframework.kafka.KafkaListenerEndpointContainer#5-6-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:10.462 [org.springframework.kafka.KafkaListenerEndpointContainer#5-6-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:10.462 [org.springframework.kafka.KafkaListenerEndpointContainer#0-7-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:10.462 [org.springframework.kafka.KafkaListenerEndpointContainer#1-6-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:10.462 [org.springframework.kafka.KafkaListenerEndpointContainer#3-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:10.462 [org.springframework.kafka.KafkaListenerEndpointContainer#5-6-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:10.462 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:10.462 [org.springframework.kafka.KafkaListenerEndpointContainer#0-5-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:10.462 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:10.462 [org.springframework.kafka.KafkaListenerEndpointContainer#0-5-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:10.462 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:10.462 [org.springframework.kafka.KafkaListenerEndpointContainer#0-5-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:10.462 [org.springframework.kafka.KafkaListenerEndpointContainer#3-5-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:10.462 [org.springframework.kafka.KafkaListenerEndpointContainer#3-5-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:10.462 [org.springframework.kafka.KafkaListenerEndpointContainer#3-5-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:10.462 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:10.462 [org.springframework.kafka.KafkaListenerEndpointContainer#5-8-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:10.462 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:10.462 [org.springframework.kafka.KafkaListenerEndpointContainer#7-2-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:10.462 [org.springframework.kafka.KafkaListenerEndpointContainer#5-8-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:10.462 [org.springframework.kafka.KafkaListenerEndpointContainer#3-2-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:10.462 [org.springframework.kafka.KafkaListenerEndpointContainer#5-8-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:10.462 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:10.462 [org.springframework.kafka.KafkaListenerEndpointContainer#3-2-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:10.462 [org.springframework.kafka.KafkaListenerEndpointContainer#7-2-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:10.462 [org.springframework.kafka.KafkaListenerEndpointContainer#3-6-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:10.477 [org.springframework.kafka.KafkaListenerEndpointContainer#7-2-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:10.462 [org.springframework.kafka.KafkaListenerEndpointContainer#3-2-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:10.462 [org.springframework.kafka.KafkaListenerEndpointContainer#3-4-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:10.462 [org.springframework.kafka.KafkaListenerEndpointContainer#5-5-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:10.477 [org.springframework.kafka.KafkaListenerEndpointContainer#3-4-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:10.462 [org.springframework.kafka.KafkaListenerEndpointContainer#1-3-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:10.477 [org.springframework.kafka.KafkaListenerEndpointContainer#2-8-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:10.462 [org.springframework.kafka.KafkaListenerEndpointContainer#4-2-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:10.477 [org.springframework.kafka.KafkaListenerEndpointContainer#4-3-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:10.462 [org.springframework.kafka.KafkaListenerEndpointContainer#4-5-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:10.477 [org.springframework.kafka.KafkaListenerEndpointContainer#5-2-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:10.477 [org.springframework.kafka.KafkaListenerEndpointContainer#4-6-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:10.477 [org.springframework.kafka.KafkaListenerEndpointContainer#4-2-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:10.477 [org.springframework.kafka.KafkaListenerEndpointContainer#4-6-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:10.462 [org.springframework.kafka.KafkaListenerEndpointContainer#3-7-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:10.477 [org.springframework.kafka.KafkaListenerEndpointContainer#2-2-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:10.477 [org.springframework.kafka.KafkaListenerEndpointContainer#3-6-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:10.477 [org.springframework.kafka.KafkaListenerEndpointContainer#5-4-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:10.477 [org.springframework.kafka.KafkaListenerEndpointContainer#5-5-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:10.477 [org.springframework.kafka.KafkaListenerEndpointContainer#5-4-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:10.477 [org.springframework.kafka.KafkaListenerEndpointContainer#5-2-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:10.477 [org.springframework.kafka.KafkaListenerEndpointContainer#4-2-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:10.477 [org.springframework.kafka.KafkaListenerEndpointContainer#7-1-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:10.477 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:10.477 [org.springframework.kafka.KafkaListenerEndpointContainer#7-1-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:10.477 [org.springframework.kafka.KafkaListenerEndpointContainer#5-7-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:10.477 [org.springframework.kafka.KafkaListenerEndpointContainer#7-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:10.477 [org.springframework.kafka.KafkaListenerEndpointContainer#5-7-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:10.477 [org.springframework.kafka.KafkaListenerEndpointContainer#3-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:10.477 [org.springframework.kafka.KafkaListenerEndpointContainer#2-8-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:10.477 [org.springframework.kafka.KafkaListenerEndpointContainer#3-8-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:10.477 [org.springframework.kafka.KafkaListenerEndpointContainer#1-3-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:10.477 [org.springframework.kafka.KafkaListenerEndpointContainer#4-3-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:10.477 [org.springframework.kafka.KafkaListenerEndpointContainer#6-2-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:10.477 [org.springframework.kafka.KafkaListenerEndpointContainer#4-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:10.477 [org.springframework.kafka.KafkaListenerEndpointContainer#4-5-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:10.477 [org.springframework.kafka.KafkaListenerEndpointContainer#3-8-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:10.477 [org.springframework.kafka.KafkaListenerEndpointContainer#4-6-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:10.477 [org.springframework.kafka.KafkaListenerEndpointContainer#3-8-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:10.477 [org.springframework.kafka.KafkaListenerEndpointContainer#1-1-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:10.477 [org.springframework.kafka.KafkaListenerEndpointContainer#4-8-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:10.477 [org.springframework.kafka.KafkaListenerEndpointContainer#1-1-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:10.477 [org.springframework.kafka.KafkaListenerEndpointContainer#4-8-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:10.477 [org.springframework.kafka.KafkaListenerEndpointContainer#3-7-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:10.477 [org.springframework.kafka.KafkaListenerEndpointContainer#4-8-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:10.477 [org.springframework.kafka.KafkaListenerEndpointContainer#2-2-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:10.477 [org.springframework.kafka.KafkaListenerEndpointContainer#2-6-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:10.477 [org.springframework.kafka.KafkaListenerEndpointContainer#4-4-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:10.477 [org.springframework.kafka.KafkaListenerEndpointContainer#4-7-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:10.477 [org.springframework.kafka.KafkaListenerEndpointContainer#7-7-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:10.477 [org.springframework.kafka.KafkaListenerEndpointContainer#5-7-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:10.477 [org.springframework.kafka.KafkaListenerEndpointContainer#2-6-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:10.477 [org.springframework.kafka.KafkaListenerEndpointContainer#3-6-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:10.477 [org.springframework.kafka.KafkaListenerEndpointContainer#5-5-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:10.477 [org.springframework.kafka.KafkaListenerEndpointContainer#1-5-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:10.477 [org.springframework.kafka.KafkaListenerEndpointContainer#2-8-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:10.477 [org.springframework.kafka.KafkaListenerEndpointContainer#5-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:10.477 [org.springframework.kafka.KafkaListenerEndpointContainer#5-2-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:10.477 [org.springframework.kafka.KafkaListenerEndpointContainer#1-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:10.477 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:10.477 [org.springframework.kafka.KafkaListenerEndpointContainer#6-2-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:10.477 [org.springframework.kafka.KafkaListenerEndpointContainer#6-8-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:10.477 [org.springframework.kafka.KafkaListenerEndpointContainer#1-4-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:10.477 [org.springframework.kafka.KafkaListenerEndpointContainer#6-8-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:10.477 [org.springframework.kafka.KafkaListenerEndpointContainer#1-4-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:10.477 [org.springframework.kafka.KafkaListenerEndpointContainer#6-5-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:10.477 [org.springframework.kafka.KafkaListenerEndpointContainer#4-5-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:10.477 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:10.477 [org.springframework.kafka.KafkaListenerEndpointContainer#1-2-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:10.477 [org.springframework.kafka.KafkaListenerEndpointContainer#6-2-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:10.477 [org.springframework.kafka.KafkaListenerEndpointContainer#1-2-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:10.477 [org.springframework.kafka.KafkaListenerEndpointContainer#4-1-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:10.477 [org.springframework.kafka.KafkaListenerEndpointContainer#6-3-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:10.477 [org.springframework.kafka.KafkaListenerEndpointContainer#1-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:10.477 [org.springframework.kafka.KafkaListenerEndpointContainer#1-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:10.477 [org.springframework.kafka.KafkaListenerEndpointContainer#6-5-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:10.477 [org.springframework.kafka.KafkaListenerEndpointContainer#5-3-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:10.477 [org.springframework.kafka.KafkaListenerEndpointContainer#7-4-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:10.477 [org.springframework.kafka.KafkaListenerEndpointContainer#6-7-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:10.477 [org.springframework.kafka.KafkaListenerEndpointContainer#7-4-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:10.477 [org.springframework.kafka.KafkaListenerEndpointContainer#6-7-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:10.477 [org.springframework.kafka.KafkaListenerEndpointContainer#3-7-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:10.477 [org.springframework.kafka.KafkaListenerEndpointContainer#1-2-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:10.477 [org.springframework.kafka.KafkaListenerEndpointContainer#4-1-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:10.477 [org.springframework.kafka.KafkaListenerEndpointContainer#6-4-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:10.477 [org.springframework.kafka.KafkaListenerEndpointContainer#7-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:10.477 [org.springframework.kafka.KafkaListenerEndpointContainer#2-5-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:10.477 [org.springframework.kafka.KafkaListenerEndpointContainer#4-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:10.477 [org.springframework.kafka.KafkaListenerEndpointContainer#4-7-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:10.477 [org.springframework.kafka.KafkaListenerEndpointContainer#2-2-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:10.477 [org.springframework.kafka.KafkaListenerEndpointContainer#4-7-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:10.477 [org.springframework.kafka.KafkaListenerEndpointContainer#7-7-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:10.477 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:10.477 [org.springframework.kafka.KafkaListenerEndpointContainer#5-1-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:10.477 [org.springframework.kafka.KafkaListenerEndpointContainer#4-4-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:10.477 [org.springframework.kafka.KafkaListenerEndpointContainer#2-6-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:10.477 [org.springframework.kafka.KafkaListenerEndpointContainer#1-5-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:10.477 [org.springframework.kafka.KafkaListenerEndpointContainer#0-8-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:10.477 [org.springframework.kafka.KafkaListenerEndpointContainer#0-8-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:10.477 [org.springframework.kafka.KafkaListenerEndpointContainer#7-8-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:10.477 [org.springframework.kafka.KafkaListenerEndpointContainer#7-8-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:10.477 [org.springframework.kafka.KafkaListenerEndpointContainer#7-8-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:10.477 [org.springframework.kafka.KafkaListenerEndpointContainer#2-4-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:10.477 [org.springframework.kafka.KafkaListenerEndpointContainer#2-4-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:10.477 [org.springframework.kafka.KafkaListenerEndpointContainer#3-3-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:10.477 [org.springframework.kafka.KafkaListenerEndpointContainer#6-8-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:10.477 [org.springframework.kafka.KafkaListenerEndpointContainer#6-3-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:10.477 [org.springframework.kafka.KafkaListenerEndpointContainer#5-3-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:10.477 [org.springframework.kafka.KafkaListenerEndpointContainer#6-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:10.477 [org.springframework.kafka.KafkaListenerEndpointContainer#5-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:10.477 [org.springframework.kafka.KafkaListenerEndpointContainer#6-5-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:10.477 [org.springframework.kafka.KafkaListenerEndpointContainer#6-4-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:10.477 [org.springframework.kafka.KafkaListenerEndpointContainer#6-7-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:10.477 [org.springframework.kafka.KafkaListenerEndpointContainer#2-5-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:10.477 [org.springframework.kafka.KafkaListenerEndpointContainer#7-7-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:10.477 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:10.477 [org.springframework.kafka.KafkaListenerEndpointContainer#5-1-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:10.477 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:10.477 [org.springframework.kafka.KafkaListenerEndpointContainer#4-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:10.477 [org.springframework.kafka.KafkaListenerEndpointContainer#1-5-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:10.477 [org.springframework.kafka.KafkaListenerEndpointContainer#0-8-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:10.477 [org.springframework.kafka.KafkaListenerEndpointContainer#2-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:10.477 [org.springframework.kafka.KafkaListenerEndpointContainer#3-3-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:10.477 [org.springframework.kafka.KafkaListenerEndpointContainer#6-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:10.477 [org.springframework.kafka.KafkaListenerEndpointContainer#2-5-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:10.477 [org.springframework.kafka.KafkaListenerEndpointContainer#5-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:10.477 [org.springframework.kafka.KafkaListenerEndpointContainer#3-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:10.546 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [exchange-order-completed-0] for group default-group
13:58:10.546 [org.springframework.kafka.KafkaListenerEndpointContainer#4-0-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [exchange-market-symbol-0] for group default-group
13:58:10.546 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [exchange-trade-mocker-0] for group default-group
13:58:10.546 [org.springframework.kafka.KafkaListenerEndpointContainer#5-0-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [exchange-order-cancel-success-0] for group default-group
13:58:10.546 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [exchange-trade-plate-0] for group default-group
13:58:10.546 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [exchange-trade-0] for group default-group
13:58:10.546 [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [exchange-waiting-order-0] for group default-group
13:58:10.562 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[exchange-trade-0]
13:58:10.562 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[exchange-trade-plate-0]
13:58:10.562 [org.springframework.kafka.KafkaListenerEndpointContainer#5-0-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[exchange-order-cancel-success-0]
13:58:10.562 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[exchange-trade-mocker-0]
13:58:10.562 [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[exchange-waiting-order-0]
13:58:10.562 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:10.562 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:10.562 [org.springframework.kafka.KafkaListenerEndpointContainer#5-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:10.562 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:10.562 [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:10.578 [org.springframework.kafka.KafkaListenerEndpointContainer#7-0-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [exchange-waiting-order-cancel-0] for group default-group
13:58:11.544 [org.springframework.kafka.KafkaListenerEndpointContainer#4-0-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[exchange-market-symbol-0]
13:58:11.544 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[exchange-order-completed-0]
13:58:11.548 [org.springframework.kafka.KafkaListenerEndpointContainer#4-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:11.548 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:11.571 [org.springframework.kafka.KafkaListenerEndpointContainer#7-0-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[exchange-waiting-order-cancel-0]
13:58:11.571 [org.springframework.kafka.KafkaListenerEndpointContainer#7-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:11.649 [org.springframework.kafka.KafkaListenerEndpointContainer#1-7-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 49
13:58:11.649 [org.springframework.kafka.KafkaListenerEndpointContainer#5-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 49
13:58:11.649 [org.springframework.kafka.KafkaListenerEndpointContainer#1-7-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:11.649 [org.springframework.kafka.KafkaListenerEndpointContainer#3-7-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 49
13:58:11.649 [org.springframework.kafka.KafkaListenerEndpointContainer#5-0-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [exchange-order-cancel-success-0] for group default-group
13:58:11.649 [org.springframework.kafka.KafkaListenerEndpointContainer#3-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 49
13:58:11.649 [org.springframework.kafka.KafkaListenerEndpointContainer#0-7-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 49
13:58:11.649 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 49
13:58:11.649 [org.springframework.kafka.KafkaListenerEndpointContainer#0-7-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:11.649 [org.springframework.kafka.KafkaListenerEndpointContainer#2-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 49
13:58:11.649 [org.springframework.kafka.KafkaListenerEndpointContainer#3-8-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 49
13:58:11.649 [org.springframework.kafka.KafkaListenerEndpointContainer#2-3-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:11.649 [org.springframework.kafka.KafkaListenerEndpointContainer#3-8-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:11.649 [org.springframework.kafka.KafkaListenerEndpointContainer#7-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 49
13:58:11.649 [org.springframework.kafka.KafkaListenerEndpointContainer#1-7-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:11.649 [org.springframework.kafka.KafkaListenerEndpointContainer#3-7-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:11.649 [org.springframework.kafka.KafkaListenerEndpointContainer#3-8-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:11.649 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [exchange-trade-0] for group default-group
13:58:11.649 [org.springframework.kafka.KafkaListenerEndpointContainer#3-4-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:11.649 [org.springframework.kafka.KafkaListenerEndpointContainer#3-7-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:11.649 [org.springframework.kafka.KafkaListenerEndpointContainer#3-4-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:11.649 [org.springframework.kafka.KafkaListenerEndpointContainer#0-7-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:11.649 [org.springframework.kafka.KafkaListenerEndpointContainer#1-6-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 49
13:58:11.649 [org.springframework.kafka.KafkaListenerEndpointContainer#1-8-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 49
13:58:11.649 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 49
13:58:11.649 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 49
13:58:11.649 [org.springframework.kafka.KafkaListenerEndpointContainer#5-2-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 49
13:58:11.649 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [exchange-trade-plate-0] for group default-group
13:58:11.649 [org.springframework.kafka.KafkaListenerEndpointContainer#4-2-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 49
13:58:11.649 [org.springframework.kafka.KafkaListenerEndpointContainer#0-6-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 49
13:58:11.649 [org.springframework.kafka.KafkaListenerEndpointContainer#4-2-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:11.649 [org.springframework.kafka.KafkaListenerEndpointContainer#1-6-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:11.649 [org.springframework.kafka.KafkaListenerEndpointContainer#1-8-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:11.649 [org.springframework.kafka.KafkaListenerEndpointContainer#1-6-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:11.649 [org.springframework.kafka.KafkaListenerEndpointContainer#7-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 49
13:58:11.649 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [exchange-order-completed-0] for group default-group
13:58:11.649 [org.springframework.kafka.KafkaListenerEndpointContainer#7-1-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:11.649 [org.springframework.kafka.KafkaListenerEndpointContainer#2-3-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:11.649 [org.springframework.kafka.KafkaListenerEndpointContainer#7-1-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:11.649 [org.springframework.kafka.KafkaListenerEndpointContainer#2-7-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 49
13:58:11.649 [org.springframework.kafka.KafkaListenerEndpointContainer#6-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 49
13:58:11.649 [org.springframework.kafka.KafkaListenerEndpointContainer#2-7-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:11.649 [org.springframework.kafka.KafkaListenerEndpointContainer#7-5-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 49
13:58:11.649 [org.springframework.kafka.KafkaListenerEndpointContainer#4-2-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:11.649 [org.springframework.kafka.KafkaListenerEndpointContainer#7-5-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:11.649 [org.springframework.kafka.KafkaListenerEndpointContainer#6-2-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 49
13:58:11.649 [org.springframework.kafka.KafkaListenerEndpointContainer#4-7-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 49
13:58:11.649 [org.springframework.kafka.KafkaListenerEndpointContainer#3-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 49
13:58:11.649 [org.springframework.kafka.KafkaListenerEndpointContainer#7-3-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:11.656 [org.springframework.kafka.KafkaListenerEndpointContainer#3-1-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:11.649 [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 49
13:58:11.649 [org.springframework.kafka.KafkaListenerEndpointContainer#5-5-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 49
13:58:11.649 [org.springframework.kafka.KafkaListenerEndpointContainer#6-6-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 49
13:58:11.656 [org.springframework.kafka.KafkaListenerEndpointContainer#5-5-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:11.649 [org.springframework.kafka.KafkaListenerEndpointContainer#7-6-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 49
13:58:11.649 [org.springframework.kafka.KafkaListenerEndpointContainer#2-7-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:11.649 [org.springframework.kafka.KafkaListenerEndpointContainer#2-2-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 49
13:58:11.649 [org.springframework.kafka.KafkaListenerEndpointContainer#5-2-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:11.656 [org.springframework.kafka.KafkaListenerEndpointContainer#6-2-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:11.656 [org.springframework.kafka.KafkaListenerEndpointContainer#4-7-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:11.656 [org.springframework.kafka.KafkaListenerEndpointContainer#4-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 49
13:58:11.649 [org.springframework.kafka.KafkaListenerEndpointContainer#0-6-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:11.649 [org.springframework.kafka.KafkaListenerEndpointContainer#1-8-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:11.656 [org.springframework.kafka.KafkaListenerEndpointContainer#3-1-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:11.656 [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [exchange-waiting-order-0] for group default-group
13:58:11.656 [org.springframework.kafka.KafkaListenerEndpointContainer#5-6-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 49
13:58:11.649 [org.springframework.kafka.KafkaListenerEndpointContainer#6-1-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:11.656 [org.springframework.kafka.KafkaListenerEndpointContainer#6-1-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:11.656 [org.springframework.kafka.KafkaListenerEndpointContainer#5-5-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:11.656 [org.springframework.kafka.KafkaListenerEndpointContainer#7-6-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:11.649 [org.springframework.kafka.KafkaListenerEndpointContainer#7-5-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:11.656 [org.springframework.kafka.KafkaListenerEndpointContainer#5-8-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 49
13:58:11.656 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 49
13:58:11.656 [org.springframework.kafka.KafkaListenerEndpointContainer#0-5-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 49
13:58:11.656 [org.springframework.kafka.KafkaListenerEndpointContainer#5-2-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:11.656 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 49
13:58:11.656 [org.springframework.kafka.KafkaListenerEndpointContainer#7-3-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:11.656 [org.springframework.kafka.KafkaListenerEndpointContainer#3-5-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 49
13:58:11.656 [org.springframework.kafka.KafkaListenerEndpointContainer#6-2-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:11.656 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:11.656 [org.springframework.kafka.KafkaListenerEndpointContainer#6-6-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:11.656 [org.springframework.kafka.KafkaListenerEndpointContainer#2-2-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:11.656 [org.springframework.kafka.KafkaListenerEndpointContainer#0-6-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:11.656 [org.springframework.kafka.KafkaListenerEndpointContainer#4-7-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:11.656 [org.springframework.kafka.KafkaListenerEndpointContainer#3-5-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:11.656 [org.springframework.kafka.KafkaListenerEndpointContainer#4-6-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 49
13:58:11.656 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:11.656 [org.springframework.kafka.KafkaListenerEndpointContainer#4-0-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [exchange-market-symbol-0] for group default-group
13:58:11.656 [org.springframework.kafka.KafkaListenerEndpointContainer#3-6-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 49
13:58:11.656 [org.springframework.kafka.KafkaListenerEndpointContainer#5-6-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:11.656 [org.springframework.kafka.KafkaListenerEndpointContainer#4-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 49
13:58:11.656 [org.springframework.kafka.KafkaListenerEndpointContainer#2-6-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 49
13:58:11.656 [org.springframework.kafka.KafkaListenerEndpointContainer#7-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 49
13:58:11.656 [org.springframework.kafka.KafkaListenerEndpointContainer#1-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 49
13:58:11.656 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 49
13:58:11.656 [org.springframework.kafka.KafkaListenerEndpointContainer#4-5-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 49
13:58:11.656 [org.springframework.kafka.KafkaListenerEndpointContainer#6-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 49
13:58:11.656 [org.springframework.kafka.KafkaListenerEndpointContainer#4-5-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:11.656 [org.springframework.kafka.KafkaListenerEndpointContainer#7-6-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:11.656 [org.springframework.kafka.KafkaListenerEndpointContainer#4-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 49
13:58:11.656 [org.springframework.kafka.KafkaListenerEndpointContainer#3-5-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:11.656 [org.springframework.kafka.KafkaListenerEndpointContainer#4-8-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 49
13:58:11.656 [org.springframework.kafka.KafkaListenerEndpointContainer#4-6-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:11.656 [org.springframework.kafka.KafkaListenerEndpointContainer#3-6-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:11.656 [org.springframework.kafka.KafkaListenerEndpointContainer#4-6-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:11.656 [org.springframework.kafka.KafkaListenerEndpointContainer#3-6-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:11.656 [org.springframework.kafka.KafkaListenerEndpointContainer#5-6-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:11.656 [org.springframework.kafka.KafkaListenerEndpointContainer#1-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 49
13:58:11.656 [org.springframework.kafka.KafkaListenerEndpointContainer#7-7-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 49
13:58:11.656 [org.springframework.kafka.KafkaListenerEndpointContainer#5-8-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:11.656 [org.springframework.kafka.KafkaListenerEndpointContainer#2-8-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 49
13:58:11.656 [org.springframework.kafka.KafkaListenerEndpointContainer#7-0-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [exchange-waiting-order-cancel-0] for group default-group
13:58:11.656 [org.springframework.kafka.KafkaListenerEndpointContainer#2-8-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:11.656 [org.springframework.kafka.KafkaListenerEndpointContainer#7-2-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 49
13:58:11.656 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:11.656 [org.springframework.kafka.KafkaListenerEndpointContainer#1-2-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 49
13:58:11.656 [org.springframework.kafka.KafkaListenerEndpointContainer#1-2-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:11.656 [org.springframework.kafka.KafkaListenerEndpointContainer#1-2-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:11.656 [org.springframework.kafka.KafkaListenerEndpointContainer#0-5-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:11.656 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [exchange-trade-mocker-0] for group default-group
13:58:11.656 [org.springframework.kafka.KafkaListenerEndpointContainer#5-7-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 49
13:58:11.656 [org.springframework.kafka.KafkaListenerEndpointContainer#5-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 49
13:58:11.656 [org.springframework.kafka.KafkaListenerEndpointContainer#4-8-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:11.656 [org.springframework.kafka.KafkaListenerEndpointContainer#6-6-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:11.656 [org.springframework.kafka.KafkaListenerEndpointContainer#1-1-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:11.656 [org.springframework.kafka.KafkaListenerEndpointContainer#7-8-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 49
13:58:11.656 [org.springframework.kafka.KafkaListenerEndpointContainer#6-8-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 49
13:58:11.656 [org.springframework.kafka.KafkaListenerEndpointContainer#7-8-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:11.656 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 49
13:58:11.656 [org.springframework.kafka.KafkaListenerEndpointContainer#3-2-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 49
13:58:11.656 [org.springframework.kafka.KafkaListenerEndpointContainer#5-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 49
13:58:11.656 [org.springframework.kafka.KafkaListenerEndpointContainer#4-4-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:11.656 [org.springframework.kafka.KafkaListenerEndpointContainer#2-2-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:11.656 [org.springframework.kafka.KafkaListenerEndpointContainer#4-4-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:11.656 [org.springframework.kafka.KafkaListenerEndpointContainer#1-5-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 49
13:58:11.656 [org.springframework.kafka.KafkaListenerEndpointContainer#2-6-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:11.656 [org.springframework.kafka.KafkaListenerEndpointContainer#2-6-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:11.656 [org.springframework.kafka.KafkaListenerEndpointContainer#5-8-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:11.656 [org.springframework.kafka.KafkaListenerEndpointContainer#2-8-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:11.656 [org.springframework.kafka.KafkaListenerEndpointContainer#1-3-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:11.656 [org.springframework.kafka.KafkaListenerEndpointContainer#4-5-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:11.656 [org.springframework.kafka.KafkaListenerEndpointContainer#0-8-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 49
13:58:11.656 [org.springframework.kafka.KafkaListenerEndpointContainer#6-3-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:11.656 [org.springframework.kafka.KafkaListenerEndpointContainer#0-5-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:11.656 [org.springframework.kafka.KafkaListenerEndpointContainer#6-5-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 49
13:58:11.656 [org.springframework.kafka.KafkaListenerEndpointContainer#4-3-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:11.656 [org.springframework.kafka.KafkaListenerEndpointContainer#5-7-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:11.656 [org.springframework.kafka.KafkaListenerEndpointContainer#4-8-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:11.656 [org.springframework.kafka.KafkaListenerEndpointContainer#5-4-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:11.656 [org.springframework.kafka.KafkaListenerEndpointContainer#1-1-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:11.656 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:11.656 [org.springframework.kafka.KafkaListenerEndpointContainer#7-7-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:11.656 [org.springframework.kafka.KafkaListenerEndpointContainer#6-8-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:11.656 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 49
13:58:11.656 [org.springframework.kafka.KafkaListenerEndpointContainer#6-8-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:11.656 [org.springframework.kafka.KafkaListenerEndpointContainer#1-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 49
13:58:11.656 [org.springframework.kafka.KafkaListenerEndpointContainer#0-8-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:11.656 [org.springframework.kafka.KafkaListenerEndpointContainer#6-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 49
13:58:11.656 [org.springframework.kafka.KafkaListenerEndpointContainer#0-8-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:11.656 [org.springframework.kafka.KafkaListenerEndpointContainer#3-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 49
13:58:11.656 [org.springframework.kafka.KafkaListenerEndpointContainer#6-4-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:11.656 [org.springframework.kafka.KafkaListenerEndpointContainer#6-7-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 49
13:58:11.656 [org.springframework.kafka.KafkaListenerEndpointContainer#2-5-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 49
13:58:11.656 [org.springframework.kafka.KafkaListenerEndpointContainer#7-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 49
13:58:11.656 [org.springframework.kafka.KafkaListenerEndpointContainer#7-2-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:11.656 [org.springframework.kafka.KafkaListenerEndpointContainer#7-4-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:11.656 [org.springframework.kafka.KafkaListenerEndpointContainer#7-7-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:11.656 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:11.656 [org.springframework.kafka.KafkaListenerEndpointContainer#4-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 49
13:58:11.656 [org.springframework.kafka.KafkaListenerEndpointContainer#3-3-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:11.656 [org.springframework.kafka.KafkaListenerEndpointContainer#1-3-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:11.656 [org.springframework.kafka.KafkaListenerEndpointContainer#2-5-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:11.656 [org.springframework.kafka.KafkaListenerEndpointContainer#5-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 49
13:58:11.656 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:11.656 [org.springframework.kafka.KafkaListenerEndpointContainer#5-3-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:11.656 [org.springframework.kafka.KafkaListenerEndpointContainer#6-3-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:11.656 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:11.656 [org.springframework.kafka.KafkaListenerEndpointContainer#4-3-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:11.656 [org.springframework.kafka.KafkaListenerEndpointContainer#7-8-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:11.656 [org.springframework.kafka.KafkaListenerEndpointContainer#3-2-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:11.656 [org.springframework.kafka.KafkaListenerEndpointContainer#5-3-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:11.656 [org.springframework.kafka.KafkaListenerEndpointContainer#3-2-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:11.656 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:11.656 [org.springframework.kafka.KafkaListenerEndpointContainer#5-1-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:11.656 [org.springframework.kafka.KafkaListenerEndpointContainer#1-5-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:11.656 [org.springframework.kafka.KafkaListenerEndpointContainer#6-5-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:11.656 [org.springframework.kafka.KafkaListenerEndpointContainer#5-7-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:11.656 [org.springframework.kafka.KafkaListenerEndpointContainer#6-4-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:11.656 [org.springframework.kafka.KafkaListenerEndpointContainer#5-4-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:11.656 [org.springframework.kafka.KafkaListenerEndpointContainer#6-7-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:11.656 [org.springframework.kafka.KafkaListenerEndpointContainer#6-7-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:11.656 [org.springframework.kafka.KafkaListenerEndpointContainer#2-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 49
13:58:11.656 [org.springframework.kafka.KafkaListenerEndpointContainer#1-4-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:11.656 [org.springframework.kafka.KafkaListenerEndpointContainer#1-4-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:11.656 [org.springframework.kafka.KafkaListenerEndpointContainer#4-1-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:11.656 [org.springframework.kafka.KafkaListenerEndpointContainer#2-5-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:11.656 [org.springframework.kafka.KafkaListenerEndpointContainer#7-4-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:11.656 [org.springframework.kafka.KafkaListenerEndpointContainer#7-2-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:11.656 [org.springframework.kafka.KafkaListenerEndpointContainer#3-3-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:11.656 [org.springframework.kafka.KafkaListenerEndpointContainer#5-1-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:11.656 [org.springframework.kafka.KafkaListenerEndpointContainer#1-5-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:11.656 [org.springframework.kafka.KafkaListenerEndpointContainer#6-5-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:11.656 [org.springframework.kafka.KafkaListenerEndpointContainer#2-4-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:11.656 [org.springframework.kafka.KafkaListenerEndpointContainer#4-1-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:11.656 [org.springframework.kafka.KafkaListenerEndpointContainer#2-4-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:11.719 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[exchange-order-completed-0]
13:58:11.729 [org.springframework.kafka.KafkaListenerEndpointContainer#4-0-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[exchange-market-symbol-0]
13:58:11.729 [org.springframework.kafka.KafkaListenerEndpointContainer#5-0-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[exchange-order-cancel-success-0]
13:58:11.729 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[exchange-trade-0]
13:58:11.729 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[exchange-trade-plate-0]
13:58:11.729 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[exchange-trade-mocker-0]
13:58:11.729 [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[exchange-waiting-order-0]
13:58:11.729 [org.springframework.kafka.KafkaListenerEndpointContainer#7-0-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[exchange-waiting-order-cancel-0]
13:58:20.715 [org.springframework.kafka.KafkaListenerEndpointContainer#2-3-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:20.716 [org.springframework.kafka.KafkaListenerEndpointContainer#2-3-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:20.716 [org.springframework.kafka.KafkaListenerEndpointContainer#2-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:20.715 [org.springframework.kafka.KafkaListenerEndpointContainer#1-7-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:20.716 [org.springframework.kafka.KafkaListenerEndpointContainer#1-7-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:20.716 [org.springframework.kafka.KafkaListenerEndpointContainer#1-7-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:20.717 [org.springframework.kafka.KafkaListenerEndpointContainer#1-6-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:20.717 [org.springframework.kafka.KafkaListenerEndpointContainer#0-6-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:20.717 [org.springframework.kafka.KafkaListenerEndpointContainer#0-7-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:20.717 [org.springframework.kafka.KafkaListenerEndpointContainer#7-5-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:20.717 [org.springframework.kafka.KafkaListenerEndpointContainer#6-6-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:20.718 [org.springframework.kafka.KafkaListenerEndpointContainer#0-7-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:20.718 [org.springframework.kafka.KafkaListenerEndpointContainer#1-6-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:20.718 [org.springframework.kafka.KafkaListenerEndpointContainer#7-5-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:20.718 [org.springframework.kafka.KafkaListenerEndpointContainer#1-6-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:20.717 [org.springframework.kafka.KafkaListenerEndpointContainer#7-3-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:20.718 [org.springframework.kafka.KafkaListenerEndpointContainer#0-7-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:20.718 [org.springframework.kafka.KafkaListenerEndpointContainer#0-6-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:20.718 [org.springframework.kafka.KafkaListenerEndpointContainer#3-1-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:20.718 [org.springframework.kafka.KafkaListenerEndpointContainer#0-6-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:20.718 [org.springframework.kafka.KafkaListenerEndpointContainer#6-6-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:20.718 [org.springframework.kafka.KafkaListenerEndpointContainer#7-5-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:20.718 [org.springframework.kafka.KafkaListenerEndpointContainer#7-3-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:20.718 [org.springframework.kafka.KafkaListenerEndpointContainer#1-8-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:20.718 [org.springframework.kafka.KafkaListenerEndpointContainer#3-1-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:20.718 [org.springframework.kafka.KafkaListenerEndpointContainer#6-1-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:20.719 [org.springframework.kafka.KafkaListenerEndpointContainer#6-1-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:20.718 [org.springframework.kafka.KafkaListenerEndpointContainer#2-7-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:20.719 [org.springframework.kafka.KafkaListenerEndpointContainer#2-7-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:20.719 [org.springframework.kafka.KafkaListenerEndpointContainer#2-7-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:20.718 [org.springframework.kafka.KafkaListenerEndpointContainer#6-6-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:20.718 [org.springframework.kafka.KafkaListenerEndpointContainer#7-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:20.718 [org.springframework.kafka.KafkaListenerEndpointContainer#1-8-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:20.719 [org.springframework.kafka.KafkaListenerEndpointContainer#3-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:20.719 [org.springframework.kafka.KafkaListenerEndpointContainer#6-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:20.719 [org.springframework.kafka.KafkaListenerEndpointContainer#1-8-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:20.720 [org.springframework.kafka.KafkaListenerEndpointContainer#6-2-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:20.720 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:20.720 [org.springframework.kafka.KafkaListenerEndpointContainer#6-2-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:20.720 [org.springframework.kafka.KafkaListenerEndpointContainer#5-8-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:20.720 [org.springframework.kafka.KafkaListenerEndpointContainer#5-6-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:20.720 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:20.721 [org.springframework.kafka.KafkaListenerEndpointContainer#6-2-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:20.721 [org.springframework.kafka.KafkaListenerEndpointContainer#5-6-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:20.721 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:20.721 [org.springframework.kafka.KafkaListenerEndpointContainer#5-8-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:20.721 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:20.721 [org.springframework.kafka.KafkaListenerEndpointContainer#3-5-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:20.721 [org.springframework.kafka.KafkaListenerEndpointContainer#5-6-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:20.721 [org.springframework.kafka.KafkaListenerEndpointContainer#3-7-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:20.721 [org.springframework.kafka.KafkaListenerEndpointContainer#3-6-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:20.721 [org.springframework.kafka.KafkaListenerEndpointContainer#5-8-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:20.721 [org.springframework.kafka.KafkaListenerEndpointContainer#3-5-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:20.721 [org.springframework.kafka.KafkaListenerEndpointContainer#0-5-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:20.721 [org.springframework.kafka.KafkaListenerEndpointContainer#0-5-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:20.721 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:20.721 [org.springframework.kafka.KafkaListenerEndpointContainer#3-7-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:20.721 [org.springframework.kafka.KafkaListenerEndpointContainer#3-7-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:20.721 [org.springframework.kafka.KafkaListenerEndpointContainer#7-2-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:20.721 [org.springframework.kafka.KafkaListenerEndpointContainer#3-6-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:20.721 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:20.722 [org.springframework.kafka.KafkaListenerEndpointContainer#4-5-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:20.722 [org.springframework.kafka.KafkaListenerEndpointContainer#4-2-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:20.721 [org.springframework.kafka.KafkaListenerEndpointContainer#3-5-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:20.721 [org.springframework.kafka.KafkaListenerEndpointContainer#0-5-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:20.721 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:20.721 [org.springframework.kafka.KafkaListenerEndpointContainer#7-2-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:20.722 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:20.722 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:20.722 [org.springframework.kafka.KafkaListenerEndpointContainer#4-5-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:20.722 [org.springframework.kafka.KafkaListenerEndpointContainer#4-5-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:20.722 [org.springframework.kafka.KafkaListenerEndpointContainer#4-2-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:20.722 [org.springframework.kafka.KafkaListenerEndpointContainer#4-2-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:20.722 [org.springframework.kafka.KafkaListenerEndpointContainer#2-8-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:20.722 [org.springframework.kafka.KafkaListenerEndpointContainer#3-6-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:20.722 [org.springframework.kafka.KafkaListenerEndpointContainer#4-8-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:20.722 [org.springframework.kafka.KafkaListenerEndpointContainer#4-6-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:20.722 [org.springframework.kafka.KafkaListenerEndpointContainer#7-2-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:20.722 [org.springframework.kafka.KafkaListenerEndpointContainer#4-3-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:20.722 [org.springframework.kafka.KafkaListenerEndpointContainer#7-6-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:20.722 [org.springframework.kafka.KafkaListenerEndpointContainer#3-2-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:20.722 [org.springframework.kafka.KafkaListenerEndpointContainer#3-4-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:20.723 [org.springframework.kafka.KafkaListenerEndpointContainer#4-8-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:20.722 [org.springframework.kafka.KafkaListenerEndpointContainer#3-8-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:20.723 [org.springframework.kafka.KafkaListenerEndpointContainer#4-3-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:20.722 [org.springframework.kafka.KafkaListenerEndpointContainer#2-2-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:20.723 [org.springframework.kafka.KafkaListenerEndpointContainer#3-2-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:20.723 [org.springframework.kafka.KafkaListenerEndpointContainer#5-5-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:20.723 [org.springframework.kafka.KafkaListenerEndpointContainer#3-4-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:20.723 [org.springframework.kafka.KafkaListenerEndpointContainer#4-8-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:20.722 [org.springframework.kafka.KafkaListenerEndpointContainer#2-8-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:20.722 [org.springframework.kafka.KafkaListenerEndpointContainer#1-1-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:20.722 [org.springframework.kafka.KafkaListenerEndpointContainer#4-7-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:20.723 [org.springframework.kafka.KafkaListenerEndpointContainer#1-1-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:20.723 [org.springframework.kafka.KafkaListenerEndpointContainer#3-8-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:20.722 [org.springframework.kafka.KafkaListenerEndpointContainer#5-4-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:20.723 [org.springframework.kafka.KafkaListenerEndpointContainer#7-6-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:20.723 [org.springframework.kafka.KafkaListenerEndpointContainer#3-2-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:20.723 [org.springframework.kafka.KafkaListenerEndpointContainer#4-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:20.723 [org.springframework.kafka.KafkaListenerEndpointContainer#5-5-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:20.723 [org.springframework.kafka.KafkaListenerEndpointContainer#2-2-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:20.723 [org.springframework.kafka.KafkaListenerEndpointContainer#2-8-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:20.723 [org.springframework.kafka.KafkaListenerEndpointContainer#7-1-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:20.722 [org.springframework.kafka.KafkaListenerEndpointContainer#5-2-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:20.723 [org.springframework.kafka.KafkaListenerEndpointContainer#1-2-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:20.723 [org.springframework.kafka.KafkaListenerEndpointContainer#4-7-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:20.722 [org.springframework.kafka.KafkaListenerEndpointContainer#1-3-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:20.724 [org.springframework.kafka.KafkaListenerEndpointContainer#1-3-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:20.724 [org.springframework.kafka.KafkaListenerEndpointContainer#5-5-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:20.724 [org.springframework.kafka.KafkaListenerEndpointContainer#1-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:20.723 [org.springframework.kafka.KafkaListenerEndpointContainer#4-6-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:20.724 [org.springframework.kafka.KafkaListenerEndpointContainer#1-2-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:20.724 [org.springframework.kafka.KafkaListenerEndpointContainer#7-6-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:20.724 [org.springframework.kafka.KafkaListenerEndpointContainer#1-2-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:20.723 [org.springframework.kafka.KafkaListenerEndpointContainer#3-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:20.723 [org.springframework.kafka.KafkaListenerEndpointContainer#1-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:20.723 [org.springframework.kafka.KafkaListenerEndpointContainer#3-8-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:20.724 [org.springframework.kafka.KafkaListenerEndpointContainer#7-1-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:20.724 [org.springframework.kafka.KafkaListenerEndpointContainer#5-2-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:20.725 [org.springframework.kafka.KafkaListenerEndpointContainer#7-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:20.725 [org.springframework.kafka.KafkaListenerEndpointContainer#6-3-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:20.724 [org.springframework.kafka.KafkaListenerEndpointContainer#5-4-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:20.725 [org.springframework.kafka.KafkaListenerEndpointContainer#6-8-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:20.724 [org.springframework.kafka.KafkaListenerEndpointContainer#4-4-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:20.725 [org.springframework.kafka.KafkaListenerEndpointContainer#6-3-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:20.725 [org.springframework.kafka.KafkaListenerEndpointContainer#6-8-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:20.725 [org.springframework.kafka.KafkaListenerEndpointContainer#6-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:20.725 [org.springframework.kafka.KafkaListenerEndpointContainer#6-8-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:20.725 [org.springframework.kafka.KafkaListenerEndpointContainer#4-4-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:20.724 [org.springframework.kafka.KafkaListenerEndpointContainer#4-7-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:20.724 [org.springframework.kafka.KafkaListenerEndpointContainer#2-2-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:20.724 [org.springframework.kafka.KafkaListenerEndpointContainer#4-6-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:20.724 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:20.725 [org.springframework.kafka.KafkaListenerEndpointContainer#7-7-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:20.725 [org.springframework.kafka.KafkaListenerEndpointContainer#5-2-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:20.725 [org.springframework.kafka.KafkaListenerEndpointContainer#2-6-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:20.726 [org.springframework.kafka.KafkaListenerEndpointContainer#2-6-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:20.726 [org.springframework.kafka.KafkaListenerEndpointContainer#2-6-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:20.725 [org.springframework.kafka.KafkaListenerEndpointContainer#5-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:20.725 [org.springframework.kafka.KafkaListenerEndpointContainer#5-7-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:20.726 [org.springframework.kafka.KafkaListenerEndpointContainer#5-7-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:20.725 [org.springframework.kafka.KafkaListenerEndpointContainer#4-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:20.726 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:20.726 [org.springframework.kafka.KafkaListenerEndpointContainer#7-7-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:20.726 [org.springframework.kafka.KafkaListenerEndpointContainer#5-7-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:20.726 [org.springframework.kafka.KafkaListenerEndpointContainer#7-7-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:20.726 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:20.727 [org.springframework.kafka.KafkaListenerEndpointContainer#5-1-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:20.727 [org.springframework.kafka.KafkaListenerEndpointContainer#1-5-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:20.727 [org.springframework.kafka.KafkaListenerEndpointContainer#6-4-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:20.727 [org.springframework.kafka.KafkaListenerEndpointContainer#2-5-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:20.727 [org.springframework.kafka.KafkaListenerEndpointContainer#4-1-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:20.727 [org.springframework.kafka.KafkaListenerEndpointContainer#5-1-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:20.728 [org.springframework.kafka.KafkaListenerEndpointContainer#4-1-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:20.727 [org.springframework.kafka.KafkaListenerEndpointContainer#1-5-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:20.727 [org.springframework.kafka.KafkaListenerEndpointContainer#7-8-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:20.728 [org.springframework.kafka.KafkaListenerEndpointContainer#4-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:20.727 [org.springframework.kafka.KafkaListenerEndpointContainer#6-4-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:20.728 [org.springframework.kafka.KafkaListenerEndpointContainer#6-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:20.728 [org.springframework.kafka.KafkaListenerEndpointContainer#2-5-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:20.728 [org.springframework.kafka.KafkaListenerEndpointContainer#2-5-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:20.728 [org.springframework.kafka.KafkaListenerEndpointContainer#2-4-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:20.728 [org.springframework.kafka.KafkaListenerEndpointContainer#0-8-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:20.728 [org.springframework.kafka.KafkaListenerEndpointContainer#5-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:20.728 [org.springframework.kafka.KafkaListenerEndpointContainer#6-7-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:20.728 [org.springframework.kafka.KafkaListenerEndpointContainer#5-3-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:20.728 [org.springframework.kafka.KafkaListenerEndpointContainer#6-7-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:20.728 [org.springframework.kafka.KafkaListenerEndpointContainer#5-3-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:20.728 [org.springframework.kafka.KafkaListenerEndpointContainer#6-5-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:20.728 [org.springframework.kafka.KafkaListenerEndpointContainer#1-5-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:20.728 [org.springframework.kafka.KafkaListenerEndpointContainer#7-8-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:20.728 [org.springframework.kafka.KafkaListenerEndpointContainer#3-3-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:20.728 [org.springframework.kafka.KafkaListenerEndpointContainer#1-4-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:20.729 [org.springframework.kafka.KafkaListenerEndpointContainer#3-3-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:20.728 [org.springframework.kafka.KafkaListenerEndpointContainer#2-4-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:20.728 [org.springframework.kafka.KafkaListenerEndpointContainer#7-4-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group default-group
13:58:20.729 [org.springframework.kafka.KafkaListenerEndpointContainer#6-5-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:20.728 [org.springframework.kafka.KafkaListenerEndpointContainer#6-7-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:20.729 [org.springframework.kafka.KafkaListenerEndpointContainer#1-4-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:20.729 [org.springframework.kafka.KafkaListenerEndpointContainer#7-8-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:20.728 [org.springframework.kafka.KafkaListenerEndpointContainer#0-8-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:20.729 [org.springframework.kafka.KafkaListenerEndpointContainer#3-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:20.729 [org.springframework.kafka.KafkaListenerEndpointContainer#2-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:20.729 [org.springframework.kafka.KafkaListenerEndpointContainer#7-4-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[]
13:58:20.729 [org.springframework.kafka.KafkaListenerEndpointContainer#6-5-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:20.728 [org.springframework.kafka.KafkaListenerEndpointContainer#5-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:20.729 [org.springframework.kafka.KafkaListenerEndpointContainer#1-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:20.729 [org.springframework.kafka.KafkaListenerEndpointContainer#0-8-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:20.729 [org.springframework.kafka.KafkaListenerEndpointContainer#7-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:20.775 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [exchange-order-completed-0] for group default-group
13:58:20.777 [org.springframework.kafka.KafkaListenerEndpointContainer#4-0-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [exchange-market-symbol-0] for group default-group
13:58:20.778 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [exchange-trade-mocker-0] for group default-group
13:58:20.779 [org.springframework.kafka.KafkaListenerEndpointContainer#5-0-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [exchange-order-cancel-success-0] for group default-group
13:58:20.780 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [exchange-trade-0] for group default-group
13:58:20.780 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [exchange-trade-plate-0] for group default-group
13:58:20.780 [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [exchange-waiting-order-0] for group default-group
13:58:20.783 [org.springframework.kafka.KafkaListenerEndpointContainer#7-0-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [exchange-waiting-order-cancel-0] for group default-group
13:58:20.797 [org.springframework.kafka.KafkaListenerEndpointContainer#5-0-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[exchange-order-cancel-success-0]
13:58:20.797 [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[exchange-waiting-order-0]
13:58:20.797 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[exchange-trade-mocker-0]
13:58:20.797 [org.springframework.kafka.KafkaListenerEndpointContainer#7-0-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[exchange-waiting-order-cancel-0]
13:58:20.797 [org.springframework.kafka.KafkaListenerEndpointContainer#5-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:20.797 [org.springframework.kafka.KafkaListenerEndpointContainer#7-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:20.797 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[exchange-trade-plate-0]
13:58:20.797 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[exchange-trade-0]
13:58:20.797 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:20.797 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:20.797 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:20.797 [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:21.786 [org.springframework.kafka.KafkaListenerEndpointContainer#4-0-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[exchange-market-symbol-0]
13:58:21.786 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions revoked:[exchange-order-completed-0]
13:58:21.786 [org.springframework.kafka.KafkaListenerEndpointContainer#4-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:21.786 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - (Re-)joining group default-group
13:58:21.842 [org.springframework.kafka.KafkaListenerEndpointContainer#2-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 50
13:58:21.842 [org.springframework.kafka.KafkaListenerEndpointContainer#2-3-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:21.842 [org.springframework.kafka.KafkaListenerEndpointContainer#2-3-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:21.842 [org.springframework.kafka.KafkaListenerEndpointContainer#7-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 50
13:58:21.842 [org.springframework.kafka.KafkaListenerEndpointContainer#1-7-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 50
13:58:21.842 [org.springframework.kafka.KafkaListenerEndpointContainer#1-6-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 50
13:58:21.842 [org.springframework.kafka.KafkaListenerEndpointContainer#7-3-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:21.842 [org.springframework.kafka.KafkaListenerEndpointContainer#1-6-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:21.842 [org.springframework.kafka.KafkaListenerEndpointContainer#7-3-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:21.842 [org.springframework.kafka.KafkaListenerEndpointContainer#1-7-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:21.842 [org.springframework.kafka.KafkaListenerEndpointContainer#1-6-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:21.842 [org.springframework.kafka.KafkaListenerEndpointContainer#1-7-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:21.842 [org.springframework.kafka.KafkaListenerEndpointContainer#6-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 50
13:58:21.842 [org.springframework.kafka.KafkaListenerEndpointContainer#6-1-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:21.842 [org.springframework.kafka.KafkaListenerEndpointContainer#0-7-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 50
13:58:21.842 [org.springframework.kafka.KafkaListenerEndpointContainer#7-5-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 50
13:58:21.842 [org.springframework.kafka.KafkaListenerEndpointContainer#0-7-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:21.842 [org.springframework.kafka.KafkaListenerEndpointContainer#3-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 50
13:58:21.842 [org.springframework.kafka.KafkaListenerEndpointContainer#6-1-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:21.842 [org.springframework.kafka.KafkaListenerEndpointContainer#6-6-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 50
13:58:21.842 [org.springframework.kafka.KafkaListenerEndpointContainer#7-5-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:21.857 [org.springframework.kafka.KafkaListenerEndpointContainer#6-6-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:21.857 [org.springframework.kafka.KafkaListenerEndpointContainer#7-5-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:21.842 [org.springframework.kafka.KafkaListenerEndpointContainer#0-6-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 50
13:58:21.842 [org.springframework.kafka.KafkaListenerEndpointContainer#2-7-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 50
13:58:21.857 [org.springframework.kafka.KafkaListenerEndpointContainer#0-7-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:21.842 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 50
13:58:21.857 [org.springframework.kafka.KafkaListenerEndpointContainer#3-1-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:21.842 [org.springframework.kafka.KafkaListenerEndpointContainer#1-8-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 50
13:58:21.857 [org.springframework.kafka.KafkaListenerEndpointContainer#6-6-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:21.857 [org.springframework.kafka.KafkaListenerEndpointContainer#0-6-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:21.857 [org.springframework.kafka.KafkaListenerEndpointContainer#2-7-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:21.857 [org.springframework.kafka.KafkaListenerEndpointContainer#2-7-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:21.857 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [exchange-order-completed-0] for group default-group
13:58:21.857 [org.springframework.kafka.KafkaListenerEndpointContainer#3-1-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:21.857 [org.springframework.kafka.KafkaListenerEndpointContainer#1-8-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:21.857 [org.springframework.kafka.KafkaListenerEndpointContainer#0-6-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:21.857 [org.springframework.kafka.KafkaListenerEndpointContainer#1-8-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:21.857 [org.springframework.kafka.KafkaListenerEndpointContainer#5-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 50
13:58:21.857 [org.springframework.kafka.KafkaListenerEndpointContainer#3-8-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 50
13:58:21.857 [org.springframework.kafka.KafkaListenerEndpointContainer#5-0-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [exchange-order-cancel-success-0] for group default-group
13:58:21.857 [org.springframework.kafka.KafkaListenerEndpointContainer#5-2-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 50
13:58:21.857 [org.springframework.kafka.KafkaListenerEndpointContainer#6-2-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 50
13:58:21.857 [org.springframework.kafka.KafkaListenerEndpointContainer#5-2-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:21.857 [org.springframework.kafka.KafkaListenerEndpointContainer#3-8-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:21.857 [org.springframework.kafka.KafkaListenerEndpointContainer#5-2-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:21.857 [org.springframework.kafka.KafkaListenerEndpointContainer#6-2-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:21.857 [org.springframework.kafka.KafkaListenerEndpointContainer#3-8-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:21.857 [org.springframework.kafka.KafkaListenerEndpointContainer#6-2-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:21.857 [org.springframework.kafka.KafkaListenerEndpointContainer#3-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 50
13:58:21.857 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 50
13:58:21.857 [org.springframework.kafka.KafkaListenerEndpointContainer#3-7-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 50
13:58:21.857 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [exchange-trade-0] for group default-group
13:58:21.857 [org.springframework.kafka.KafkaListenerEndpointContainer#3-4-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:21.857 [org.springframework.kafka.KafkaListenerEndpointContainer#3-7-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:21.857 [org.springframework.kafka.KafkaListenerEndpointContainer#3-4-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:21.857 [org.springframework.kafka.KafkaListenerEndpointContainer#4-2-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 50
13:58:21.857 [org.springframework.kafka.KafkaListenerEndpointContainer#7-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 50
13:58:21.857 [org.springframework.kafka.KafkaListenerEndpointContainer#3-7-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:21.857 [org.springframework.kafka.KafkaListenerEndpointContainer#7-6-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 50
13:58:21.857 [org.springframework.kafka.KafkaListenerEndpointContainer#4-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 50
13:58:21.857 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 50
13:58:21.857 [org.springframework.kafka.KafkaListenerEndpointContainer#4-2-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:21.857 [org.springframework.kafka.KafkaListenerEndpointContainer#2-2-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 50
13:58:21.857 [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 50
13:58:21.857 [org.springframework.kafka.KafkaListenerEndpointContainer#4-0-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [exchange-market-symbol-0] for group default-group
13:58:21.857 [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [exchange-waiting-order-0] for group default-group
13:58:21.857 [org.springframework.kafka.KafkaListenerEndpointContainer#5-6-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 50
13:58:21.857 [org.springframework.kafka.KafkaListenerEndpointContainer#7-1-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:21.857 [org.springframework.kafka.KafkaListenerEndpointContainer#7-6-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:21.857 [org.springframework.kafka.KafkaListenerEndpointContainer#5-8-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 50
13:58:21.857 [org.springframework.kafka.KafkaListenerEndpointContainer#7-6-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:21.857 [org.springframework.kafka.KafkaListenerEndpointContainer#2-2-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:21.857 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 50
13:58:21.857 [org.springframework.kafka.KafkaListenerEndpointContainer#5-5-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 50
13:58:21.857 [org.springframework.kafka.KafkaListenerEndpointContainer#3-5-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 50
13:58:21.857 [org.springframework.kafka.KafkaListenerEndpointContainer#2-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 50
13:58:21.857 [org.springframework.kafka.KafkaListenerEndpointContainer#3-5-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:21.857 [org.springframework.kafka.KafkaListenerEndpointContainer#4-2-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:21.857 [org.springframework.kafka.KafkaListenerEndpointContainer#3-6-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 50
13:58:21.857 [org.springframework.kafka.KafkaListenerEndpointContainer#4-7-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 50
13:58:21.857 [org.springframework.kafka.KafkaListenerEndpointContainer#0-5-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 50
13:58:21.857 [org.springframework.kafka.KafkaListenerEndpointContainer#4-7-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:21.857 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [exchange-trade-plate-0] for group default-group
13:58:21.857 [org.springframework.kafka.KafkaListenerEndpointContainer#3-5-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:21.857 [org.springframework.kafka.KafkaListenerEndpointContainer#7-2-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 50
13:58:21.857 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 50
13:58:21.857 [org.springframework.kafka.KafkaListenerEndpointContainer#5-6-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:21.857 [org.springframework.kafka.KafkaListenerEndpointContainer#7-1-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:21.857 [org.springframework.kafka.KafkaListenerEndpointContainer#5-5-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:21.857 [org.springframework.kafka.KafkaListenerEndpointContainer#5-8-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:21.857 [org.springframework.kafka.KafkaListenerEndpointContainer#2-2-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:21.857 [org.springframework.kafka.KafkaListenerEndpointContainer#5-8-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:21.857 [org.springframework.kafka.KafkaListenerEndpointContainer#1-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 50
13:58:21.857 [org.springframework.kafka.KafkaListenerEndpointContainer#4-7-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:21.857 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 50
13:58:21.857 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [exchange-trade-mocker-0] for group default-group
13:58:21.857 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:21.857 [org.springframework.kafka.KafkaListenerEndpointContainer#7-2-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:21.857 [org.springframework.kafka.KafkaListenerEndpointContainer#5-6-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:21.857 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:21.857 [org.springframework.kafka.KafkaListenerEndpointContainer#4-6-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 50
13:58:21.857 [org.springframework.kafka.KafkaListenerEndpointContainer#5-5-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:21.857 [org.springframework.kafka.KafkaListenerEndpointContainer#2-1-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:21.857 [org.springframework.kafka.KafkaListenerEndpointContainer#3-6-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:21.857 [org.springframework.kafka.KafkaListenerEndpointContainer#0-5-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:21.857 [org.springframework.kafka.KafkaListenerEndpointContainer#4-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 50
13:58:21.857 [org.springframework.kafka.KafkaListenerEndpointContainer#1-3-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:21.857 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:21.857 [org.springframework.kafka.KafkaListenerEndpointContainer#4-6-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:21.857 [org.springframework.kafka.KafkaListenerEndpointContainer#1-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 50
13:58:21.857 [org.springframework.kafka.KafkaListenerEndpointContainer#2-1-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:21.857 [org.springframework.kafka.KafkaListenerEndpointContainer#7-2-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:21.857 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 50
13:58:21.857 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:21.857 [org.springframework.kafka.KafkaListenerEndpointContainer#3-6-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:21.857 [org.springframework.kafka.KafkaListenerEndpointContainer#3-2-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 50
13:58:21.857 [org.springframework.kafka.KafkaListenerEndpointContainer#2-8-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 50
13:58:21.857 [org.springframework.kafka.KafkaListenerEndpointContainer#4-5-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 50
13:58:21.857 [org.springframework.kafka.KafkaListenerEndpointContainer#4-8-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 50
13:58:21.857 [org.springframework.kafka.KafkaListenerEndpointContainer#0-5-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:21.857 [org.springframework.kafka.KafkaListenerEndpointContainer#1-1-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:21.857 [org.springframework.kafka.KafkaListenerEndpointContainer#6-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 50
13:58:21.857 [org.springframework.kafka.KafkaListenerEndpointContainer#4-3-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:21.857 [org.springframework.kafka.KafkaListenerEndpointContainer#4-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 50
13:58:21.857 [org.springframework.kafka.KafkaListenerEndpointContainer#4-3-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:21.857 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:21.857 [org.springframework.kafka.KafkaListenerEndpointContainer#1-3-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:21.857 [org.springframework.kafka.KafkaListenerEndpointContainer#4-6-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:21.857 [org.springframework.kafka.KafkaListenerEndpointContainer#4-5-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:21.857 [org.springframework.kafka.KafkaListenerEndpointContainer#4-8-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:21.857 [org.springframework.kafka.KafkaListenerEndpointContainer#5-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 50
13:58:21.857 [org.springframework.kafka.KafkaListenerEndpointContainer#1-1-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:21.857 [org.springframework.kafka.KafkaListenerEndpointContainer#4-4-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:21.857 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 50
13:58:21.857 [org.springframework.kafka.KafkaListenerEndpointContainer#4-4-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:21.857 [org.springframework.kafka.KafkaListenerEndpointContainer#3-2-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:21.857 [org.springframework.kafka.KafkaListenerEndpointContainer#2-6-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 50
13:58:21.857 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:21.857 [org.springframework.kafka.KafkaListenerEndpointContainer#2-8-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:21.857 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:21.857 [org.springframework.kafka.KafkaListenerEndpointContainer#4-5-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:21.857 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:21.857 [org.springframework.kafka.KafkaListenerEndpointContainer#5-4-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:21.857 [org.springframework.kafka.KafkaListenerEndpointContainer#6-3-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:21.857 [org.springframework.kafka.KafkaListenerEndpointContainer#6-3-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:21.857 [org.springframework.kafka.KafkaListenerEndpointContainer#3-2-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:21.857 [org.springframework.kafka.KafkaListenerEndpointContainer#2-6-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:21.857 [org.springframework.kafka.KafkaListenerEndpointContainer#4-8-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:21.857 [org.springframework.kafka.KafkaListenerEndpointContainer#2-8-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:21.857 [org.springframework.kafka.KafkaListenerEndpointContainer#5-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 50
13:58:21.857 [org.springframework.kafka.KafkaListenerEndpointContainer#5-4-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:21.857 [org.springframework.kafka.KafkaListenerEndpointContainer#2-6-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:21.857 [org.springframework.kafka.KafkaListenerEndpointContainer#5-1-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:21.857 [org.springframework.kafka.KafkaListenerEndpointContainer#5-1-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:21.857 [org.springframework.kafka.KafkaListenerEndpointContainer#5-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 50
13:58:21.857 [org.springframework.kafka.KafkaListenerEndpointContainer#5-3-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:21.857 [org.springframework.kafka.KafkaListenerEndpointContainer#5-3-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:21.857 [org.springframework.kafka.KafkaListenerEndpointContainer#7-7-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 50
13:58:21.857 [org.springframework.kafka.KafkaListenerEndpointContainer#7-7-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:21.857 [org.springframework.kafka.KafkaListenerEndpointContainer#7-7-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:21.857 [org.springframework.kafka.KafkaListenerEndpointContainer#6-8-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 50
13:58:21.857 [org.springframework.kafka.KafkaListenerEndpointContainer#7-0-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 50
13:58:21.857 [org.springframework.kafka.KafkaListenerEndpointContainer#6-8-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:21.857 [org.springframework.kafka.KafkaListenerEndpointContainer#5-7-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 50
13:58:21.873 [org.springframework.kafka.KafkaListenerEndpointContainer#7-0-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [exchange-waiting-order-cancel-0] for group default-group
13:58:21.857 [org.springframework.kafka.KafkaListenerEndpointContainer#1-2-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 50
13:58:21.873 [org.springframework.kafka.KafkaListenerEndpointContainer#6-8-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:21.873 [org.springframework.kafka.KafkaListenerEndpointContainer#5-7-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:21.873 [org.springframework.kafka.KafkaListenerEndpointContainer#1-5-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 50
13:58:21.873 [org.springframework.kafka.KafkaListenerEndpointContainer#1-2-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:21.873 [org.springframework.kafka.KafkaListenerEndpointContainer#5-7-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:21.873 [org.springframework.kafka.KafkaListenerEndpointContainer#1-5-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:21.874 [org.springframework.kafka.KafkaListenerEndpointContainer#6-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 50
13:58:21.874 [org.springframework.kafka.KafkaListenerEndpointContainer#1-2-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:21.874 [org.springframework.kafka.KafkaListenerEndpointContainer#6-4-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:21.874 [org.springframework.kafka.KafkaListenerEndpointContainer#6-4-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:21.874 [org.springframework.kafka.KafkaListenerEndpointContainer#1-5-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:21.874 [org.springframework.kafka.KafkaListenerEndpointContainer#2-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 50
13:58:21.874 [org.springframework.kafka.KafkaListenerEndpointContainer#3-3-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 50
13:58:21.874 [org.springframework.kafka.KafkaListenerEndpointContainer#2-4-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:21.874 [org.springframework.kafka.KafkaListenerEndpointContainer#1-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 50
13:58:21.875 [org.springframework.kafka.KafkaListenerEndpointContainer#3-3-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:21.874 [org.springframework.kafka.KafkaListenerEndpointContainer#7-8-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 50
13:58:21.875 [org.springframework.kafka.KafkaListenerEndpointContainer#1-4-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:21.874 [org.springframework.kafka.KafkaListenerEndpointContainer#2-5-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 50
13:58:21.875 [org.springframework.kafka.KafkaListenerEndpointContainer#6-7-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 50
13:58:21.875 [org.springframework.kafka.KafkaListenerEndpointContainer#7-4-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 50
13:58:21.875 [org.springframework.kafka.KafkaListenerEndpointContainer#2-4-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:21.875 [org.springframework.kafka.KafkaListenerEndpointContainer#7-4-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:21.875 [org.springframework.kafka.KafkaListenerEndpointContainer#3-3-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:21.875 [org.springframework.kafka.KafkaListenerEndpointContainer#7-4-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:21.875 [org.springframework.kafka.KafkaListenerEndpointContainer#0-8-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 50
13:58:21.875 [org.springframework.kafka.KafkaListenerEndpointContainer#4-1-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 50
13:58:21.876 [org.springframework.kafka.KafkaListenerEndpointContainer#0-8-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:21.875 [org.springframework.kafka.KafkaListenerEndpointContainer#6-5-C-1] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - Successfully joined group default-group with generation 50
13:58:21.876 [org.springframework.kafka.KafkaListenerEndpointContainer#4-1-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:21.876 [org.springframework.kafka.KafkaListenerEndpointContainer#0-8-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:21.875 [org.springframework.kafka.KafkaListenerEndpointContainer#1-4-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:21.875 [org.springframework.kafka.KafkaListenerEndpointContainer#7-8-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:21.875 [org.springframework.kafka.KafkaListenerEndpointContainer#2-5-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:21.876 [org.springframework.kafka.KafkaListenerEndpointContainer#7-8-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:21.876 [org.springframework.kafka.KafkaListenerEndpointContainer#2-5-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:21.875 [org.springframework.kafka.KafkaListenerEndpointContainer#6-7-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:21.876 [org.springframework.kafka.KafkaListenerEndpointContainer#6-5-C-1] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [] for group default-group
13:58:21.877 [org.springframework.kafka.KafkaListenerEndpointContainer#6-7-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:21.876 [org.springframework.kafka.KafkaListenerEndpointContainer#4-1-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:21.877 [org.springframework.kafka.KafkaListenerEndpointContainer#6-5-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[]
13:58:21.925 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[exchange-order-completed-0]
13:58:21.933 [org.springframework.kafka.KafkaListenerEndpointContainer#4-0-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[exchange-market-symbol-0]
13:58:21.934 [org.springframework.kafka.KafkaListenerEndpointContainer#5-0-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[exchange-order-cancel-success-0]
13:58:21.938 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[exchange-trade-0]
13:58:21.939 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[exchange-trade-mocker-0]
13:58:21.940 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[exchange-trade-plate-0]
13:58:21.941 [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[exchange-waiting-order-0]
13:58:21.956 [org.springframework.kafka.KafkaListenerEndpointContainer#7-0-C-1] INFO  o.s.kafka.listener.KafkaMessageListenerContainer - partitions assigned:[exchange-waiting-order-cancel-0]
13:58:35.740 [DiscoveryClient-CacheRefreshExecutor-0] INFO  com.netflix.discovery.DiscoveryClient - Disable delta property : false
13:58:35.740 [DiscoveryClient-CacheRefreshExecutor-0] INFO  com.netflix.discovery.DiscoveryClient - Single vip registry refresh property : null
13:58:35.740 [DiscoveryClient-CacheRefreshExecutor-0] INFO  com.netflix.discovery.DiscoveryClient - Force full registry fetch : false
13:58:35.740 [DiscoveryClient-CacheRefreshExecutor-0] INFO  com.netflix.discovery.DiscoveryClient - Application is null : false
13:58:35.740 [DiscoveryClient-CacheRefreshExecutor-0] INFO  com.netflix.discovery.DiscoveryClient - Registered Applications size is zero : true
13:58:35.740 [DiscoveryClient-CacheRefreshExecutor-0] INFO  com.netflix.discovery.DiscoveryClient - Application version is -1: false
13:58:35.740 [DiscoveryClient-CacheRefreshExecutor-0] INFO  com.netflix.discovery.DiscoveryClient - Getting all instance registry info from the eureka server
13:58:35.807 [DiscoveryClient-CacheRefreshExecutor-0] INFO  com.netflix.discovery.DiscoveryClient - The response status is 200
13:59:00.007 [MessageBroker-11] INFO  cn.ztuo.bitrade.job.KLineGeneratorJob - 分钟K线:Tue Sep 10 13:59:00 CST 2019
13:59:00.007 [MessageBroker-11] INFO  cn.ztuo.bitrade.job.KLineGeneratorJob - 生成BTC/USDT分钟k线:{}
13:59:00.037 [MessageBroker-11] INFO  cn.ztuo.bitrade.processor.DefaultCoinProcessor - auto generate 1min kline in 13:59:00,data={"closePrice":0,"count":0,"highestPrice":0,"lowestPrice":0,"openPrice":0,"period":"1min","time":1568095140000,"turnover":0,"volume":0}
13:59:02.201 [MessageBroker-9] INFO  o.s.web.socket.config.WebSocketMessageBrokerStats - WebSocketSession[0 current WS(0)-HttpStream(0)-HttpPoll(0), 0 total, 0 closed abnormally (0 connect failure, 0 send limit, 0 transport error)], stompSubProtocol[processed CONNECT(0)-CONNECTED(0)-DISCONNECT(0)], stompBrokerRelay[null], inboundChannel[pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 0], outboundChannelpool size = 0, active threads = 0, queued tasks = 0, completed tasks = 0], sockJsScheduler[pool size = 12, active threads = 1, queued tasks = 8, completed tasks = 453]
14:00:00.005 [MessageBroker-11] INFO  cn.ztuo.bitrade.component.CoinExchangeRate - rate map:{CNHUSD=0.14925, USDCNH=6.7}
14:00:00.005 [MessageBroker-12] INFO  cn.ztuo.bitrade.job.KLineGeneratorJob - 分钟K线:Tue Sep 10 14:00:00 CST 2019
14:00:00.005 [MessageBroker-12] INFO  cn.ztuo.bitrade.job.KLineGeneratorJob - 生成BTC/USDT分钟k线:{}
14:00:00.005 [MessageBroker-12] INFO  cn.ztuo.bitrade.processor.DefaultCoinProcessor - auto generate 1min kline in 14:00:00,data={"closePrice":0,"count":0,"highestPrice":0,"lowestPrice":0,"openPrice":0,"period":"1min","time":1568095200000,"turnover":0,"volume":0}
14:00:00.005 [MessageBroker-3] INFO  cn.ztuo.bitrade.job.KLineGeneratorJob - 小时K线:Tue Sep 10 14:00:00 CST 2019
14:00:00.005 [MessageBroker-3] INFO  cn.ztuo.bitrade.processor.DefaultCoinProcessor - time range from 2019-09-10 13:00:00 to 2019-09-10 14:00:00
14:00:00.016 [MessageBroker-12] INFO  cn.ztuo.bitrade.processor.DefaultCoinProcessor - time range from 2019-09-10 13:55:00 to 2019-09-10 14:00:00
14:00:00.032 [MessageBroker-12] INFO  cn.ztuo.bitrade.processor.DefaultCoinProcessor - time range from 2019-09-10 13:50:00 to 2019-09-10 14:00:00
14:00:00.048 [MessageBroker-12] INFO  cn.ztuo.bitrade.processor.DefaultCoinProcessor - time range from 2019-09-10 13:45:00 to 2019-09-10 14:00:00
14:00:00.048 [MessageBroker-12] INFO  cn.ztuo.bitrade.processor.DefaultCoinProcessor - time range from 2019-09-10 13:30:00 to 2019-09-10 14:00:00
14:01:00.006 [MessageBroker-9] INFO  cn.ztuo.bitrade.job.KLineGeneratorJob - 分钟K线:Tue Sep 10 14:01:00 CST 2019
14:01:00.006 [MessageBroker-9] INFO  cn.ztuo.bitrade.job.KLineGeneratorJob - 生成BTC/USDT分钟k线:{}
14:01:00.006 [MessageBroker-9] INFO  cn.ztuo.bitrade.processor.DefaultCoinProcessor - auto generate 1min kline in 14:01:00,data={"closePrice":0,"count":0,"highestPrice":0,"lowestPrice":0,"openPrice":0,"period":"1min","time":1568095260000,"turnover":0,"volume":0}
14:02:00.036 [MessageBroker-11] INFO  cn.ztuo.bitrade.job.KLineGeneratorJob - 分钟K线:Tue Sep 10 14:02:00 CST 2019
14:02:00.036 [MessageBroker-11] INFO  cn.ztuo.bitrade.job.KLineGeneratorJob - 生成BTC/USDT分钟k线:{}
14:02:00.036 [MessageBroker-11] INFO  cn.ztuo.bitrade.processor.DefaultCoinProcessor - auto generate 1min kline in 14:02:00,data={"closePrice":0,"count":0,"highestPrice":0,"lowestPrice":0,"openPrice":0,"period":"1min","time":1568095320000,"turnover":0,"volume":0}
14:03:00.013 [MessageBroker-12] INFO  cn.ztuo.bitrade.job.KLineGeneratorJob - 分钟K线:Tue Sep 10 14:03:00 CST 2019
14:03:00.013 [MessageBroker-12] INFO  cn.ztuo.bitrade.job.KLineGeneratorJob - 生成BTC/USDT分钟k线:{}
14:03:00.015 [MessageBroker-12] INFO  cn.ztuo.bitrade.processor.DefaultCoinProcessor - auto generate 1min kline in 14:03:00,data={"closePrice":0,"count":0,"highestPrice":0,"lowestPrice":0,"openPrice":0,"period":"1min","time":1568095380000,"turnover":0,"volume":0}
14:03:05.628 [AsyncResolver-bootstrap-executor-0] INFO  c.n.d.shared.resolver.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
14:04:00.002 [MessageBroker-2] INFO  cn.ztuo.bitrade.job.KLineGeneratorJob - 分钟K线:Tue Sep 10 14:04:00 CST 2019
14:04:00.002 [MessageBroker-2] INFO  cn.ztuo.bitrade.job.KLineGeneratorJob - 生成BTC/USDT分钟k线:{}
14:04:00.004 [MessageBroker-2] INFO  cn.ztuo.bitrade.processor.DefaultCoinProcessor - auto generate 1min kline in 14:04:00,data={"closePrice":0,"count":0,"highestPrice":0,"lowestPrice":0,"openPrice":0,"period":"1min","time":1568095440000,"turnover":0,"volume":0}
14:05:00.007 [MessageBroker-4] INFO  cn.ztuo.bitrade.job.KLineGeneratorJob - 分钟K线:Tue Sep 10 14:05:00 CST 2019
14:05:00.007 [MessageBroker-4] INFO  cn.ztuo.bitrade.job.KLineGeneratorJob - 生成BTC/USDT分钟k线:{}
14:05:00.007 [MessageBroker-4] INFO  cn.ztuo.bitrade.processor.DefaultCoinProcessor - auto generate 1min kline in 14:05:00,data={"closePrice":0,"count":0,"highestPrice":0,"lowestPrice":0,"openPrice":0,"period":"1min","time":1568095500000,"turnover":0,"volume":0}
14:05:00.022 [MessageBroker-4] INFO  cn.ztuo.bitrade.processor.DefaultCoinProcessor - time range from 2019-09-10 14:00:00 to 2019-09-10 14:05:00
14:06:00.015 [MessageBroker-10] INFO  cn.ztuo.bitrade.job.KLineGeneratorJob - 分钟K线:Tue Sep 10 14:06:00 CST 2019
14:06:00.015 [MessageBroker-10] INFO  cn.ztuo.bitrade.job.KLineGeneratorJob - 生成BTC/USDT分钟k线:{}
14:06:00.015 [MessageBroker-10] INFO  cn.ztuo.bitrade.processor.DefaultCoinProcessor - auto generate 1min kline in 14:06:00,data={"closePrice":0,"count":0,"highestPrice":0,"lowestPrice":0,"openPrice":0,"period":"1min","time":1568095560000,"turnover":0,"volume":0}
14:07:00.013 [MessageBroker-5] INFO  cn.ztuo.bitrade.job.KLineGeneratorJob - 分钟K线:Tue Sep 10 14:07:00 CST 2019
14:07:00.013 [MessageBroker-5] INFO  cn.ztuo.bitrade.job.KLineGeneratorJob - 生成BTC/USDT分钟k线:{}
14:07:00.013 [MessageBroker-5] INFO  cn.ztuo.bitrade.processor.DefaultCoinProcessor - auto generate 1min kline in 14:07:00,data={"closePrice":0,"count":0,"highestPrice":0,"lowestPrice":0,"openPrice":0,"period":"1min","time":1568095620000,"turnover":0,"volume":0}
14:08:00.016 [MessageBroker-2] INFO  cn.ztuo.bitrade.job.KLineGeneratorJob - 分钟K线:Tue Sep 10 14:08:00 CST 2019
14:08:00.016 [MessageBroker-2] INFO  cn.ztuo.bitrade.job.KLineGeneratorJob - 生成BTC/USDT分钟k线:{}
14:08:00.016 [MessageBroker-2] INFO  cn.ztuo.bitrade.processor.DefaultCoinProcessor - auto generate 1min kline in 14:08:00,data={"closePrice":0,"count":0,"highestPrice":0,"lowestPrice":0,"openPrice":0,"period":"1min","time":1568095680000,"turnover":0,"volume":0}
14:08:05.632 [AsyncResolver-bootstrap-executor-0] INFO  c.n.d.shared.resolver.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
14:09:00.018 [MessageBroker-10] INFO  cn.ztuo.bitrade.job.KLineGeneratorJob - 分钟K线:Tue Sep 10 14:09:00 CST 2019
14:09:00.018 [MessageBroker-10] INFO  cn.ztuo.bitrade.job.KLineGeneratorJob - 生成BTC/USDT分钟k线:{}
14:09:00.018 [MessageBroker-10] INFO  cn.ztuo.bitrade.processor.DefaultCoinProcessor - auto generate 1min kline in 14:09:00,data={"closePrice":0,"count":0,"highestPrice":0,"lowestPrice":0,"openPrice":0,"period":"1min","time":1568095740000,"turnover":0,"volume":0}
14:10:00.012 [MessageBroker-5] INFO  cn.ztuo.bitrade.job.KLineGeneratorJob - 分钟K线:Tue Sep 10 14:10:00 CST 2019
14:10:00.012 [MessageBroker-5] INFO  cn.ztuo.bitrade.job.KLineGeneratorJob - 生成BTC/USDT分钟k线:{}
14:10:00.014 [MessageBroker-5] INFO  cn.ztuo.bitrade.processor.DefaultCoinProcessor - auto generate 1min kline in 14:10:00,data={"closePrice":0,"count":0,"highestPrice":0,"lowestPrice":0,"openPrice":0,"period":"1min","time":1568095800000,"turnover":0,"volume":0}
14:10:00.027 [MessageBroker-5] INFO  cn.ztuo.bitrade.processor.DefaultCoinProcessor - time range from 2019-09-10 14:05:00 to 2019-09-10 14:10:00
14:10:00.038 [MessageBroker-5] INFO  cn.ztuo.bitrade.processor.DefaultCoinProcessor - time range from 2019-09-10 14:00:00 to 2019-09-10 14:10:00
14:11:00.003 [MessageBroker-8] INFO  cn.ztuo.bitrade.job.KLineGeneratorJob - 分钟K线:Tue Sep 10 14:11:00 CST 2019
14:11:00.003 [MessageBroker-8] INFO  cn.ztuo.bitrade.job.KLineGeneratorJob - 生成BTC/USDT分钟k线:{}
14:11:00.005 [MessageBroker-8] INFO  cn.ztuo.bitrade.processor.DefaultCoinProcessor - auto generate 1min kline in 14:11:00,data={"closePrice":0,"count":0,"highestPrice":0,"lowestPrice":0,"openPrice":0,"period":"1min","time":1568095860000,"turnover":0,"volume":0}
14:12:00.001 [MessageBroker-2] INFO  cn.ztuo.bitrade.job.KLineGeneratorJob - 分钟K线:Tue Sep 10 14:12:00 CST 2019
14:12:00.001 [MessageBroker-2] INFO  cn.ztuo.bitrade.job.KLineGeneratorJob - 生成BTC/USDT分钟k线:{}
14:12:00.003 [MessageBroker-2] INFO  cn.ztuo.bitrade.processor.DefaultCoinProcessor - auto generate 1min kline in 14:12:00,data={"closePrice":0,"count":0,"highestPrice":0,"lowestPrice":0,"openPrice":0,"period":"1min","time":1568095920000,"turnover":0,"volume":0}
14:13:00.024 [MessageBroker-9] INFO  cn.ztuo.bitrade.job.KLineGeneratorJob - 分钟K线:Tue Sep 10 14:13:00 CST 2019
14:13:00.024 [MessageBroker-9] INFO  cn.ztuo.bitrade.job.KLineGeneratorJob - 生成BTC/USDT分钟k线:{}
14:13:00.024 [MessageBroker-9] INFO  cn.ztuo.bitrade.processor.DefaultCoinProcessor - auto generate 1min kline in 14:13:00,data={"closePrice":0,"count":0,"highestPrice":0,"lowestPrice":0,"openPrice":0,"period":"1min","time":1568095980000,"turnover":0,"volume":0}
14:13:05.633 [AsyncResolver-bootstrap-executor-0] INFO  c.n.d.shared.resolver.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
14:14:00.013 [MessageBroker-1] INFO  cn.ztuo.bitrade.job.KLineGeneratorJob - 分钟K线:Tue Sep 10 14:14:00 CST 2019
14:14:00.013 [MessageBroker-1] INFO  cn.ztuo.bitrade.job.KLineGeneratorJob - 生成BTC/USDT分钟k线:{}
14:14:00.013 [MessageBroker-1] INFO  cn.ztuo.bitrade.processor.DefaultCoinProcessor - auto generate 1min kline in 14:14:00,data={"closePrice":0,"count":0,"highestPrice":0,"lowestPrice":0,"openPrice":0,"period":"1min","time":1568096040000,"turnover":0,"volume":0}
